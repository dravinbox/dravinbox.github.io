<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[java并发编程第一篇]]></title>
    <url>%2F2018%2F02%2F26%2Fjava-concurrent-1%2F</url>
    <content type="text"><![CDATA[目录1.1并发编程的目的1.2线程安全1.3对象锁的同步和异步1.4脏读1.5synchronized的其他概念1.6synchronized代码块1.7volatile关键字 1.1 并发编程的目的第一：面试非常重要第二：知识拓展第三：在以后的分布式系统中，你都可以找到类似的并发，分布式，并行处理的问题 多线程中：synchronized 同步的volatile 爆炸性，挥发性ReentrantLock 重进入锁concurrent 并发的；一致的；同时发生的 1.2 线程安全1.2.1 概念当多个线程访问某一个类（对象或方法）时，这个类始终都能表现出正确的行为，那么这个类（对象或方法）就是线程安全的。 synchronized:可以在任意对象及方法上加锁，而加锁的这段代码称为“互斥区”或“临界区” 1.2.2 多线程与多个锁关键字synchronized 是对象锁，多个对象相当于有多个锁。所以说当多个线程操作的是不同的对象时，就相当于使用多把锁，多线程之间互不影响。 注意，当synchronized修饰的是静态方法时，这把锁是类锁，无论有多少个对象，它们公用一把锁，因此会产生锁竞争 1.3 对象锁的同步和异步同步：synchronized 同步概念就是共享，共享资源。 异步：asynchronized 异步的概念就是独立，相互之间不受任何制约。 同步需要线程安全。需要两个特性： 1.原子性（同步） 2.可见性 1.3.1 对象锁的必要性案例11234567891011121314151617181920212223242526272829303132333435363738394041424344package mytest;public class Bank &#123; private double money=1000; //取钱 public double getMoney(double get_money)&#123; money=money-get_money; System.out.println("取钱后，总金额："+money); return get_money ; &#125; //存钱 public double putMoney(double put_money)&#123; money+=put_money; System.out.println("存钱后，总金额："+money); return money; &#125; public static void main(String [] args)&#123; Bank bank= new Bank(); Thread t1=new Thread(new Runnable()&#123; @Override public void run() &#123; bank.getMoney(100); &#125; &#125;,"t1"); Thread t2=new Thread(new Runnable()&#123; @Override public void run() &#123; bank.putMoney(100); &#125; &#125;,"t2"); t1.start(); t2.start(); &#125;&#125; 结果：取钱后，总金额：1000.0存钱后，总金额：1000.0 我们期待的结果应该是“取钱后，总金额：900.0存钱后，总金额：1000.0”，那是因为线程1和线程2的代码经过排列之后才给cpu处理，有可能排列的是这样的： 12345//有可能排序成这样，依次让cpu处理:money=money-get_money;//线程1的代码money+=put_money;//线程2的代码System.out.println("取钱后，总金额："+money);//线程1的代码System.out.println("存钱后，总金额："+money);//线程2的代码 所以有可能出现以上结果 改进代码加上synchronized,使得getMoney和putMoney的方法拥有原子性，就是说，里面的代码是一个整体，在cpu排序处理时，不可插入其他线程的代码。1234567891011121314151617181920212223242526272829303132333435363738394041424344package mytest;public class Bank &#123; private double money=1000; //取钱 public synchronized double getMoney(double get_money)&#123; money=money-get_money; System.out.println("取钱后，总金额："+money); return get_money ; &#125; //存钱 public synchronized double putMoney(double put_money)&#123; money+=put_money; System.out.println("存钱后，总金额："+money); return money; &#125; public static void main(String [] args)&#123; Bank bank= new Bank(); Thread t1=new Thread(new Runnable()&#123; @Override public void run() &#123; bank.getMoney(100); &#125; &#125;,"t1"); Thread t2=new Thread(new Runnable()&#123; @Override public void run() &#123; bank.putMoney(100); &#125; &#125;,"t2"); t1.start(); t2.start(); &#125;&#125; 结果：取钱后，总金额：900.0存钱后，总金额：1000.0 对象锁被synchronzied修饰的方法叫同步方法，否则叫异步方法。当某一线程调用该对象的同步方法时，其他线程无法调用该对象的其他同步方法，但是可以调用该对象的异步方法。也就是说，无论多少个synchronized方法，一个对象一把锁，使用了一把锁，其他的线程只能等待锁释放，才能访问同步方法。 案例212345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package mytest;public class Bank &#123; private volatile double money=1000; //同步方法，取钱 public synchronized double getMoney(double get_money)&#123; money=money-get_money; System.out.println("取钱后，总金额："+money);// return get_money ; while(true)&#123; System.out.println(Thread.currentThread().getName()+"拿着把锁"); &#125; &#125; //异步方法，存钱 public synchronized double putMoney(double put_money)&#123; money+=put_money; System.out.println("存钱后，总金额："+money); return money; &#125; //异步方法 public void getm()&#123; while(true)&#123; System.out.println("异步方法，============总金额："+money); &#125; &#125; public static void main(String [] args)&#123; Bank bank= new Bank(); Thread t1=new Thread(new Runnable()&#123; @Override public void run() &#123; //访问同步方法 bank.getMoney(100); &#125; &#125;,"t1"); Thread t2=new Thread(new Runnable()&#123; @Override public void run() &#123; //访问同步方法 bank.putMoney(100); &#125; &#125;,"t2"); Thread t3=new Thread(new Runnable()&#123; @Override public void run() &#123; //访问异步方法 bank.getm(); &#125; &#125;,"t3"); t1.start(); t2.start(); t3.start(); &#125; &#125; 结果：t1拿着把锁异步方法，============总金额：900.0异步方法，============总金额：900.0异步方法，============总金额：900.0异步方法，============总金额：900.0异步方法，============总金额：900.0异步方法，============总金额：900.0t1拿着把锁t1拿着把锁异步方法，============总金额：900.0异步方法，============总金额：900.0异步方法，============总金额：900.0异步方法，============总金额：900.0t1拿着把锁t1拿着把锁异步方法，============总金额：900.0 总结：当线程持续拿着一把对象锁(bank)不放时，其他线程就不能访问该对象锁(bank)，但是能访问bank的异步方法。 1.4 脏读对于对象的同步和异步的方法，我们在设计自己的程序时候，一定要考虑问题的整体(原子性)，不然会出现数据不一致的错误。 例子：set/get方法都加上synchronized的修饰。 synchronized能保证函数的原子性 1.5 synchronized的其他概念锁重入概念关键字synchronized 拥有锁重入的功能，也就是在使用synchronized时，当一个线程得到一个对象的锁后，再次调用此对象时就是可以再次获得该对象的锁。 锁重入形式1:对于某一线程操作某一对象时，在该类函数中，不同的同步方法相互调用，形成锁重入。 锁重入形式2:对于某一线程操作某一对象时，在父子类函数中，不同类的不同的同步方法相互调用，形成锁重入。 synchronized的异常处理当synchronized处理过程中，抛出异常时会丢失锁，因此要好好的处理异常，不然业务逻辑就发生严重错误。 1.6 synchronized代码块对象锁123synchronized(this)&#123;&#125;//修改对象里的属性时，不会释放锁。 字符串(它也是对象)锁：1.使用常量字符串作为锁123456synchronized(“ssss”)&#123; while(true)&#123; //这种形式某一线程不会释放锁,此序使用"ssss"对象锁 &#125;&#125; 2.使用new String(“sss”)作为锁,每次访问该代码块，都使用新的字符串作为锁123456synchronized(new String(“sss”))&#123; while(true)&#123; //这种形式任意线程不会释放锁,此序使用各自new 出来的"ssss"对象锁,相互不影响 &#125;&#125; 3.修改对象的引用，导致释放锁12345private lockstr=’ssss’;synchronized(lockstr)&#123; lockstr=“aaa”; //这种形式，当线程在改变的瞬间释放锁，导致其他线程进来&#125; 死锁：123456789101112131415//线程1执行的代码块：synchronized(object1)&#123; //尝试获取object2锁 synchronized(object2)&#123; .. &#125;&#125;//线程2执行的代码块：synchronized(object2)&#123; //尝试获取object1锁 synchronized(object1)&#123; .. &#125;&#125; 以上是双方互持有对方的锁，形成了死锁 1.7 volatile关键字volatile 关键字主要作用是使变量在多个线程间可见 下面这段话摘自《深入理解Java虚拟机》：“观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令” lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： 1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； 2）它会强制将对缓存的修改操作立即写入主存； 3）如果是写操作，它会导致其他CPU中对应的缓存行无效。 可见性当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。 而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。 另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。 使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）；由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。 综上所述，volatile能保证可见性,synchronized和Lock也能保证可见性 原子性1234x = 10; //语句1y = x; //语句2x++; //语句3x = x + 1; //语句4 语句1 是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。 语句2 实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。 同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。 所以上面4个语句只有语句1的操作具备原子性。 volatile 能保证可见性，但不能保证原子性synchronized，Lock,java.util.concurrent.atomic*能保证原子性 有序性在前面提到volatile关键字能禁止指令重排序，所以volatile能在一定程度上保证有序性。 volatile关键字禁止指令重排序有两层意思： 当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行； 在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。 可能上面说的比较绕，举个简单的例子：12345678//x、y为非volatile变量//flag为volatile变量 x = 2; //语句1y = 0; //语句2flag = true; //语句3x = 4; //语句4y = -1; //语句5 由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。 并且volatile关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。 一个例子： 123456789//线程1:context = loadContext(); //语句1inited = true; //语句2 //线程2:while(!inited )&#123; sleep() &#125;doSomethingwithconfig(context); 前面举这个例子的时候，提到有可能语句2会在语句1之前执行，那么久可能导致context还没被初始化，而线程2中就使用未初始化的context去进行操作，导致程序出错。 这里如果用volatile关键字对inited变量进行修饰，就不会出现这种问题了，因为当执行到语句2时，必定能保证context已经初始化完毕。 volatile应用场景ynchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件： 1）对变量的写操作不依赖于当前值 2）该变量没有包含在具有其他变量的不变式中 实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。 事实上，我的理解就是上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行。 下面列举几个Java中使用volatile的几个场景。 状态标记量1234567891011//例1volatile boolean flag = false; //线程1while(!flag)&#123; doSomething();&#125; //线程2public void setFlag() &#123; flag = true;&#125;setFlag(); 1234567891011//例2volatile boolean inited = false;//线程1:context = loadContext(); inited = true; //线程2:while(!inited )&#123;sleep()&#125;doSomethingwithconfig(context); 就是在两个线程之间，一个线程的循环状态被两外一线程通过inited的值来控制 double check123456789101112131415161718//例3class Singleton&#123; private volatile static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if(instance==null) &#123; synchronized (Singleton.class) &#123; if(instance==null) instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; double-check的应用就是：多线程取得单例时，先只允许同步获取单例，一旦单例被实例化出来，其他的线程就无须来竞争锁都可以异步获取单例。]]></content>
      <categories>
        <category>java</category>
        <category>concurrent</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>synchronized</tag>
        <tag>volatile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Socket网络编程第三篇]]></title>
    <url>%2F2018%2F02%2F25%2Fsocket-io-3%2F</url>
    <content type="text"><![CDATA[目录代码：https://github.com/dravinbox/SocketIO_03 最佳实践（数据通信，心跳检测） netty实现文件服务器（基于Http协议） mina入门基础 1.1 最佳实践 - 数据通信考虑机器应该如何使用netty通信： 第一种，使用长连接，如果服务器的性能足够好，并且我们的客户端的数量也比较少的情况下，推荐这种 第二种，一次性批量提交数据，采用短连接；又或者定时任务轮询提交，在对于实时性不高的应用程序中可以推荐使用。 第三种，我们可以使用特殊的长连接，超时时断开连接，下次需要发送请求时，再次建立连接。 1.2最佳实践 - 心跳检测我们使用Socket 通信一般经常会处理多个服务器之间的心跳检测，一般来说我们去维护服务器集群，肯定有一台或几台服务主机（Master),然后还有N台（Slave）,那么我们的主机肯定要时时刻刻知道自己下面的从服务器的各种情况，然后进行实时监控的功能，这个在分布式架构里叫做心跳检测或心跳监控，最佳处理方案是使用一下通信框架进行实践如Netty]]></content>
      <categories>
        <category>Socket</category>
        <category>Socket-03</category>
      </categories>
      <tags>
        <tag>Socket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Socket网络编程第二篇]]></title>
    <url>%2F2018%2F02%2F24%2Fsocket-io-2%2F</url>
    <content type="text"><![CDATA[目录代码：https://github.com/dravinbox/SocketIO_02 1.Netty初步2.HelloWorld3.Netty核心技术之（TCP拆包和粘包问题）4.Netty核心技术之（编解码技术）5.Netty的UDP实现6.Netty的WebSocket实现 1.1 为什么选择Netty我们已经了解了Socket通信/IO/NIO/AIO编程，对于通信模型已经有了一个初步的认识。其实我们之前所学习的仅仅是一个模型，如果把这些真正的用于实际工作中去，那么还需要不断的完善，扩展和优化。比如很经典的TCP读包写包问题，或者是数据接收的大小，实际的通信读取与应答的处理逻辑等等一些细节问题需要我们认真的去思考，而这些我们都需要大量的时间和经历，以及丰富的经验。所以想学好socket通信不是件容易的事情，那么现在，我们就要学习一门新的技术Netty，我们为什么选择Netty，原因无他，简单！我们再也不必要去编写复杂的代码逻辑去实现通信，我们再也不需要去考虑性能问题，不需要考虑便解码问题，半包读写问题等，这些强大的Netty已经帮我们实现好了，我们只需要使用即可。 Netty是最流行的NIO框架，他的健壮性，功能，性能，可定制性和可扩展性在同类的框架都是首屈一指。它已经得到成千上万个商业/商用项目验证，如Hadoop的RPC框架Avro,以及我们之后学的JMS框架，强大的RocketMQ消息中间件，还有主流的分布式通信框架Dubbox等等。 1.4 Netty简介Netty是基于Java NIO 的网络应用框架Netty是一个NIO Client-Server(客户端服务器)框架，使用Netty 可以是快速开发网络应用，例如服务器和客户端协议。Netty提供了一种新的方式来开发网络应用程序，这种新的方式使得它很容易使用和很强的扩展性。Netty的内部实现是很复杂的，但是netty提供了简单易用的api从网络处理代码中解耦业务逻辑。Netty是完全基于NIO实现的，所以整个Netty都是异步的。网络应用程序通常要求较高的可扩展性，无论是Netty还是其他基于Java NIO 的框架，都会提供可扩展性的解决方案。Netty中一个关键的组成部分是它的异步特性，本章将讨论同步（阻塞）和异步（非阻塞）的IO来说明为什么使用异步代码来解决扩展性问题已经如何使用异步。 1.5 Netty架构组成 1.6 Netty特性 2.1 HelloworldNetty实现通信的步骤：1.创建两个NIO的线程组，一个专门用于网络事件处理（接收客户端的连接），另一个则进行网络通信读写。2.创建一个ServerBootstrap对象，配置Netty的一系列参数，例如接受传出的缓存大小等等。3.创建一个实际处理数据的类ChannelInitializer，进行初始化的准备工作，比如设置接受传出数据的字符集，格式，已经实际处理数据启动即可。4.绑定端口，执行同步阻塞方法等待服务器启动即可。 具体的Helloworld入门请查看：http://ifeve.com/netty5-user-guide/ 服务类DiscardServer.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package zry.netty.discard;import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelOption;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;public class DiscardServer &#123; private int port; public DiscardServer(int port)&#123; this.port=port; &#125; public void run() throws InterruptedException&#123; EventLoopGroup bossGroup=new NioEventLoopGroup(); EventLoopGroup workGroup=new NioEventLoopGroup(); try &#123; ServerBootstrap bootstrap= new ServerBootstrap(); bootstrap.group(bossGroup,workGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel sc) throws Exception &#123; sc.pipeline().addLast(new DiscardHandler()); &#125; &#125;) .option(ChannelOption.SO_BACKLOG, 128) .childOption(ChannelOption.SO_KEEPALIVE, true); ChannelFuture cf = bootstrap.bind(port).sync(); cf.channel().closeFuture().sync(); &#125; finally &#123; workGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) throws Exception&#123; int port=8765; new DiscardServer(port).run(); &#125;&#125; 服务端处理类DiscardHandler.java12345678910111213141516171819202122232425package zry.netty.discard;import io.netty.channel.ChannelHandlerAdapter;import io.netty.channel.ChannelHandlerContext;import io.netty.util.ReferenceCountUtil;public class DiscardHandler extends ChannelHandlerAdapter&#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123;// try &#123; ctx.write(msg); ctx.flush();// &#125; finally &#123;// ReferenceCountUtil.release(msg);// &#125; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 客户端Client.java12345678910111213141516171819202122232425262728293031323334353637383940414243package zry.netty.discard;import io.netty.bootstrap.Bootstrap;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelOption;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioSocketChannel;public class Client &#123; public static void main(String[] args) throws InterruptedException &#123; EventLoopGroup workGroup=new NioEventLoopGroup(); try &#123; Bootstrap bootstrap= new Bootstrap(); bootstrap.group(workGroup) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel sc) throws Exception &#123; sc.pipeline().addLast(new ClientHandler()); &#125; &#125;) .option(ChannelOption.SO_KEEPALIVE, true); ChannelFuture channelFuture=bootstrap.connect("127.0.0.1",8765).sync(); channelFuture.channel().write(Unpooled.copiedBuffer("hello,world".getBytes())); channelFuture.channel().flush(); channelFuture.channel().closeFuture().sync(); &#125; finally &#123; // TODO: handle finally clause workGroup.shutdownGracefully(); &#125; &#125;&#125; 客户端处理器ClientHandler.java123456789101112131415161718192021222324252627282930package zry.netty.discard;import io.netty.buffer.ByteBuf;import io.netty.channel.ChannelHandlerAdapter;import io.netty.channel.ChannelHandlerContext;import io.netty.util.ReferenceCountUtil;public class ClientHandler extends ChannelHandlerAdapter&#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; try &#123; ByteBuf b=(ByteBuf)msg; byte[] m=new byte[b.readableBytes()]; b.readBytes(m); String data_str=new String(m, "utf-8"); System.out.println("getFromServer: "+data_str); &#125; finally &#123; ReferenceCountUtil.release(msg); &#125; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 完成了一个hello程序。 3.1 TCP粘包，拆包问题我们发的一个完整的包可能会被TCP分成多个包进行发送，也可能把多个小包封装成一个大的数据包发送出去，这就是所谓的TCP粘包，拆包问题。 分析产生的原因： 1.应用程序write写入的字节大小 大于套接字口发送缓冲区的大小 2.进行MSS大小的TCP分段 3.以太帧的payload大于MTU进行IP分片 3.2 TCP粘包，拆包问题解决方案粘包拆包问题的解决方案，根据业界主流协议，的有三中方案：1.在包尾部添加特殊的字符进行分割，例如加回车等2.消息定长，例如每个报文的大小固定为200个字节，如果不够，空位补空格。3.将消息分为消息头和消息体，在消息头中包含表示消息总长度的字段，然后进行业务逻辑的处理 3.3 Netty如何解决粘包，拆包问题1.使用自定义分隔符类 DelimiterBasedFrameDecoder2.使用定长类 FixedLengthFrameDecoder 服务类：使用了分隔符类,定义了分隔符为$ ByteBuf buf = Unpooled.copiedBuffer(“$“.getBytes());使用分隔符类new DelimiterBasedFrameDecoder(1024, buf))并使用支付串解码类new StringDecoder() Server.java1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package bhz.netty.ende1;import java.nio.ByteBuffer;import io.netty.bootstrap.ServerBootstrap;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelOption;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;import io.netty.handler.codec.DelimiterBasedFrameDecoder;import io.netty.handler.codec.FixedLengthFrameDecoder;import io.netty.handler.codec.string.StringDecoder;import io.netty.handler.codec.string.StringEncoder;public class Server &#123; public static void main(String[] args) throws Exception&#123; //1 创建2个线程，一个是负责接收客户端的连接。一个是负责进行数据传输的 EventLoopGroup pGroup = new NioEventLoopGroup(); EventLoopGroup cGroup = new NioEventLoopGroup(); //2 创建服务器辅助类 ServerBootstrap b = new ServerBootstrap(); b.group(pGroup, cGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 1024) .option(ChannelOption.SO_SNDBUF, 32*1024) .option(ChannelOption.SO_RCVBUF, 32*1024) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel sc) throws Exception &#123; //设置特殊分隔符 ByteBuf buf = Unpooled.copiedBuffer("$_".getBytes()); sc.pipeline().addLast(new DelimiterBasedFrameDecoder(1024, buf)); //设置字符串形式的解码 sc.pipeline().addLast(new StringDecoder()); sc.pipeline().addLast(new ServerHandler()); &#125; &#125;); //4 绑定连接 ChannelFuture cf = b.bind(8765).sync(); //等待服务器监听端口关闭 cf.channel().closeFuture().sync(); pGroup.shutdownGracefully(); cGroup.shutdownGracefully(); &#125; &#125; 服务端处理器：直接转化msg为字符串，返回数据时也跟上$_结尾 ServerHandler.java123456789101112131415161718192021222324252627282930313233343536package bhz.netty.ende1;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelHandlerAdapter;import io.netty.channel.ChannelHandlerContext;public class ServerHandler extends ChannelHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(" server channel active... "); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; String request = (String)msg; System.out.println("Server :" + msg); String response = "服务器响应：" + msg + "$_"; ctx.writeAndFlush(Unpooled.copiedBuffer(response.getBytes())); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable t) throws Exception &#123; ctx.close(); &#125;&#125; 客户端：同样使用分隔符 Client.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package bhz.netty.ende1;import io.netty.bootstrap.Bootstrap;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioSocketChannel;import io.netty.handler.codec.DelimiterBasedFrameDecoder;import io.netty.handler.codec.FixedLengthFrameDecoder;import io.netty.handler.codec.string.StringDecoder;import io.netty.handler.codec.string.StringEncoder;public class Client &#123; public static void main(String[] args) throws Exception &#123; EventLoopGroup group = new NioEventLoopGroup(); Bootstrap b = new Bootstrap(); b.group(group) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel sc) throws Exception &#123; // ByteBuf buf = Unpooled.copiedBuffer("$_".getBytes()); sc.pipeline().addLast(new DelimiterBasedFrameDecoder(1024, buf)); sc.pipeline().addLast(new StringDecoder()); sc.pipeline().addLast(new ClientHandler()); &#125; &#125;); ChannelFuture cf = b.connect("127.0.0.1", 8765).sync(); cf.channel().writeAndFlush(Unpooled.wrappedBuffer("bbbb$_".getBytes())); cf.channel().writeAndFlush(Unpooled.wrappedBuffer("cccc$_".getBytes())); //等待客户端端口关闭 cf.channel().closeFuture().sync(); group.shutdownGracefully(); &#125;&#125; ClientHandler.java123456789101112131415161718192021222324252627282930313233package bhz.netty.ende1;import io.netty.channel.ChannelHandlerAdapter;import io.netty.channel.ChannelHandlerContext;import io.netty.util.ReferenceCountUtil;public class ClientHandler extends ChannelHandlerAdapter&#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("client channel active... "); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; try &#123; String response = (String)msg; System.out.println("Client: " + response); &#125; finally &#123; ReferenceCountUtil.release(msg); &#125; &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; ctx.close(); &#125;&#125; 4.1 Netty 编解码技术编解码技术，说白了就是java序列化技术，序列化的目的：1.进行网络传输 2.对象持久化 虽然我们可以使用java进行对象序列化，netty去传输，但是java序列化的硬伤太多，比如java序列化无法跨语言，序列化后码流太大，序列化性能太低等等。 主流的编解码框架： JBoss的Marshalling包 Google的Protobuf 基于Protobuf的Kyro MessagePack框架 4.2 JBoss Marshalling 序列化框架JBoss Marshalling是一个java对象序列化包，对JDK默认的序列化框架进行了优化，但保持跟java.io.Serializable接口的兼容，同是增加了一些可调的参数和附加特性。JBoss Marshalling与Netty结合后进行序列化对象的代码编写非常简单。]]></content>
      <categories>
        <category>Socket</category>
        <category>Socket-02</category>
      </categories>
      <tags>
        <tag>Socket</tag>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Socket网络编程第一篇]]></title>
    <url>%2F2018%2F02%2F24%2Fsocket-io%2F</url>
    <content type="text"><![CDATA[目录代码：https://github.com/dravinbox/SocketIO_01 1.学习基本概念，传统的同步阻塞式I/O编程,伪异步IO实现2.学习基于NIO的同步非阻塞式编程3.了解NIO2.0(jdk1.7以后)的异步非阻塞式(AIO)编程 1.1 基本概念Socket 又称套接字，应用程序通常通过“套接字”向网络发出请求或应答网络请求。套接字之间的连接过程可以分为四个步骤：（1）服务器监听：等待连接的状态，实时监控网络状态（2）客户端请求服务器：客户端的套接字提出连接请求，要连接的目标是服务器的套接字，为此，客户端的套接字必须首先描述他要连接的服务器的套接字，指出服务器套接字的地址和端口号，然后向服务器套接字提出连续的请求。（3）服务器确认：当服务器套接字监听到或者说接受到客户端套接字的连接请求，他就会响应客户端套接字的请求，建立一个新的线程，把服务器套接字的描述发给客户端。（4）客户端确认：一点客户端确认该描述，连接就建立好了，双方开始进行通信，而服务器套接字继续处于监听的状态，继续接受其他客户端套接字的连接请求。进行通信 1.2 概念IO(BIO)和NIO的区别：其本质就是阻塞和非阻塞的区别 阻塞概念：应用程序再获取网络数据的时候，如果网络传输的数据很慢，那么程序就一直等待，直到传输完毕为止。 非阻塞概念：应用程序直接可以获取已经准备就绪好的数据，无需等待BIO为同步阻塞形式，NIO为同步非阻塞形式，NIO并没有实现异步，再JDK1.7之后，升级了NIO库包，支持异步非阻塞通信模型即NIO2.0（AIO） 同步和异步：同步和异步一般是面向操作系统与应用程序对IO操作的层面上来区别的。 同步：应用程序会直接参与IO读写操作，并且我们的应用程序会直接阻塞到某一个方法上，直到数据准备就绪；或者采用轮询的策略实时检查数据的就绪状态，如果就绪则获取数据。 异步：所有的IO读写操作交给操作系统处理，与我们的应用程序没有直接关系，我们程序不需要关心IO读写，当操作系统完成了IO读写操作时，会给我们应用程序发送通知，我们的应用程序直接拿走数据即可。 同步是说你的server服务端的执行方式阻塞是说具体的技术，接受数据的方式，状态（IO,NIO) 1.3 传统的BIO编程（com.bjsxt.bio）网络编程的基本模型是Client/Server模型，也就是两个进程直接进行相互通信，其中服务端提供配置信息（绑定的ip地址和监听端口），客户端通过连接操作向服务端监听地址发起连接请求，通过3次的握手建立连接，如果连接成功，则双方既可以进行通信 1.4 伪异步IO采用线程池和任务队列可以实现一种伪异步的IO通信框架。就是将客户端的socket封装城一个task任务（实现runnable接口的类）然后投递到线程池中，配置相应的队列进行实现。 2.1 NIO编程介绍学习NIO编程，首先了解几个概念：Buffer（缓冲区），Channel(管道，通道)，Selector（选择器，多路复用器） 服务器运行的是ServerSocketChannel，客户端运行的是SocketChannel，可以理解为是对Socket的封装，数据呢就存在Buffer缓冲区里，而不是直接的InputStream和OutputStream的直接方式。 客户端的通道需要注册在服务端里的Selector里，Selector就会轮询所有注册的通道，根据通道的状态，来执行相关的操作。这里有4种通道状态，连接状态Connect，阻塞状态Accept，可读状态Read，可写状态Write。 2.2 BufferBuffer 是一个对象，它包含一些要写入或者读取的数据，在NIO类库中加入Buffer对象，体现新库与原IO的一个重要的区别。在面向流的IO中，可以将数据直接写入或者读取到Stream对象中，在NIO库中，所有数据都是用缓冲区处理的（读写）。缓冲区实质是一个数组，通常它是一个字节数组（ByteBuffer），也可以使用其他类型的数组。这个数组为缓冲区提供了数据的访问读写等操作属性，如位置，容量，上限等概念。参考api文档。Buffer类型：我们最常用的就是ByteBuffer，实际上每一种java基本类型都对应了一种缓存区（除了Boolean类型）ByteBufferCharBufferShorBufferIntBufferLongBufferFloatBufferDoubleBuffer 2.3 Channel通道（Channel），他就像自来水管道一样，网络数据通过Channel读取和写入，通道与流不同之处在于管道是双向的，而流只是一个方向上的移动（一个流必须是InputSteam或者OutputStream的子类），而管道可以用于读/写或者二者同时进行，最关键的是可以与多路复用器结合起来，有多种的状态位，方便多路复用器去识别。事实上通道分为两大类，一类是网络读写的（SelectableChannel),一类是用于文件操作(FileChannel),我们使用的是SocketChannel和ServerSockerChannel都是SelectableChannel的子类。 2.4 Selector(一)多路复用器（selector），他是NIO编程的基础，非常重要，多路复用器提供选择已经就绪的任务的能力。简单来说，就是Selector会不断地轮询注册在其上的通道（Channel），如果某个通道发生了读写操作，这个通道就处于就绪状态，会被Selector轮询出来，然后通过SelectionKey可以取得就绪的Channel集合，从而进行后续的IO操作。一个多路复用器可以复杂成千上万Channel通道，没有上限，这也是JDK使用epoll替代传统的select实现，获得连接句柄没有限制，这也就意味着我们只要一个线程Selector的轮询，就可以接入成千上万个客户端，这个是JDK NIO的巨大进步。 2.5 Selector(二)Selector线程类似一个管理者（Master），管理成千上万的个管道，然后轮询哪一个管道的数据已经准备好，通知Cpu值执行IO的读取获取写入操作。 每个管道都会对选择器进行注册不用的时间状态，以便选择器查找。SelectionKey.OP_CONNECTSelectionKey.OP_ACCEPTSelectionKey.OP_READSelectionKey.OP_WRITE 3.1 AIOAIO编程，在NIO基础之上引入了异步通道的该你那，并提供了异步文件和异步套接字通道的实现，从而在真正意义上实现了异步非阻塞，之前我们学习的NIO只是非阻塞而并非异步。而AIO它不需要通过多路复用器对注册的通道进行轮询操作即可实现异步读写。从而简化了NIO编程模型。也可以称之为NIO2.0，这种模型才可以真正的属于我们异步非阻塞的模型.AsynchronousServerSocketChannelAsynchronousSocketChannel AIO隐藏了对Channel的操作，只需定义一个线程缓存池，重写好handler的接口函数即可。每一个客户端连接都会递归调用服务器的accept方法，保证一个客户端可以连接上来。 Server.java12345678910111213141516171819202122232425262728293031323334353637383940414243package bhz.aio;import java.net.InetSocketAddress;import java.nio.channels.AsynchronousChannelGroup;import java.nio.channels.AsynchronousServerSocketChannel;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class Server &#123; //线程池 private ExecutorService executorService; //线程组 private AsynchronousChannelGroup threadGroup; //服务器通道 public AsynchronousServerSocketChannel assc; public Server(int port)&#123; try &#123; //创建一个缓存池 executorService = Executors.newCachedThreadPool(); //创建线程组 threadGroup = AsynchronousChannelGroup.withCachedThreadPool(executorService, 1); //创建服务器通道 assc = AsynchronousServerSocketChannel.open(threadGroup); //进行绑定 assc.bind(new InetSocketAddress(port)); System.out.println("server start , port : " + port); //进行阻塞 assc.accept(this, new ServerCompletionHandler()); //一直阻塞 不让服务器停止 Thread.sleep(Integer.MAX_VALUE); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; Server server = new Server(8765); &#125; &#125; ServerCompletionHandler.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package bhz.aio;import java.nio.ByteBuffer;import java.nio.channels.AsynchronousSocketChannel;import java.nio.channels.CompletionHandler;import java.util.concurrent.ExecutionException;public class ServerCompletionHandler implements CompletionHandler&lt;AsynchronousSocketChannel, Server&gt; &#123; @Override public void completed(AsynchronousSocketChannel asc, Server attachment) &#123; //当有下一个客户端接入的时候 直接调用Server的accept方法，这样反复执行下去，保证多个客户端都可以阻塞 attachment.assc.accept(attachment, this); read(asc); &#125; private void read(final AsynchronousSocketChannel asc) &#123; //读取数据 ByteBuffer buf = ByteBuffer.allocate(1024); asc.read(buf, buf, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer resultSize, ByteBuffer attachment) &#123; //进行读取之后,重置标识位 attachment.flip(); //获得读取的字节数 System.out.println("Server -&gt; " + "收到客户端的数据长度为:" + resultSize); //获取读取的数据 String resultData = new String(attachment.array()).trim(); System.out.println("Server -&gt; " + "收到客户端的数据信息为:" + resultData); String response = "服务器响应, 收到了客户端发来的数据: " + resultData; write(asc, response); &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; exc.printStackTrace(); &#125; &#125;); &#125; private void write(AsynchronousSocketChannel asc, String response) &#123; try &#123; ByteBuffer buf = ByteBuffer.allocate(1024); buf.put(response.getBytes()); buf.flip(); asc.write(buf).get(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void failed(Throwable exc, Server attachment) &#123; exc.printStackTrace(); &#125;&#125; Client.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package bhz.aio;import java.io.UnsupportedEncodingException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.AsynchronousSocketChannel;import java.util.concurrent.ExecutionException;public class Client implements Runnable&#123; private AsynchronousSocketChannel asc ; public Client() throws Exception &#123; asc = AsynchronousSocketChannel.open(); &#125; public void connect()&#123; asc.connect(new InetSocketAddress("127.0.0.1", 8765)); &#125; public void write(String request)&#123; try &#123; asc.write(ByteBuffer.wrap(request.getBytes())).get(); read(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; private void read() &#123; ByteBuffer buf = ByteBuffer.allocate(1024); try &#123; asc.read(buf).get(); buf.flip(); byte[] respByte = new byte[buf.remaining()]; buf.get(respByte); System.out.println(new String(respByte,"utf-8").trim()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; while(true)&#123; &#125; &#125; public static void main(String[] args) throws Exception &#123; Client c1 = new Client(); c1.connect(); Client c2 = new Client(); c2.connect(); Client c3 = new Client(); c3.connect(); new Thread(c1, "c1").start(); new Thread(c2, "c2").start(); new Thread(c3, "c3").start(); Thread.sleep(1000); c1.write("c1 aaa"); c2.write("c2 bbbb"); c3.write("c3 ccccc"); &#125; &#125;]]></content>
      <categories>
        <category>Socket</category>
        <category>Socket-01</category>
      </categories>
      <tags>
        <tag>Socket</tag>
        <tag>BIO</tag>
        <tag>NIO</tag>
        <tag>AIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMvc实现RESTful风格]]></title>
    <url>%2F2018%2F01%2F31%2Frestful%2F</url>
    <content type="text"><![CDATA[RESTful 什么是RESTful-符合REST约束风格和原则的应用程序或设计就是RESTful. 1234567eg: /emp/1 HTTP GET 查询id=1的emp /emp/1 HTTP DELETE 删除id=1的emp,实验中直接删除会报405错误，但是采用$.ajax异步删除就没问题 /emp/1 HTTP PUT 跟新emp /emp/add HTTP POST 新增emp Spring对RESTful的支持 Spring MVC 对 RESTful应用提供了以下支持 利用@RequestMapping 指定要处理请求的URI模板和HTTP请求的动作类型 利用@PathVariable讲URI请求模板中的变量映射到处理方法参数上 利用Ajax,在客户端发出PUT、DELETE动作的请求 123@RequestMapping(value = "/&#123;id&#125;", method = RequestMethod.GET) public String toUpdate(@PathVariable("id") Integer id, Model model) &#123;&#125; RequestMapping的一般应用格式@RequestMapping(value = “/{id}”, method = RequestMethod.GET) @RequestMapping(value = “/{id}”, method = RequestMethod.POST) @RequestMapping(value = “/{id}”, method = RequestMethod.DELETE) // 因为这个需要Ajax请求，所有返回的是个json @ResponseBody @RequestMapping(value = “/{id}”, method = RequestMethod.PUT) 客户端发送PUT，DELETE请求 , 可以采用Ajax方式发送PUT和DELETE请求123456789$.ajax( &#123; type : "DELETE", url : "/spring_crud_restful/emp/deleteEmp/" + id, dataType : "json", success : function(data) &#123; alert(data); location.href = "/spring_crud_restful/emp/listEmp/1"; &#125; &#125;); 静态资源访问处理采用RESTful架构后，需要将web.xml中控制器拦截的请求设置为/，这样会将css,js等静态资源进行拦截，发送404错误。 解决方法： –配置123&lt;mvc:resources/&gt; &lt;mvc:resources mapping=&quot;请求URI&quot; location=&quot;资源位置&quot; /&gt; –配置123&lt;mvc:default-servlet-handler/&gt; &lt;mvc:default-servlet-handler/&gt;]]></content>
      <categories>
        <category>Spring</category>
        <category>SpringMvc</category>
      </categories>
      <tags>
        <tag>RESTful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信支付-服务商下的公众号支付]]></title>
    <url>%2F2018%2F01%2F20%2Fweixin-subapp-pay%2F</url>
    <content type="text"><![CDATA[服务商下的公众号支付在服务商模式下，必须传本公众号和用户的openid 给服务商来生成jsapi支付参数。最近有个坑，前端怎么调都是没法支付，只是转一下就没了。最后发现是服务商那里没有配置该子商户的公众号支付的域名：登陆服务商的微信商户后台，找到该子商户，点击配置，添加一个域名。 单例页面的微信支付之前一直都是 http://xxxx/#/paypage改为http://xxxx/#/pay/paypage 就可以 也就是说如果是单例页面如vue ,就微信后台后台配置http://xxxx/#/pay/这里就是要求支付必须在2级目录里，paypage.vue得放在pay目录里。]]></content>
      <categories>
        <category>微信支付</category>
        <category>服务商下</category>
        <category>公众号支付</category>
      </categories>
      <tags>
        <tag>微信支付</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信网页授权]]></title>
    <url>%2F2018%2F01%2F18%2Fweixin-auth%2F</url>
    <content type="text"><![CDATA[微信网页授权最近做前后台分离，发现微信授权登陆做的很烦。域名跳来跳去的，跳晕了。微信的网页授权文档传送门 微信官方给出的步骤:1 第一步：用户同意授权，获取code 2 第二步：通过code换取网页授权access_token 3 第三步：刷新access_token（如果需要） 4 第四步：拉取用户信息(需scope为 snsapi_userinfo) 5 附：检验授权凭证（access_token）是否有效 实践思考前端判断用户的cookie为空，并且是微信浏览器，就跳转到长链接： 1https://open.weixin.qq.com/connect/oauth2/authorize?appid=公众号APPID&amp;redirect_uri=后台地址&amp;response_type=code&amp;scope=SCOPE&amp;state=前端拼接的随机字符串#wechat_redirect 用户的体验是：他打开了前端的一个网页，然后跳转到open.weixin.qq.com的网页，然后又杯重定向到后台的一个地址。最后，后台获取用户信息后，又重定向到前端的某一个页面。 我门可以思考一个这样的场景，你的朋友分享了一个商城的商品详情页面给你。你打开之后，有了以上的跳转体验，是不是很晕，但是用户用微信浏览器打开的时候是看不到地址的变化，只看到上面有一个绿色的进度条，加载了又加载了…。我们要的效果就是，用户打开这个商品详情页面就静默授权，然后回跳到该页面。 实现前端的实现： 前端在跳转前，使用cookie保存当前的请求的地址ori_path，还要保存一个md5(时间+随机数) 的值md5_str，拼到长链接里。 1https://open.weixin.qq.com/connect/oauth2/authorize?appid=公众号APPID&amp;redirect_uri=后台地址&amp;response_type=code&amp;scope=SCOPE&amp;state=md5_str#wechat_redirect 拼好后，跳转！ -》微信官方-》后台-》前端某一个具体的地址/auth 这时候，前端在/auth的页面里，cookie拿出md5_str,去异步请求后台获取用户数据，再拿出之前存的地址ori_path去跳转。 后台的实现： 做一个controller,接受微信官方的请求，微信会带来code 和state (md5_str)拿到code就可以拿到用户信息，具体查看微信公众号文档传送门,然后，用户数据和state(md5_str)保存起来 再做一个controller，接受前端发来的md5_str,去拿用户数据]]></content>
      <categories>
        <category>微信公众号</category>
        <category>网页授权</category>
      </categories>
      <tags>
        <tag>微信公众号</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信公众号支付]]></title>
    <url>%2F2018%2F01%2F18%2Fweixin-mppay%2F</url>
    <content type="text"><![CDATA[微信公众号支付如果是服务商下的公众号发起公众号支付，必须有以下参数用户在子公众号下的openid 开发者调试的时候找不到子公众号的openid1.开发者先关注该服务商下的被服务的公众号（这里叫子公众号）2.在子公众号里的用户管理下，新建一个标签“开发”,把开发人员拉进去3.在线上调试工具先获取access_token,4.在微信文档-标签,先调用获取公众号已创建的标签，再调用获取标签下粉丝列表5.如果你想查询一下该openid的具体用户信息，请调用微信文档-用户信息里的获取用户基本信息]]></content>
      <categories>
        <category>微信支付</category>
        <category>公众号支付</category>
      </categories>
      <tags>
        <tag>微信支付</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql中delete语句使用别名]]></title>
    <url>%2F2018%2F01%2F17%2Fmysql-delete%2F</url>
    <content type="text"><![CDATA[delete语法中使用别名问题1delete from a_table A where A.name = '123'; 但是有一个错误 1You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 解决方法在delete 与from之间加上一个别名 1delete A from a_table A where A.name = '123'; 删除成功!]]></content>
      <categories>
        <category>mysql</category>
        <category>delete</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx反向代理tomcat]]></title>
    <url>%2F2018%2F01%2F16%2Fnginx-proxy%2F</url>
    <content type="text"><![CDATA[反向代理tomcat并提供web服务定义了两个server每个server指定一个域名dev.mall.com指向一个web应用api.mall.com反向代理到8080端口tomcat上 123456789101112131415161718192021222324252627server&#123; listen 80; server_name dev.mall.com; access_log /www/wwwlogs/mall-acess_log; location / &#123; root /www/wwwroot/mall; &#125;&#125;server&#123; listen 80; server_name api.mall.com; access_log /www/wwwlogs/mall-api-acess_log; location / &#123; proxy_pass http://127.0.0.1:8080; proxy_read_timeout 300; proxy_connect_timeout 300; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125;]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven nexus 私库配置]]></title>
    <url>%2F2018%2F01%2F15%2Fmaven-nexus%2F</url>
    <content type="text"><![CDATA[nexus的配置使用docker 安装nexus 1docker run -d -p 32770:8081 --name nexus sonatype/nexus 1.访问http://localhost:32770/nexus2.在节点增加一个用户 setting.xml12345&lt;server&gt; &lt;id&gt;rrg&lt;/id&gt; &lt;username&gt;rrg&lt;/username&gt; &lt;password&gt;rrg88888&lt;/password&gt;&lt;/server&gt; 3.修改central为阿里云的代理4.修改setting文件，包括mirro 和profile setting.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;!--mirrors节点添加如下：--&gt; &lt;mirror&gt; &lt;id&gt;local-nexus3&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;local maven3&lt;/name&gt; &lt;url&gt;http://localhost:32770/nexus/content/groups/public/&lt;/url&gt; &lt;/mirror&gt; &lt;!--profiles节点添加如下：--&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;local-maven-main-repository&lt;/name&gt; &lt;url&gt;http://localhost:32770/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;local-maven-plugin-repository&lt;/name&gt; &lt;url&gt;http://localhost:32770/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt;&lt;!-- 最后激活 --&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;dev&lt;/activeProfile&gt; &lt;/activeProfiles&gt; 5.发布与部署6.使用7.发布第3方包]]></content>
      <categories>
        <category>maven</category>
        <category>nexus</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>nexus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-gui]]></title>
    <url>%2F2017%2F12%2F25%2Fdocker-gui%2F</url>
    <content type="text"><![CDATA[在Mac上使用Docker运行GUI应用程序firefoxvscode 需要准备的东西： osx系统 docker for mac XQartz 2.7.11 一位国外的美女大神写的Dockerfile osx系统没有就不用看下去docker for mac 自行安装XQuartz使用brew 安装 1brew cask install xquartz 关于Quartz的最新版，可以前往XQuartz官网 运行起来！使用我们本机的终端来打开XQuartz 1open -a XQuartz 我们就运行起来了xquartz的终端，我们打开它的偏好设置 把这个钩上，然后重启XQuartz就生效。 我们在XQuartz的终端输入一下命令,来允许你本机的连接: 12ip=$(ifconfig en0 | grep inet | awk '$1=="inet" &#123;print $2&#125;')xhost + $ip 设置好之后，我们就可以运行一下Jessie大神做的Firefox镜像，她写的dockerfile在这 firefox: 1docker run -d --name firefox -e DISPLAY=$ip:0 -v /tmp/.X11-unix:/tmp/.X11-unix jess/firefox vscode: 1docker run -v /etc/localtime:/etc/localtime:ro -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=$ip:0 --name vscode jess/vscode chrome(记得加上–privileged):因为Chrome使用的是沙盒，因此运行一个没权限的沙盒将等到一个错误：Failed to move to new namespace: PID namespaces supported, Network namespace supported, but failed: errno = Operation not permitted使用--privileged可以给容器赋予权限去访问主机的资源，就如主机的进程那样访问主机的资源。 1docker run -d -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=$ip:0 -v ~/Downloads:/root/Downloads --privileged --name chrome jess/chrome Merry Christmas]]></content>
      <categories>
        <category>Docker</category>
        <category>部署例子</category>
        <category>运行GUI应用程序</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>GUI</tag>
        <tag>FireFox</tag>
        <tag>VSCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在docker里运行Jenkins]]></title>
    <url>%2F2017%2F12%2F23%2Fdocker-jenkins%2F</url>
    <content type="text"><![CDATA[Jenkins123#注意/your/home 替换成你创建的目录，保证容器有访问权限docker run -d -p 12821:8080 -p 50000:50000 -v /your/home:/var/jenkins_home --name jenkins jenkins/jenkins5cc5e09fdea5e9296bd26095b90f770b0d05213d80299d44dd3984db14bdbd85 然后登陆到容器里获取初始化密码: 1234567docker exec -it 5cc5e09fdea5 bash#使用cat 命令查看密码jenkins@5cc5e09fdea5:/$ cat /var/jenkins_home/secrets/initialAdminPassword#然后出来这个密码44fcdb88xxxxxxxxxxx6a2d00c2d 把上面的密码复制到浏览器里http://localhost:12821 里需要密码的地方:]]></content>
      <categories>
        <category>Docker</category>
        <category>部署例子</category>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门-part5-Stacks]]></title>
    <url>%2F2017%2F12%2F22%2Fdocker-part5%2F</url>
    <content type="text"><![CDATA[Stacks前言本Docker入门系列文章是翻译于Docker官方getStarted文档,如有出入，请跳转查看官方文档 简单介绍 A stack is a group of interrelated services that share dependencies, and can be orchestrated and scaled together. 可以理解一个堆里有多个服务，服务之间相互协作。有一些复杂的应用，它可能需要多个堆。 添加一个新的服务并且部署它1.我们打开之前的docker-compose.yml文件，使用下面的代码覆盖它。记得替换那里username/repo:tag 对应的远程库镜像值。 123456789101112131415161718192021222324252627282930version: "3"services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 restart_policy: condition: on-failure resources: limits: cpus: "0.1" memory: 50M ports: - "80:80" networks: - webnet visualizer: image: dockersamples/visualizer:stable ports: - "8080:8080" volumes: - "/var/run/docker.sock:/var/run/docker.sock" deploy: placement: constraints: [node.role == manager] networks: - webnetnetworks: webnet: 我们可以看到上面的代码里，多了一个服务：visualizer。并且看到一个新的关键字volumes ,它给visualizer容器权限，能访问宿主机的socket文件。还有一个新的关键字placement,定义这个服务只能在swarm manager上运行，不能在worker上。因为这个容器是用来展示Docker的各种服务在一个图表里，它由Docker开发的并且开源。 2.设置你的shell连接上myvm1 ，上部分已经讲过： docker-machine ls docker-machine env myvm1 eval $(docker-machine env myvm1) 3.在manager节点上再次运行docker stack deploy,如下： 1docker stack deploy -c docker-compose.yml getstartedlab 4.我们来看看visualizer先使用docker-machine ls查看各个节点的ip,然后你用浏览访问任何一个ip的8080端口，就可以看到图像化界面，显示各种服务在不同的机器上运行。 我们可以看到,visualizer只运行在manager节点上。 可以使用docker stack ps getstartedlab查看该堆所有服务的任务。 持久化数据让我们添加一个Redis 数据库 用来存储数据 1.我们打开之前的docker-compose.yml文件，使用下面的代码覆盖它。记得替换那里username/repo:tag 对应的远程库镜像值。 123456789101112131415161718192021222324252627282930313233343536373839404142version: "3"services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 restart_policy: condition: on-failure resources: limits: cpus: "0.1" memory: 50M ports: - "80:80" networks: - webnet visualizer: image: dockersamples/visualizer:stable ports: - "8080:8080" volumes: - "/var/run/docker.sock:/var/run/docker.sock" deploy: placement: constraints: [node.role == manager] networks: - webnet redis: image: redis ports: - "6379:6379" volumes: - /home/docker/data:/data deploy: placement: constraints: [node.role == manager] command: redis-server --appendonly yes networks: - webnetnetworks: webnet: 2.在manager机器上（即myvm1）,创建一个目录：./data 1docker-machine ssh myvm1 "mkdir ./data" 这里注意几点: redis 的远程镜像就是很短：”redis”,不用质疑 redis容器对外服务端口依然是6379,方便其他服务获取。 redis的volumes 的/home/docker/data目录是myvm1的目录，因为下面定义了它只能部署在manager上，所以我们使用docker-machine ssh myvm1 &quot;mkdir ./data&quot; 创建一个/home/docker/data目录。然后冒号后边的/data是redis容器里的路径，这里是redis的工作路径，我们不用管。 3.保证你的shell连接上myvm1 ,前面讲过 4.重新部署,再次执行： 1docker stack deploy -c docker-compose.yml getstartedlab 5.查看服务： 1docker service ls 6.访问你的一个节点机器 http://192.168.99.101 ,我们可以看到Visits在递增，那是因为我们的数据存在Redis上了。我们继续看看http://192.168.99.101:8080]]></content>
      <categories>
        <category>Docker</category>
        <category>Docker入门</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门-part4-Swarms]]></title>
    <url>%2F2017%2F12%2F22%2Fdocker-part4%2F</url>
    <content type="text"><![CDATA[Swarms前言本Docker入门系列文章是翻译于Docker官方getStarted文档,如有出入，请跳转查看官方文档 简单介绍 Here in part 4, you deploy this application onto a cluster, running it on multiple machines. Multi-container, multi-machine applications are made possible by joining multiple machines into a “Dockerized” cluster called a swarm. 可以理解swarm 是一个种多宿主机器，多容器组成的机器群体。 你可以通过 Swarm manager来控制这种多容器，多机器组成的集群。这里的机器可以是真实的也可以是虚拟的。一旦加入了swarm ，就称为一个节点node。 建立你的swarm在你的机器上执行docker swarm init去启动swarm 模式，且成为swarm manager。使用其他的机器执行docker swarm join加入刚刚的swarm 群里成为worker。这里 我们使用虚拟机模拟一个由两台机器组成的集群。 创建cluster MAC, LINUX 先在宿主机上安装VirtualBox 使用docker-machine 命令，和VirtualBox的驱动： 12docker-machine create --driver virtualbox myvm1docker-machine create --driver virtualbox myvm2 使用以下命令获得机器列表和他们的ip 12345$docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmyvm1 - virtualbox Running tcp://192.168.99.100:2376 v17.11.0-ce myvm2 - virtualbox Running tcp://192.168.99.101:2376 v17.11.0-ce 初始化swarm 和添加节点 我们让myvm1成为manger,myvm2成为worker可以使用docker-machine ssh向 myvm1 发送docker swarm init命令格式是docker-machine ssh myvm1 &quot;docker swarm init --advertise-addr &lt;myvm1 ip&gt;&quot; 12345678 $ docker-machine ssh myvm1 "docker swarm init --advertise-addr 192.168.99.100"Swarm initialized: current node (qkxdnhw56ibpdwqt22jpvxtj6) is now a manager.To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-547x8uwxy9kjkf31c46q9bx74jb92v16y2ruoo6aabvv5rhq1r-36qjytbfe7i3dxu8tdp9fyfnr 192.168.99.100:2377To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions. 同样地，我们向myvm2发送命令加入swarm,格式是： 123docker-machine ssh myvm2 "docker swarm join \--token &lt;token&gt; \&lt;ip&gt;:2377" 123$ docker-machine ssh myvm2 "docker swarm join --token SWMTKN-1-547x8uwxy9kjkf31c46q9bx74jb92v16y2ruoo6aabvv5rhq1r-36qjytbfe7i3dxu8tdp9fyfnr 192.168.99.100:2377"This node joined a swarm as a worker. 恭喜，你成功建立你的第一个swarm执行docker node ls 查看你的swarm中的各种节点: 12345$ docker-machine ssh myvm1 "docker node ls"ID HOSTNAME STATUS AVAILABILITY MANAGER STATUSqkxdnhw56ibpdwqt22jpvxtj6 * myvm1 Ready Active Leaderplax8po1p26hs67f693yqm5c7 myvm2 Ready Active 在你的swarm 集群部署你的APP上面艰难的步骤已经完了，接下来就简单了，重复Part3的步骤来部署在你新的swarm上，你只要记住，你的myvm1是管理者，只用来执行命令的，worker节点只是容纳过来的。他们都可以工作。 配置你的shell给swarm manager（可以理解为登陆到某个节点，不需要每次都docker-machine ssh） 这里提供mac / Linux的方法 1234567$ docker-machine env myvm1export DOCKER_TLS_VERIFY="1"export DOCKER_HOST="tcp://192.168.99.100:2376"export DOCKER_CERT_PATH="/Users/sam/.docker/machine/machines/myvm1"export DOCKER_MACHINE_NAME="myvm1"# Run this command to configure your shell:# eval $(docker-machine env myvm1) 然后运行 1eval $(docker-machine env myvm1) 现在你的shell已经登陆到myvm1上了，可以使用docker-machine ls 查看myvm1 的ACTIVE端是不是有个*号，表示你的shell登陆上这台机器 1234$ docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmyvm1 * virtualbox Running tcp://192.168.99.100:2376 v17.11.0-ce myvm2 - virtualbox Running tcp://192.168.99.101:2376 v17.11.0-ce 在swarm manager机器上部署你的APP虽然你现在的shell已经登陆上myvm1 了，但是还是可以访问本机的文件，这里我们部署app就需要之前写的docker-compose.yml文件。我们使用以下命令： 1$docker stack deploy -c docker-compose.yml getstartedlab 我们成功部署了APP，在这个集群上。使用以下查看详细的部署： 12345678910$ docker stack ps getstartedlabID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSl546oo0pmewz getstartedlab_web.1 dk5664280/get-started:part2 myvm1 Running Preparing 25 seconds ago vdym3ibcbhku getstartedlab_web.2 dk5664280/get-started:part2 myvm2 Running Preparing 25 seconds ago x4gx5wzj7pp6 getstartedlab_web.3 dk5664280/get-started:part2 myvm2 Running Preparing 25 seconds ago imw4urn7oo9d getstartedlab_web.4 dk5664280/get-started:part2 myvm1 Running Preparing 26 seconds ago ios5s8yejbhj getstartedlab_web.5 dk5664280/get-started:part2 myvm2 Running Preparing 25 seconds ago vhkwaz09n4q8 getstartedlab_web.6 dk5664280/get-started:part2 myvm1 Running Preparing 25 seconds ago qybf5fd0ueij getstartedlab_web.7 dk5664280/get-started:part2 myvm2 Running Preparing 25 seconds ago 看到了，我们的app在补同的机器myvm1和myvm2上部署，它们组成了一个集群. 访问我们的集群你可以访问myvm1或myvm2,例如 http://192.168.99.100:4000或http://192.168.99.101:4000 ,你都可以得到返回结果，并且每次结果不一样，因为它们使用了swarm的一个负载均衡器。 重新调配你的app你可以修改你的docker-compose.yml,然后再运行 1docker stack deploy -c docker-compose.yml getstartedlab 清除和重启stacks 和swarms清除 stacks:docker stack rm getstartedlab 我们先不敢掉swarms,因为下一个Part 5,我们还用先保留以下。 如果你真想敢掉swarms,执行docker-machine ssh myvm2 &quot;docker swarm leave这样能使work机里开该swarm集群，docker-machine ssh myvm1 &quot;docker swarm leave --force 能使manager离开swarm 关掉所有机器执行下面的命令停止所有的机器： 1$docker-machine stop $(docker-machine ls -q) 清除shell配置1eval $(docker-machine env -u) 这样就可以中断连接虚拟机了。可以使用docker-machine ls查看，已经没有ACTIVE的机器了。 启动机器使用下面的代码启动机器 1docker-machine start &lt;machine-name&gt; socker是我打错了，ctrl+c 中断了该命令 总结123456789101112131415161718192021docker-machine create --driver virtualbox myvm1 # Create a VM (Mac, Win7, Linux)docker-machine create -d hyperv --hyperv-virtual-switch "myswitch" myvm1 # Win10docker-machine env myvm1 # View basic information about your nodedocker-machine ssh myvm1 "docker node ls" # List the nodes in your swarmdocker-machine ssh myvm1 "docker node inspect &lt;node ID&gt;" # Inspect a nodedocker-machine ssh myvm1 "docker swarm join-token -q worker" # View join tokendocker-machine ssh myvm1 # Open an SSH session with the VM; type "exit" to enddocker node ls # View nodes in swarm (while logged on to manager)docker-machine ssh myvm2 "docker swarm leave" # Make the worker leave the swarmdocker-machine ssh myvm1 "docker swarm leave -f" # Make master leave, kill swarmdocker-machine ls # list VMs, asterisk shows which VM this shell is talking todocker-machine start myvm1 # Start a VM that is currently not runningdocker-machine env myvm1 # show environment variables and command for myvm1eval $(docker-machine env myvm1) # Mac command to connect shell to myvm1&amp; "C:\Program Files\Docker\Docker\Resources\bin\docker-machine.exe" env myvm1 | Invoke-Expression # Windows command to connect shell to myvm1docker stack deploy -c &lt;file&gt; &lt;app&gt; # Deploy an app; command shell must be set to talk to manager (myvm1), uses local Compose filedocker-machine scp docker-compose.yml myvm1:~ # Copy file to node's home dir (only required if you use ssh to connect to manager and deploy the app)docker-machine ssh myvm1 "docker stack deploy -c &lt;file&gt; &lt;app&gt;" # Deploy an app using ssh (you must have first copied the Compose file to myvm1)eval $(docker-machine env -u) # Disconnect shell from VMs, use native dockerdocker-machine stop $(docker-machine ls -q) # Stop all running VMsdocker-machine rm $(docker-machine ls -q) # Delete all VMs and their disk images]]></content>
      <categories>
        <category>Docker</category>
        <category>Docker入门</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门-part3-Services]]></title>
    <url>%2F2017%2F12%2F22%2Fdocker-part3%2F</url>
    <content type="text"><![CDATA[关于服务 About services前言本Docker入门系列文章是翻译于Docker官方getStarted文档,如有出入，请跳转查看官方文档 简单介绍 In a distributed application, different pieces of the app are called “services.” For example, if you imagine a video sharing site, it probably includes a service for storing application data in a database, a service for video transcoding in the background after a user uploads something, a service for the front-end, and so on.Services are really just “containers in production.” A service only runs one image, but it codifies the way that image runs—what ports it should use, how many replicas of the container should run so the service has the capacity it needs, and so on. Scaling a service changes the number of container instances running that piece of software, assigning more computing resources to the service in the process.Luckily it’s very easy to define, run, and scale services with the Docker platform – just write a docker-compose.yml file. 可以理解为，服务包含多个容器。一个服务通过docker-compose.yml创建，里面定义了多个容器的行为，资源消耗等问题。 编写你的 docker-compose.yml 文件这个文件定义了容器的行为 docker-compose.yml文件在你喜欢的目录下，创建 一个文件叫docker-compose.yml，使用你之前在Part 2推送的镜像，更新一下下面中username/repo:tag 的位置代码： 12345678910111213141516171819version: "3"services: web: #使用之前你推送的镜像路径 替代这里的 username/repo:tag image: username/repo:tag deploy: replicas: 5 resources: limits: cpus: "0.1" memory: 50M restart_policy: condition: on-failure ports: - "4000:80" networks: - webnetnetworks: webnet: 文件解释这个文件告诉docker 去做以下的事： 拉取远程镜像 运行5个容器作为一个服务，命名为web;限制每一个的资源：最多10%CPU的使用和50MB内存 如果有一个容器宕机，立马重启它这个容器 映射宿主机的4000端口到web该服务的80端口 这里面的5个容器通过负载均衡网络webnet共享80端口 定义一个默认配置的网络webnet，它是一个负载均衡的网络(load-balanced overlay network) 运行你的负载均衡APP在我们使用docker stack deploy前先执行下面的命令： 1docker swarm init 注意：如果你不运行docker swarm init你将得到一个错误：“this node is not a swarm manager” 运行 以上命令后，使用一下命令给你的负载均衡APP命名，这里名为getstartedlab : 1docker stack deploy -c docker-compose.yml getstartedlab 如果你运行起来有***.***.*** must be a mapping 就说明的你yml配置文件格式不对 好了，我们来看看这个服务是不是有5个容器在运行，使用以下命令查看服务： 1docker service ls 我们可以看到服务name 是getstartedlab_web ，就是APP名__服务名的结合。这里服务中的每一个容器称为任务(Task)，这些任务都分配着唯一的ID，查看该服务的详细任务列表： 1docker service ps getstartedlab_web 以上 看到服务里各个任务id，当然容器对于外部系统来说，也有容器id: 1docker container ls -q 现在你可以使用curl -4 http://localhost:4000多次执行，或多次浏览该URL，你会发现所有不同，他们真的负载均衡了。你可以看到变得是容器ID,就是上面docker containter ls -q的结果之一。 调控你的APP你可以修改docker-compose.yml里的replicas的值，然后保存，再次执行：修改前我查看一下容器id列表： 123456$docker container ls -q6e64e22402783ccbef3e8459985e1fec14828c7dbe7aad8d6633801d7557 这里我修改replicas为7，然后保存，再次执行以下命令： 1docker stack deploy -c docker-compose.yml getstartedlab 再查看容器id列表： 12345678$docker container ls -qcc9987a174f1e4b0337fed8d6e64e22402783ccbef3e8459985e1fec14828c7dbe7aad8d6633801d7557 发现它保留了原来的容器，并增加两个新的容器：cc9987a174f1和e4b0337fed8d，说明调控任务数量时，它不会把原来的全部容器杀死，而是一种更新。 关闭你的app和关闭swarm关闭app 1docker stack rm getstartedlab 关闭swarm: 1docker swarm leave --force 总结12345678docker stack ls # List stacks or appsdocker stack deploy -c &lt;composefile&gt; &lt;appname&gt; # Run the specified Compose filedocker service ls # List running services associated with an appdocker service ps &lt;service&gt; # List tasks associated with an appdocker inspect &lt;task or container&gt; # Inspect task or containerdocker container ls -q # List container IDsdocker stack rm &lt;appname&gt; # Tear down an applicationdocker swarm leave --force # Take down a single node swarm from the manager]]></content>
      <categories>
        <category>Docker</category>
        <category>Docker入门</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门-part2-Containers]]></title>
    <url>%2F2017%2F12%2F22%2Fdocker-part2%2F</url>
    <content type="text"><![CDATA[容器Containers前言本Docker入门系列文章是翻译于Docker官方getStarted文档,如有出入，请跳转查看官方文档 定义Dockerfile文件新建一个空目录，cd进去，然后新建一个文件叫Dockerfile拷贝下面的内容进去。 1234567891011121314151617181920# Use an official Python runtime as a parent imageFROM python:2.7-slim# Set the working directory to /appWORKDIR /app# Copy the current directory contents into the container at /appADD . /app# Install any needed packages specified in requirements.txtRUN pip install --trusted-host pypi.python.org -r requirements.txt# Make port 80 available to the world outside this containerEXPOSE 80# Define environment variableENV NAME World# Run app.py when the container launchesCMD ["python", "app.py"] the app itself再拷贝两个文件，requirements.txt和app.py。把他们放到Dockerfile的相同目录里。这样Dockerfile就可以“ADD . /app” 把他们两个文件放进image镜象里。 requirements.txt12FlaskRedis app.py123456789101112131415161718192021222324from flask import Flaskfrom redis import Redis, RedisErrorimport osimport socket# Connect to Redisredis = Redis(host="redis", db=0, socket_connect_timeout=2, socket_timeout=2)app = Flask(__name__)@app.route("/")def hello(): try: visits = redis.incr("counter") except RedisError: visits = "&lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;" html = "&lt;h3&gt;Hello &#123;name&#125;!&lt;/h3&gt;" \ "&lt;b&gt;Hostname:&lt;/b&gt; &#123;hostname&#125;&lt;br/&gt;" \ "&lt;b&gt;Visits:&lt;/b&gt; &#123;visits&#125;" return html.format(name=os.getenv("NAME", "world"), hostname=socket.gethostname(), visits=visits)if __name__ == "__main__": app.run(host='0.0.0.0', port=80) 我们就看到刚刚的”pip install -r requirements.txt”,就是读取requirements.txt里的文件，安装Flask和Redis的库文件给Python。我们设置的环境变量NAME 为World ,那么代码里的socket.gethostname()就可以获取World。 建立我们的APP我们先看看我们现有的文件： 12$ lsDockerfile app.py requirements.txt 创建一个镜像，使用 -t 为它名一个友善的名字friendlyhello: 1docker build -t friendlyhello . 你可以使用docker images 或docker image ls查看镜像列表 运行我们的APP使用-p去映射宿主机的4000端口到容器的80端口： 1docker run -p 4000:80 friendlyhello 去打开我们的浏览器浏览http://localhost:4000 如果你使用的是Window 7 的Docker Toolbox ，请求不是localhost,而是http://192.168.99.100:4000。如果还不是，使用docker-machine ip 查看具体的Docker Machine IP 你也可以使用curl命令发起请求： 123$ curl http://localhost:4000&lt;h3&gt;Hello World!&lt;/h3&gt;&lt;b&gt;Hostname:&lt;/b&gt; 8fc990912a14&lt;br/&gt;&lt;b&gt;Visits:&lt;/b&gt; &lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt; 使用Ctrl+C 退出以上的正在运行的容器 对于Window系统，可能Ctrl+C并不能完全退出，只是简单退出运行的页面，还得docker container ls查看正在运行的容器，接着就docker container stop &lt;Container NAME or ID&gt;来停止该容器 现在呢，我们来让容器在后台运行,使用-d： 1docker run -d -p 4000:80 friendlyhello 你就会得到一个很长的容器ID,这个容器已经在后台运行了，我们可以使用docker container ls来查看正在运行的容器。同时我们可以访问http://localhsot:4000。现在我们可以关闭该容器： 1docker container stop bb1dd75f205d 分享你的镜像使用Docker账号登录如果你还没有账号，请在cloud.docker.com注册。注册好后，在命令行登录： 1$docker login 为你的镜像打上标签Tag具体的语法：docker tag image username/repository:tag image：哪一个镜像名； username:用户名（一定要对上你的账户名）； repository:库名； tag ：版本号 例如：docker tag friendlyhello john/get-started:part2 发布你的镜像1docker push username/repository:tag 等一上传完后，可以登录Docker Hub，去查看你新分享的镜像。 拉取远程镜像并且运行它1docker run -p 4000:80 username/repository:tag 如果你本地没有这个镜像它会去远程拉取，否则运行本地的镜像。 总结12345678910111213141516docker build -t friendlyname . # 使用Dockerfile 创建一个镜像，并使用-t为镜像命名，注意别漏了最后那一点"."，它表示Dockerfile的当前目录。docker run -p 4000:80 friendlyname # 使用-p 映射宿主机的端口4000到容器的80端口，运行镜像docker run -d -p 4000:80 friendlyname #使用后台运行模式 -d docker container ls # 查看运行中的容器列表docker container ls -a # 查看所有容器，包括没有运行中的docker container stop &lt;hash&gt; # 根据hash值，停止容器docker container kill &lt;hash&gt; # 强行关闭某个容器docker container rm &lt;hash&gt; # 删除某个容器docker container rm $(docker container ls -a -q) # 删除所有容器docker image ls -a # 查看所有的镜像docker image rm &lt;image id&gt; # 根据镜像ID，删除镜像docker image rm $(docker image ls -a -q) # 删除所有的镜像docker login # 登录docker tag &lt;image&gt; username/repository:tag # 为某个镜像打上标签docker push username/repository:tag # 上次镜像到远程仓库docker run username/repository:tag # 从远程仓库里运行一个镜像，如果本地没有就先拉取再运行]]></content>
      <categories>
        <category>Docker</category>
        <category>Docker入门</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门-part1]]></title>
    <url>%2F2017%2F12%2F22%2Fdocker-part1%2F</url>
    <content type="text"><![CDATA[Docker HelloWorld前言本Docker入门系列文章是翻译于Docker官方getStarted文档,如有出入，请跳转查看官方文档 简单介绍容器 An image is a lightweight, stand-alone, executable package that includes everything needed to run a piece of software, including the code, a runtime, libraries, environment variables, and config files. 镜像是一种轻量级的、独立的、可执行的包，它包含运行一个软件所需的所有内容，包括代码、运行时、库、环境变量和配置文件。 A container is a runtime instance of an image—what the image becomes in memory when actually executed. It runs completely isolated from the host environment by default, only accessing host files and ports if configured to do so. 容器是镜像的运行时实例——当实际执行时，镜像会变成内存。默认情况下，它完全与主机环境隔离，如果配置为这样，则只能访问主机文件和端口。 Hello world1234567$ docker run hello-worldHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps:...(snipped)...]]></content>
      <categories>
        <category>Docker</category>
        <category>Docker入门</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在docker里部署zookeeper]]></title>
    <url>%2F2017%2F12%2F21%2Fdocker-zookeeper%2F</url>
    <content type="text"><![CDATA[部署Zookeeper单台机器部署3个zookeeper节点首先，初始化swarm 1docker swarm init 然后编辑一个文件,如下： docker-compose-single.yml 1234567891011121314151617181920212223242526272829303132333435363738394041version: '3.1'services: zoo1: image: zookeeper restart: always hostname: zoo1 ports: - 2181:2181 environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=0.0.0.0:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 zoo2: image: zookeeper restart: always hostname: zoo2 ports: - 2182:2181 environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=0.0.0.0:2888:3888 server.3=zoo3:2888:3888 zoo3: image: zookeeper restart: always hostname: zoo3 ports: - 2183:2181 environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=0.0.0.0:2888:3888 visualizer: image: dockersamples/visualizer:stable ports: - "8080:8080" volumes: - "/var/run/docker.sock:/var/run/docker.sock" deploy: placement: constraints: [node.role == manager] 以上的部署文件，定义了4个服务，3个zookeeper和visualizer，visualizer是一个可视化服务，待会你可以用浏览器访问8080端口，查看其他服务的可视化状态。 使用命令，查看zookeeper的启动情况： 1echo stat | nc 127.0.0.1 2181 或者 1echo stat | nc 127.0.0.1 2182 或者 1echo stat | nc 127.0.0.1 2183 如果显示如下内容，说明启动成功，zookeeper的容器已经绑定在你本机的2181,2182,2183端口上 123456789101112Zookeeper version: 3.4.11-37e277162d567b55a07d1755f0b31c32e93c01a0, built on 11/01/2017 18:06 GMTClients: /10.255.0.2:56420[0](queued=0,recved=1,sent=0)Latency min/avg/max: 0/0/0Received: 1Sent: 0Connections: 1Outstanding: 0Zxid: 0x0Mode: followerNode count: 4 怎么使用zkCli.sh登陆客户端呢： 首先, 123456docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES99ee6c7335cd zookeeper:latest "/docker-entrypoin..." 17 hours ago Up 17 hours 2181/tcp, 2888/tcp, 3888/tcp zoolab_zoo2.1.0rfczhfcn1782fzpb2d6ir2iq0148b0cc522f zookeeper:latest "/docker-entrypoin..." 17 hours ago Up 17 hours 2181/tcp, 2888/tcp, 3888/tcp zoolab_zoo3.1.981cslrn7zqegvvp90r5vx5dme534fd292d3f zookeeper:latest "/docker-entrypoin..." 17 hours ago Up 17 hours 2181/tcp, 2888/tcp, 3888/tcp zoolab_zoo1.1.k45vcu9hqmzsxf8fg56b5hlx812e9ab6ae214 dockersamples/visualizer:stable "npm start" 17 hours ago Up 17 hours 8080/tcp zoolab_visualizer.1.hbg9c9sx9zd2c3obcaa9nbwgi 找到zookeeper的容器id : 99ee6c7335cd，0148b0cc522f，e534fd292d3f 我们现在选择一个容器id，进入容器: 12345678docker exec -it 99ee6c7335cd bashbash-4.4# lsLICENSE.txt bin dist-maven lib zookeeper-3.4.11.jar.ascNOTICE.txt build.xml docs recipes zookeeper-3.4.11.jar.md5README.md conf ivy.xml src zookeeper-3.4.11.jar.sha1README_packaging.txt contrib ivysettings.xml zookeeper-3.4.11.jarbash-4.4# ./bin/zkCli.sh （直接回车即可登陆zk客户端） 即可使用 zk 的 ls , get ,set ,create 等命令, 为了验证3个zookeeper之间的数据是互通的 我们可以登陆到一个容器里的zkCli创建一个节点数据： 123#容器99ee6c7335cd里的zkCli里输入[zk: localhost:2181(CONNECTED) 1] create /test 123456Created /test 我们登陆到另一台的容器的zkCli里： 1234567891011121314#容器0148b0cc522f里的zkCli里输入[zk: localhost:2181(CONNECTED) 1] get /test123456cZxid = 0x100000002ctime = Thu Dec 21 03:29:15 GMT 2017mZxid = 0x100000002mtime = Thu Dec 21 03:29:15 GMT 2017pZxid = 0x100000002cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 6numChildren = 0 如果在其他的容器里的zkCli能获取其他容器创建的节点数据，说明他们的数据是互通的。 多台机器部署3个zookeeper节点由于我们没有这么多台机器，我们将虚拟出其他3台虚拟机。 使用docker-machine 模拟3台机器： Mac,Linux,Win7,Win8 使用virtualbox 首先，您需要一个可以创建虚拟机(vm)的管理程序，因此为您的机器的操作系统安装Oracle VirtualBox。然后使用以下命令创建多台虚拟机 123docker-machine create --driver virtualbox myvm1docker-machine create --driver virtualbox myvm2docker-machine create --driver virtualbox myvm3 Win10 使用 hyper-V 登陆Hyper-V 管理系统 点击右边菜单的Virtual Switch Manager 在External里点击Create Virtual Switch 给给他一个名字myswitch ,选中该复选框以共享主机的活动网络适配器 现在，使用我们的节点管理工具docker-machine创建几个vm 123docker-machine create -d hyperv --hyperv-virtual-switch "myswitch" myvm1docker-machine create -d hyperv --hyperv-virtual-switch "myswitch" myvm2docker-machine create -d hyperv --hyperv-virtual-switch "myswitch" myvm3 接下来我们创建一个部署文件： docker-compose-swarm.yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152version: '3.1'services: zoo1: image: zookeeper restart: always hostname: zoo1 ports: - 2181:2181 environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 networks: - webnet zoo2: image: zookeeper restart: always hostname: zoo2 ports: - 2182:2181 environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 networks: - webnet zoo3: image: zookeeper restart: always hostname: zoo3 ports: - 2183:2181 environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 networks: - webnet visualizer: image: dockersamples/visualizer:stable ports: - 8080:8080 volumes: - "/var/run/docker.sock:/var/run/docker.sock" deploy: placement: constraints: [node.role == manager] networks: - webnetnetworks: webnet: driver: overlay 好了，在我们部署之前，我们需要定义好，myvm1为manager,myvm2和myvm3为worker。所以，我们先登陆到myvm1里去初始化swarm(前面也初始化过swarm,不过是单台机器)，然后把myvm2和myvm3加入到这个swarm中，最后才运行部署文件。具体操作如下： 设置终端环境我们不是要去登陆到myvm1里，而是获取myvm1的终端环境到本机的终端，在本机终端操作，从而操作虚拟机。 Mac,Linux 123456789101112docker-machine env myvm1#按提示，继续输入命令：eval $(docker-machine env myvm1)#查看docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmyvm1 * virtualbox Running tcp://192.168.99.100:2376 v17.06.2-ce myvm2 - virtualbox Running tcp://192.168.99.101:2376 v17.06.2-ce 在myvm1 旁边多了个星号，表示成功 Winodow 12345678910111213docker-machine env myvm1#按提示，继续输入命令：&amp; "C:\Program Files\Docker\Docker\Resources\bin\docker-machine.exe" env myvm1 | Invoke-Expression#查看docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmyvm1 * hyperv Running tcp://192.168.203.207:2376 v17.06.2-cemyvm2 - hyperv Running tcp://192.168.200.181:2376 v17.06.2-ce在myvm1 旁边多了个星号，表示成功 我们获取好myvm1终端环境，然后我们初始化swarm 12345678docker swarm init --advertise-addr &lt;myvm1 ip&gt;Swarm initialized: current node &lt;node ID&gt; is now a manager.To add a worker to this swarm, run the following command: docker swarm join \ --token &lt;token&gt; \ &lt;myvm ip&gt;:&lt;port&gt; 它这里提示我们登陆到其他的worker里,输入它上面给出的命令。 1234567#获取myvm2的终端环境eval $(docker-machine env myvm2)#加入swarmdocker swarm join \ --token &lt;token&gt; \ &lt;myvm ip&gt;:&lt;port&gt; 类似的，我们把myvm3也加入swarm来。 现在我们要登陆到myvm1里，因为它是manager,用它来进行部署 12345678#登陆myvm1eval $(docker-machine env myvm1)#部署docker stack deploy -c docker-compose-swarm.yml zklab#查看docker stack ps zklab 验证zookeeper 123echo stat | nc &lt;myvm1/2/3 ip&gt; 2181echo stat | nc &lt;myvm1/2/3 ip&gt; 2182echo stat | nc &lt;myvm1/2/3 ip&gt; 2183 用浏览器查看：http://myvm1/2/3_ip:8080]]></content>
      <categories>
        <category>Docker</category>
        <category>部署例子</category>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
</search>
